[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Survival analysis with tidymodels",
    "section": "",
    "text": "These are the materials for workshops on survival analysis with tidymodels. The tidymodels framework is a collection of packages for modeling and machine learning using tidyverse principles.\nThis course will teach you core tidymodels packages and their uses: data splitting/resampling with rsample, model fitting with parsnip, measuring model performance with yardstick, and basic model optimization with tune. Time permitting, youâ€™ll be introduced to pre-processing using the recipes package. Youâ€™ll learn tidymodels syntax as well as the process of predictive modeling for tabular data."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Survival analysis with tidymodels",
    "section": "",
    "text": "These are the materials for workshops on survival analysis with tidymodels. The tidymodels framework is a collection of packages for modeling and machine learning using tidyverse principles.\nThis course will teach you core tidymodels packages and their uses: data splitting/resampling with rsample, model fitting with parsnip, measuring model performance with yardstick, and basic model optimization with tune. Time permitting, youâ€™ll be introduced to pre-processing using the recipes package. Youâ€™ll learn tidymodels syntax as well as the process of predictive modeling for tabular data."
  },
  {
    "objectID": "index.html#is-this-workshop-for-me",
    "href": "index.html#is-this-workshop-for-me",
    "title": "Survival analysis with tidymodels",
    "section": "Is this workshop for me? ",
    "text": "Is this workshop for me? \nThis workshop is for you if you:\n\nare familiar with basic survival analysis such as censoring of time-to-event data, Kaplan-Meier curves, proportional hazards models\nare familiar with the basic predictive modeling workflow such as split in train and test set, resampling, tuning via grid search\nwant to learn how to leverage the tidymodels framework for survival analysis\n\nIntermediate or expert familiarity with modeling or machine learning is not required."
  },
  {
    "objectID": "index.html#preparation",
    "href": "index.html#preparation",
    "title": "Survival analysis with tidymodels",
    "section": "Preparation",
    "text": "Preparation\nThe process to set up your computer for either workshop will look the same. Please join the workshop with a computer that has the following installed (all available for free):\n\nA recent version of R, available at https://cran.r-project.org/\nA recent version of RStudio Desktop (RStudio Desktop Open Source License, at least v2022.02), available at https://posit.co/download/rstudio-desktop/\nThe following R packages, which you can install from the R console:\n\n\n# Install the packages for the workshop\npkgs &lt;- \n  c(\"bonsai\", \"doParallel\", \"embed\", \"finetune\", \"lightgbm\", \"lme4\",\n    \"plumber\", \"probably\", \"ranger\", \"rpart\", \"rpart.plot\", \"rules\",\n    \"splines2\", \"stacks\", \"text2vec\", \"textrecipes\", \"tidymodels\", \n    \"vetiver\", \"remotes\")\n\ninstall.packages(pkgs)\n\nIf youâ€™re a Windows user and encounter an error message during installation noting a missing Rtools installation, install Rtools using the installer linked here."
  },
  {
    "objectID": "index.html#slides",
    "href": "index.html#slides",
    "title": "Survival analysis with tidymodels",
    "section": "Slides",
    "text": "Slides\nThese slides are designed to use with live teaching and are published for workshop participantsâ€™ convenience. There are not meant as standalone learning materials. For that, we recommend tidymodels.org and Tidy Modeling with R.\n\nIntroduction to tidymodels\n\n01: Introduction\n02: Your data budget\n03: What makes a model?\n04: Evaluating models\n05: Tuning models\n06: Wrapping up\n\n\n\nExtra content (time permitting)\n\nIntro: Time-based splitting\nIntro: Using workflowsets\nIntro: Using recipes\n\nThereâ€™s also a page for slide annotations; these are extra notes for selected slides."
  },
  {
    "objectID": "index.html#code",
    "href": "index.html#code",
    "title": "Survival analysis with tidymodels",
    "section": "Code",
    "text": "Code\nQuarto files for working along are available on GitHub. (Donâ€™t worry if you havenâ€™t used Quarto before; it will feel familiar to R Markdown users.)"
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "Survival analysis with tidymodels",
    "section": "Acknowledgments",
    "text": "Acknowledgments\n\nThis website, including the slides, is made with Quarto. Please submit an issue on the GitHub repo for this workshop if you find something that could be fixed or improved."
  },
  {
    "objectID": "index.html#reuse-and-licensing",
    "href": "index.html#reuse-and-licensing",
    "title": "Survival analysis with tidymodels",
    "section": "Reuse and licensing",
    "text": "Reuse and licensing\n\nUnless otherwise noted (i.e.Â not an original creation and reused from another source), these educational materials are licensed under Creative Commons Attribution CC BY-SA 4.0."
  },
  {
    "objectID": "slides/intro-01-introduction.html#workshop-policies",
    "href": "slides/intro-01-introduction.html#workshop-policies",
    "title": "1 - Introduction",
    "section": "Workshop policies",
    "text": "Workshop policies\n\nPlease review the code of conduct: https://events.linuxfoundation.org/user/attend/code-of-conduct/"
  },
  {
    "objectID": "slides/intro-01-introduction.html#who-are-you",
    "href": "slides/intro-01-introduction.html#who-are-you",
    "title": "1 - Introduction",
    "section": "Who are you?",
    "text": "Who are you?\n\nYou can use the magrittr %&gt;% or base R |&gt; pipe\nYou are familiar with functions from dplyr, tidyr, ggplot2\nYou have exposure to basic concepts of survival analysis\nYou are familiar with the basic predictive modeling workflow\nYou do not need intermediate or expert familiarity with modeling or ML"
  },
  {
    "objectID": "slides/intro-01-introduction.html#who-are-tidymodels",
    "href": "slides/intro-01-introduction.html#who-are-tidymodels",
    "title": "1 - Introduction",
    "section": "Who are tidymodels?",
    "text": "Who are tidymodels?\n\nSimon Couch\nHannah Frick\nEmil Hvitfeldt\nMax Kuhn\n\n\nMany thanks to Davis Vaughan, Julia Silge, David Robinson, Julie Jung, Alison Hill, and DesirÃ©e De Leon for their role in creating these materials!"
  },
  {
    "objectID": "slides/intro-01-introduction.html#section-2",
    "href": "slides/intro-01-introduction.html#section-2",
    "title": "1 - Introduction",
    "section": "ğŸ‘€",
    "text": "ğŸ‘€"
  },
  {
    "objectID": "slides/intro-01-introduction.html#plan-for-this-workshop",
    "href": "slides/intro-01-introduction.html#plan-for-this-workshop",
    "title": "1 - Introduction",
    "section": "Plan for this workshop",
    "text": "Plan for this workshop\n\nYour data budget\nWhat makes a model\nEvaluating models\nTuning models"
  },
  {
    "objectID": "slides/intro-01-introduction.html#section-3",
    "href": "slides/intro-01-introduction.html#section-3",
    "title": "1 - Introduction",
    "section": "",
    "text": "Introduce yourself to your neighbors ğŸ‘‹\n\n Log in to Posit Cloud (free): TODO-ADD-LATER"
  },
  {
    "objectID": "slides/intro-01-introduction.html#what-is-machine-learning",
    "href": "slides/intro-01-introduction.html#what-is-machine-learning",
    "title": "1 - Introduction",
    "section": "What is machine learning?",
    "text": "What is machine learning?\n\n\nhttps://xkcd.com/1838/"
  },
  {
    "objectID": "slides/intro-01-introduction.html#what-is-machine-learning-1",
    "href": "slides/intro-01-introduction.html#what-is-machine-learning-1",
    "title": "1 - Introduction",
    "section": "What is machine learning?",
    "text": "What is machine learning?\n\n\nIllustration credit: https://vas3k.com/blog/machine_learning/"
  },
  {
    "objectID": "slides/intro-01-introduction.html#what-is-machine-learning-2",
    "href": "slides/intro-01-introduction.html#what-is-machine-learning-2",
    "title": "1 - Introduction",
    "section": "What is machine learning?",
    "text": "What is machine learning?\n\n\nIllustration credit: https://vas3k.com/blog/machine_learning/"
  },
  {
    "objectID": "slides/intro-01-introduction.html#your-turn",
    "href": "slides/intro-01-introduction.html#your-turn",
    "title": "1 - Introduction",
    "section": "Your turn",
    "text": "Your turn\n\n\nHow are statistics and machine learning related?\nHow are they similar? Different?\n\n\n\nâˆ’+\n03:00\n\n\n\n\nthe â€œtwo culturesâ€\nmodel first vs.Â data first\ninference vs.Â prediction"
  },
  {
    "objectID": "slides/intro-01-introduction.html#what-is-tidymodels",
    "href": "slides/intro-01-introduction.html#what-is-tidymodels",
    "title": "1 - Introduction",
    "section": "What is tidymodels? ",
    "text": "What is tidymodels? \n\nlibrary(tidymodels)\n#&gt; â”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels 1.2.0 â”€â”€\n#&gt; âœ” broom        1.0.6      âœ” rsample      1.2.1 \n#&gt; âœ” dials        1.2.1      âœ” tibble       3.2.1 \n#&gt; âœ” dplyr        1.1.4      âœ” tidyr        1.3.1 \n#&gt; âœ” infer        1.0.7      âœ” tune         1.2.1 \n#&gt; âœ” modeldata    1.3.0      âœ” workflows    1.1.4 \n#&gt; âœ” parsnip      1.2.1      âœ” workflowsets 1.1.0 \n#&gt; âœ” purrr        1.0.2      âœ” yardstick    1.3.1 \n#&gt; âœ” recipes      1.0.10\n#&gt; â”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels_conflicts() â”€â”€\n#&gt; âœ– purrr::discard() masks scales::discard()\n#&gt; âœ– dplyr::filter()  masks stats::filter()\n#&gt; âœ– dplyr::lag()     masks stats::lag()\n#&gt; âœ– recipes::step()  masks stats::step()\n#&gt; â€¢ Learn how to get started at https://www.tidymodels.org/start/"
  },
  {
    "objectID": "slides/intro-01-introduction.html#the-whole-game",
    "href": "slides/intro-01-introduction.html#the-whole-game",
    "title": "1 - Introduction",
    "section": "The whole game",
    "text": "The whole game\n\nRoadmap for today\nMinimal version of predictive modeling process\nFeature engineering and tuning as iterative extensions"
  },
  {
    "objectID": "slides/intro-01-introduction.html#the-whole-game-1",
    "href": "slides/intro-01-introduction.html#the-whole-game-1",
    "title": "1 - Introduction",
    "section": "The whole game",
    "text": "The whole game"
  },
  {
    "objectID": "slides/intro-01-introduction.html#the-whole-game-2",
    "href": "slides/intro-01-introduction.html#the-whole-game-2",
    "title": "1 - Introduction",
    "section": "The whole game",
    "text": "The whole game\n\n\nStress that we are not fitting a model on the entire training set other than for illustrative purposes in deck 2."
  },
  {
    "objectID": "slides/intro-01-introduction.html#the-whole-game-3",
    "href": "slides/intro-01-introduction.html#the-whole-game-3",
    "title": "1 - Introduction",
    "section": "The whole game",
    "text": "The whole game"
  },
  {
    "objectID": "slides/intro-01-introduction.html#the-whole-game-4",
    "href": "slides/intro-01-introduction.html#the-whole-game-4",
    "title": "1 - Introduction",
    "section": "The whole game",
    "text": "The whole game"
  },
  {
    "objectID": "slides/intro-01-introduction.html#the-whole-game-5",
    "href": "slides/intro-01-introduction.html#the-whole-game-5",
    "title": "1 - Introduction",
    "section": "The whole game",
    "text": "The whole game"
  },
  {
    "objectID": "slides/intro-01-introduction.html#the-whole-game-6",
    "href": "slides/intro-01-introduction.html#the-whole-game-6",
    "title": "1 - Introduction",
    "section": "The whole game",
    "text": "The whole game"
  },
  {
    "objectID": "slides/intro-01-introduction.html#the-whole-game-7",
    "href": "slides/intro-01-introduction.html#the-whole-game-7",
    "title": "1 - Introduction",
    "section": "The whole game",
    "text": "The whole game"
  },
  {
    "objectID": "slides/intro-01-introduction.html#lets-install-some-packages",
    "href": "slides/intro-01-introduction.html#lets-install-some-packages",
    "title": "1 - Introduction",
    "section": "Letâ€™s install some packages",
    "text": "Letâ€™s install some packages\nIf you are using your own laptop instead of Posit Cloud:\n\n# Install the packages for the workshop\npkgs &lt;- \n  c(\"bonsai\", \"doParallel\", \"embed\", \"finetune\", \"lightgbm\", \"lme4\",\n    \"plumber\", \"probably\", \"ranger\", \"rpart\", \"rpart.plot\", \"rules\",\n    \"splines2\", \"stacks\", \"text2vec\", \"textrecipes\", \"tidymodels\", \n    \"vetiver\", \"remotes\")\n\ninstall.packages(pkgs)"
  },
  {
    "objectID": "slides/intro-01-introduction.html#our-versions",
    "href": "slides/intro-01-introduction.html#our-versions",
    "title": "1 - Introduction",
    "section": "Our versions",
    "text": "Our versions\nR version 4.4.0 (2024-04-24), Quarto (1.4.552)\n\n\n\n\n\n\n\npackage\nversion\n\n\n\n\nbonsai\n0.2.1\n\n\nbroom\n1.0.6\n\n\ndials\n1.2.1\n\n\ndoParallel\n1.0.17\n\n\ndplyr\n1.1.4\n\n\nembed\n1.1.4\n\n\nfinetune\n1.2.0\n\n\nggplot2\n3.5.1\n\n\nlightgbm\n4.3.0\n\n\n\n\n\n\n\n\n\n\n\npackage\nversion\n\n\n\n\nlme4\n1.1-35.3\n\n\nmodeldata\n1.3.0\n\n\nparsnip\n1.2.1\n\n\nplumber\n1.2.2\n\n\nprobably\n1.0.3\n\n\npurrr\n1.0.2\n\n\nranger\n0.16.0\n\n\nrecipes\n1.0.10\n\n\nremotes\n2.5.0\n\n\n\n\n\n\n\n\n\n\n\npackage\nversion\n\n\n\n\nrpart\n4.1.23\n\n\nrpart.plot\n3.1.2\n\n\nrsample\n1.2.1\n\n\nrules\n1.0.2\n\n\nscales\n1.3.0\n\n\nsplines2\n0.5.2\n\n\nstacks\n1.0.4\n\n\ntext2vec\n0.6.4\n\n\ntextrecipes\n1.0.6\n\n\n\n\n\n\n\n\n\n\n\npackage\nversion\n\n\n\n\ntibble\n3.2.1\n\n\ntidymodels\n1.2.0\n\n\ntidyr\n1.3.1\n\n\ntune\n1.2.1\n\n\nvetiver\n0.2.5\n\n\nworkflows\n1.1.4\n\n\nworkflowsets\n1.1.0\n\n\nyardstick\n1.3.1\n\n\n\n\n\n\n\n\n\n\nhttps://workshops.tidymodels.org"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#data-on-chicago-taxi-trips",
    "href": "slides/intro-02-data-budget.html#data-on-chicago-taxi-trips",
    "title": "2 - Your data budget",
    "section": "Data on Chicago taxi trips",
    "text": "Data on Chicago taxi trips\n\n\n\nThe city of Chicago releases anonymized trip-level data on taxi trips in the city.\nWe pulled a sample of 10,000 rides occurring in early 2022.\nType ?taxi to learn more about this dataset, including references.\n\n\n\n\n\n\nCredit: https://www.svgrepo.com/svg/8322/taxi"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#data-on-chicago-taxi-trips-1",
    "href": "slides/intro-02-data-budget.html#data-on-chicago-taxi-trips-1",
    "title": "2 - Your data budget",
    "section": "Data on Chicago taxi trips",
    "text": "Data on Chicago taxi trips\n\n\n\nN = 10,000\nA nominal outcome, tip, with levels \"yes\" and \"no\"\nSeveral nominal variables like pickup & dropoff location, taxi ID, and payment type.\nSeveral numeric variables like trip length and fare subtotals.\n\n\n\n\n\n\nCredit: https://unsplash.com/photos/7_r85l4eht8\n\n\nâ€œFare subtotalsâ€ refers to the fare itself, tax, tolls, tip amount.\nAlso have date/time info"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#checklist-for-predictors",
    "href": "slides/intro-02-data-budget.html#checklist-for-predictors",
    "title": "2 - Your data budget",
    "section": "Checklist for predictors",
    "text": "Checklist for predictors\n\nIs it ethical to use this variable? (Or even legal?)\nWill this variable be available at prediction time?\nDoes this variable contribute to explainability?"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#data-on-chicago-taxi-trips-2",
    "href": "slides/intro-02-data-budget.html#data-on-chicago-taxi-trips-2",
    "title": "2 - Your data budget",
    "section": "Data on Chicago taxi trips",
    "text": "Data on Chicago taxi trips\n\nlibrary(tidymodels)\n\ntaxi\n#&gt; # A tibble: 10,000 Ã— 7\n#&gt;    tip   distance company                      local dow   month  hour\n#&gt;    &lt;fct&gt;    &lt;dbl&gt; &lt;fct&gt;                        &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt;\n#&gt;  1 yes      17.2  Chicago Independents         no    Thu   Feb      16\n#&gt;  2 yes       0.88 City Service                 yes   Thu   Mar       8\n#&gt;  3 yes      18.1  other                        no    Mon   Feb      18\n#&gt;  4 yes      20.7  Chicago Independents         no    Mon   Apr       8\n#&gt;  5 yes      12.2  Chicago Independents         no    Sun   Mar      21\n#&gt;  6 yes       0.94 Sun Taxi                     yes   Sat   Apr      23\n#&gt;  7 yes      17.5  Flash Cab                    no    Fri   Mar      12\n#&gt;  8 yes      17.7  other                        no    Sun   Jan       6\n#&gt;  9 yes       1.85 Taxicab Insurance Agency Llc no    Fri   Apr      12\n#&gt; 10 yes       1.47 City Service                 no    Tue   Mar      14\n#&gt; # â„¹ 9,990 more rows\n\n\ntip: Whether the rider left a tip. A factor with levels â€œyesâ€ and â€œnoâ€.\ndistance: The trip distance, in odometer miles.\ncompany: The taxi company, as a factor. Companies that occurred few times were binned as â€œotherâ€.\nlocal: Whether the trip started in the same community area as it began. See the source data for community area values.\ndow: The day of the week in which the trip began, as a factor.\nmonth: The month in which the trip began, as a factor.\nhour: The hour of the day in which the trip began, as a numeric."
  },
  {
    "objectID": "slides/intro-02-data-budget.html#data-splitting-and-spending",
    "href": "slides/intro-02-data-budget.html#data-splitting-and-spending",
    "title": "2 - Your data budget",
    "section": "Data splitting and spending",
    "text": "Data splitting and spending\nFor machine learning, we typically split data into training and test sets:\n\n\nThe training set is used to estimate model parameters.\nThe test set is used to find an independent assessment of model performance.\n\n\n\nDo not ğŸš« use the test set during training."
  },
  {
    "objectID": "slides/intro-02-data-budget.html#data-splitting-and-spending-1",
    "href": "slides/intro-02-data-budget.html#data-splitting-and-spending-1",
    "title": "2 - Your data budget",
    "section": "Data splitting and spending",
    "text": "Data splitting and spending"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#data-splitting-and-spending-2",
    "href": "slides/intro-02-data-budget.html#data-splitting-and-spending-2",
    "title": "2 - Your data budget",
    "section": "Data splitting and spending",
    "text": "Data splitting and spending\n\nSpending too much data in training prevents us from computing a good assessment of predictive performance.\n\n\n\nSpending too much data in testing prevents us from computing a good estimate of model parameters."
  },
  {
    "objectID": "slides/intro-02-data-budget.html#your-turn",
    "href": "slides/intro-02-data-budget.html#your-turn",
    "title": "2 - Your data budget",
    "section": "Your turn",
    "text": "Your turn\n\nWhen is a good time to split your data?\n\n\n\nâˆ’+\n03:00"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#the-initial-split",
    "href": "slides/intro-02-data-budget.html#the-initial-split",
    "title": "2 - Your data budget",
    "section": "The initial split ",
    "text": "The initial split \n\nset.seed(123)\ntaxi_split &lt;- initial_split(taxi)\ntaxi_split\n#&gt; &lt;Training/Testing/Total&gt;\n#&gt; &lt;7500/2500/10000&gt;\n\n\nHow much data in training vs testing? This function uses a good default, but this depends on your specific goal/data We will talk about more powerful ways of splitting, like stratification, later"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#what-is-set.seed",
    "href": "slides/intro-02-data-budget.html#what-is-set.seed",
    "title": "2 - Your data budget",
    "section": "What is set.seed()?",
    "text": "What is set.seed()?\nTo create that split of the data, R generates â€œpseudo-randomâ€ numbers: while they are made to behave like random numbers, their generation is deterministic give a â€œseedâ€.\nThis allows us to reproduce results by setting that seed.\nWhich seed you pick doesnâ€™t matter, as long as you donâ€™t try a bunch of seeds and pick the one that gives you the best performance."
  },
  {
    "objectID": "slides/intro-02-data-budget.html#accessing-the-data",
    "href": "slides/intro-02-data-budget.html#accessing-the-data",
    "title": "2 - Your data budget",
    "section": "Accessing the data ",
    "text": "Accessing the data \n\ntaxi_train &lt;- training(taxi_split)\ntaxi_test &lt;- testing(taxi_split)"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#the-training-set",
    "href": "slides/intro-02-data-budget.html#the-training-set",
    "title": "2 - Your data budget",
    "section": "The training set",
    "text": "The training set\n\ntaxi_train\n#&gt; # A tibble: 7,500 Ã— 7\n#&gt;    tip   distance company                   local dow   month  hour\n#&gt;    &lt;fct&gt;    &lt;dbl&gt; &lt;fct&gt;                     &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt;\n#&gt;  1 yes       0.7  Taxi Affiliation Services yes   Tue   Mar      18\n#&gt;  2 yes       0.99 Sun Taxi                  yes   Tue   Jan       8\n#&gt;  3 yes       1.78 other                     no    Sat   Mar      22\n#&gt;  4 yes       0    Taxi Affiliation Services yes   Wed   Apr      15\n#&gt;  5 yes       0    Taxi Affiliation Services no    Sun   Jan      21\n#&gt;  6 yes       2.3  other                     no    Sat   Apr      21\n#&gt;  7 yes       6.35 Sun Taxi                  no    Wed   Mar      16\n#&gt;  8 yes       2.79 other                     no    Sun   Feb      14\n#&gt;  9 yes      16.6  other                     no    Sun   Apr      18\n#&gt; 10 yes       0.02 Chicago Independents      yes   Sun   Apr      15\n#&gt; # â„¹ 7,490 more rows"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#the-test-set",
    "href": "slides/intro-02-data-budget.html#the-test-set",
    "title": "2 - Your data budget",
    "section": "The test set ",
    "text": "The test set \nğŸ™ˆ\n\nThere are 2500 rows and 7 columns in the test set."
  },
  {
    "objectID": "slides/intro-02-data-budget.html#your-turn-1",
    "href": "slides/intro-02-data-budget.html#your-turn-1",
    "title": "2 - Your data budget",
    "section": "Your turn",
    "text": "Your turn\n\nSplit your data so 20% is held out for the test set.\nTry out different values in set.seed() to see how the results change.\n\n\n\nâˆ’+\n05:00"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#data-splitting-and-spending-3",
    "href": "slides/intro-02-data-budget.html#data-splitting-and-spending-3",
    "title": "2 - Your data budget",
    "section": "Data splitting and spending ",
    "text": "Data splitting and spending \n\nset.seed(123)\ntaxi_split &lt;- initial_split(taxi, prop = 0.8)\ntaxi_train &lt;- training(taxi_split)\ntaxi_test &lt;- testing(taxi_split)\n\nnrow(taxi_train)\n#&gt; [1] 8000\nnrow(taxi_test)\n#&gt; [1] 2000"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#validation-set",
    "href": "slides/intro-02-data-budget.html#validation-set",
    "title": "2 - Your data budget",
    "section": "Validation set",
    "text": "Validation set\n\nset.seed(123)\ninitial_validation_split(taxi, prop = c(0.6, 0.2))\n#&gt; &lt;Training/Validation/Testing/Total&gt;\n#&gt; &lt;6000/2000/2000/10000&gt;"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#your-turn-2",
    "href": "slides/intro-02-data-budget.html#your-turn-2",
    "title": "2 - Your data budget",
    "section": "Your turn",
    "text": "Your turn\n\nExplore the taxi_train data on your own!\n\nWhatâ€™s the distribution of the outcome, tip?\nWhatâ€™s the distribution of numeric variables like distance?\nHow does tip differ across the categorical variables?\n\n\n\n\nâˆ’+\n08:00\n\n\n\n\nMake a plot or summary and then share with neighbor"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#section-2",
    "href": "slides/intro-02-data-budget.html#section-2",
    "title": "2 - Your data budget",
    "section": "",
    "text": "taxi_train %&gt;% \n  ggplot(aes(x = tip)) +\n  geom_bar()"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#section-3",
    "href": "slides/intro-02-data-budget.html#section-3",
    "title": "2 - Your data budget",
    "section": "",
    "text": "taxi_train %&gt;% \n  ggplot(aes(x = local, fill = tip)) +\n  geom_bar()"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#section-4",
    "href": "slides/intro-02-data-budget.html#section-4",
    "title": "2 - Your data budget",
    "section": "",
    "text": "taxi_train %&gt;% \n  ggplot(aes(x = hour, fill = tip)) +\n  geom_bar()"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#section-5",
    "href": "slides/intro-02-data-budget.html#section-5",
    "title": "2 - Your data budget",
    "section": "",
    "text": "taxi_train %&gt;% \n  ggplot(aes(x = hour, fill = tip)) +\n  geom_bar(position = \"fill\")"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#section-6",
    "href": "slides/intro-02-data-budget.html#section-6",
    "title": "2 - Your data budget",
    "section": "",
    "text": "taxi_train %&gt;% \n  ggplot(aes(x = distance)) +\n  geom_histogram(bins = 100) +\n  facet_grid(vars(tip))"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#section-7",
    "href": "slides/intro-02-data-budget.html#section-7",
    "title": "2 - Your data budget",
    "section": "",
    "text": "Stratified sampling would split within response values\n\nBased on our EDA, we know that the source data contains fewer \"no\" tip values than \"yes\". We want to make sure we allot equal proportions of those responses so that both the training and testing data have enough of each to give accurate estimates."
  },
  {
    "objectID": "slides/intro-02-data-budget.html#stratification",
    "href": "slides/intro-02-data-budget.html#stratification",
    "title": "2 - Your data budget",
    "section": "Stratification",
    "text": "Stratification\nUse strata = tip\n\nset.seed(123)\ntaxi_split &lt;- initial_split(taxi, prop = 0.8, strata = tip)\ntaxi_split\n#&gt; &lt;Training/Testing/Total&gt;\n#&gt; &lt;8000/2000/10000&gt;"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#stratification-1",
    "href": "slides/intro-02-data-budget.html#stratification-1",
    "title": "2 - Your data budget",
    "section": "Stratification",
    "text": "Stratification\nStratification often helps, with very little downside"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#the-whole-game---status-update",
    "href": "slides/intro-02-data-budget.html#the-whole-game---status-update",
    "title": "2 - Your data budget",
    "section": "The whole game - status update",
    "text": "The whole game - status update\n\n\n\n\nhttps://workshops.tidymodels.org"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#your-turn",
    "href": "slides/intro-03-what-makes-a-model.html#your-turn",
    "title": "3 - What makes a model?",
    "section": "Your turn",
    "text": "Your turn\n\nHow do you fit a linear model in R? \nHow many different ways can you think of?\n\n\n\nâˆ’+\n03:00\n\n\n\n\n\nlm for linear model\nglm for generalized linear model (e.g.Â logistic regression)\nglmnet for regularized regression\nkeras for regression using TensorFlow\nstan for Bayesian regression\nspark for large data sets"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#to-specify-a-model",
    "href": "slides/intro-03-what-makes-a-model.html#to-specify-a-model",
    "title": "3 - What makes a model?",
    "section": "To specify a model ",
    "text": "To specify a model \n\n\n\n\nChoose a model\nSpecify an engine\nSet the mode\n\n\n\n\n\n\nCredit: https://www.svgrepo.com/svg/481270/cat-5"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-1",
    "href": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-1",
    "title": "3 - What makes a model?",
    "section": "To specify a model  ",
    "text": "To specify a model  \n\nproportional_hazards()\n#&gt; Proportional Hazards Model Specification (censored regression)\n#&gt; \n#&gt; Computational engine: survival\n\n\nModels have default engines"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-2",
    "href": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-2",
    "title": "3 - What makes a model?",
    "section": "To specify a model ",
    "text": "To specify a model \n\n\n\nChoose a model\nSpecify an engine\nSet the mode"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-3",
    "href": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-3",
    "title": "3 - What makes a model?",
    "section": "To specify a model  ",
    "text": "To specify a model  \n\nproportional_hazards()\n#&gt; Proportional Hazards Model Specification (censored regression)\n#&gt; \n#&gt; Computational engine: survival"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-4",
    "href": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-4",
    "title": "3 - What makes a model?",
    "section": "To specify a model  ",
    "text": "To specify a model  \n\nproportional_hazards() %&gt;%\n  set_engine(\"glmnet\")\n#&gt; Proportional Hazards Model Specification (censored regression)\n#&gt; \n#&gt; Computational engine: glmnet"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-5",
    "href": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-5",
    "title": "3 - What makes a model?",
    "section": "To specify a model ",
    "text": "To specify a model \n\n\n\nChoose a model\nSpecify an engine\nSet the mode"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-6",
    "href": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-6",
    "title": "3 - What makes a model?",
    "section": "To specify a model ",
    "text": "To specify a model \n\ndecision_tree()\n#&gt; Decision Tree Model Specification (unknown mode)\n#&gt; \n#&gt; Computational engine: rpart\n\n\nSome models have a default mode"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-7",
    "href": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-7",
    "title": "3 - What makes a model?",
    "section": "To specify a model  ",
    "text": "To specify a model  \n\ndecision_tree() %&gt;% \n  set_mode(\"censored regression\")\n#&gt; Decision Tree Model Specification (censored regression)\n#&gt; \n#&gt; Computational engine: rpart\n\n\n\n\nAll available models are listed at https://www.tidymodels.org/find/parsnip/"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-8",
    "href": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-8",
    "title": "3 - What makes a model?",
    "section": "To specify a model ",
    "text": "To specify a model \n\n\n\nChoose a model\nSpecify an engine\nSet the mode"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#your-turn-1",
    "href": "slides/intro-03-what-makes-a-model.html#your-turn-1",
    "title": "3 - What makes a model?",
    "section": "Your turn",
    "text": "Your turn\n\nWrite the specification for a proportional hazards model.\nChoose your engine.\n\nAll available models are listed at https://www.tidymodels.org/find/parsnip/\n\n\nExtension/Challenge: Edit this code to use a different model. For example, try using a conditional inference tree as implemented in the partykit package - or try an entirely different model type!\n\n\n\nâˆ’+\n05:00"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#models-well-be-using-today",
    "href": "slides/intro-03-what-makes-a-model.html#models-well-be-using-today",
    "title": "3 - What makes a model?",
    "section": "Models weâ€™ll be using today",
    "text": "Models weâ€™ll be using today\n\nProportional hazards (PH) model\nDecision tree"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#logistic-regression",
    "href": "slides/intro-03-what-makes-a-model.html#logistic-regression",
    "title": "3 - What makes a model?",
    "section": "Logistic regression",
    "text": "Logistic regression"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#logistic-regression-1",
    "href": "slides/intro-03-what-makes-a-model.html#logistic-regression-1",
    "title": "3 - What makes a model?",
    "section": "Logistic regression",
    "text": "Logistic regression"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#logistic-regression-2",
    "href": "slides/intro-03-what-makes-a-model.html#logistic-regression-2",
    "title": "3 - What makes a model?",
    "section": "Logistic regression",
    "text": "Logistic regression\n\n\n\n\n\n\n\n\n\n\n\n\n\nLogit of outcome probability modeled as linear combination of predictors:\n\n\\(log(\\frac{p}{1 - p}) = \\beta_0 + \\beta_1\\cdot \\text{A}\\)\n\nFind a sigmoid line that separates the two classes"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#decision-trees",
    "href": "slides/intro-03-what-makes-a-model.html#decision-trees",
    "title": "3 - What makes a model?",
    "section": "Decision trees",
    "text": "Decision trees"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#decision-trees-1",
    "href": "slides/intro-03-what-makes-a-model.html#decision-trees-1",
    "title": "3 - What makes a model?",
    "section": "Decision trees",
    "text": "Decision trees\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeries of splits or if/then statements based on predictors\nFirst the tree grows until some condition is met (maximum depth, no more data)\nThen the tree is pruned to reduce its complexity"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#decision-trees-2",
    "href": "slides/intro-03-what-makes-a-model.html#decision-trees-2",
    "title": "3 - What makes a model?",
    "section": "Decision trees",
    "text": "Decision trees"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#all-models-are-wrong-but-some-are-useful",
    "href": "slides/intro-03-what-makes-a-model.html#all-models-are-wrong-but-some-are-useful",
    "title": "3 - What makes a model?",
    "section": "All models are wrong, but some are useful!",
    "text": "All models are wrong, but some are useful!\n\n\nPH model\n\n\n\n\n\n\n\n\n\n\nDecision tree"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#workflows-bind-preprocessors-and-models",
    "href": "slides/intro-03-what-makes-a-model.html#workflows-bind-preprocessors-and-models",
    "title": "3 - What makes a model?",
    "section": "Workflows bind preprocessors and models",
    "text": "Workflows bind preprocessors and models\n\n\nExplain that PCA that is a preprocessor / dimensionality reduction, used to decorrelate data"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#what-is-wrong-with-this",
    "href": "slides/intro-03-what-makes-a-model.html#what-is-wrong-with-this",
    "title": "3 - What makes a model?",
    "section": "What is wrong with this?",
    "text": "What is wrong with this?"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#why-a-workflow",
    "href": "slides/intro-03-what-makes-a-model.html#why-a-workflow",
    "title": "3 - What makes a model?",
    "section": "Why a workflow()? ",
    "text": "Why a workflow()? \n\n\nWorkflows handle new data better than base R tools in terms of new factor levels\n\n\n\n\nYou can use other preprocessors besides formulas (more on feature engineering if time permits!)\n\n\n\n\nThey can help organize your work when working with multiple models\n\n\n\n\nMost importantly, a workflow captures the entire modeling process: fit() and predict() apply to the preprocessing steps in addition to the actual model fit\n\n\nTwo ways workflows handle levels better than base R:\n\nEnforces that new levels are not allowed at prediction time (this is an optional check that can be turned off)\nRestores missing levels that were present at fit time, but happen to be missing at prediction time (like, if your â€œnewâ€ data just doesnâ€™t have an instance of that level)"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#a-model-workflow-1",
    "href": "slides/intro-03-what-makes-a-model.html#a-model-workflow-1",
    "title": "3 - What makes a model?",
    "section": "A model workflow   ",
    "text": "A model workflow   \n\ntree_spec &lt;-\n  decision_tree() %&gt;% \n  set_mode(\"censored regression\")\n\ntree_spec %&gt;% \n  fit(event_time ~ ., data = cat_train) \n#&gt; parsnip model object\n#&gt; \n#&gt; $rpart\n#&gt; n= 1805 \n#&gt; \n#&gt; node), split, n, deviance, yval\n#&gt;       * denotes terminal node\n#&gt; \n#&gt; 1) root 1805 2025.6490 1.0000000  \n#&gt;   2) neutered=no,unknown 724  601.9346 0.5563459 *\n#&gt;   3) neutered=yes 1081 1309.8090 1.2024000  \n#&gt;     6) intake_condition=ill_mild,ill_moderatete,normal,under_age_or_weight,other 934 1067.3560 1.1130980 *\n#&gt;     7) intake_condition=feral,fractious 147  186.0952 2.4153980 *\n#&gt; \n#&gt; $survfit\n#&gt; \n#&gt; Call: prodlim::prodlim(formula = form, data = data)\n#&gt; \n#&gt; \n#&gt; \n#&gt; Right-censored response of a survival model\n#&gt; \n#&gt; No.Observations: 1805 \n#&gt; \n#&gt; Pattern:\n#&gt;                 Freq\n#&gt;  event          1134\n#&gt;  right.censored 671 \n#&gt; \n#&gt; $levels\n#&gt; [1] \"0.556345939526915\" \"1.11309762791995\"  \"2.41539768185841\" \n#&gt; \n#&gt; attr(,\"class\")\n#&gt; [1] \"pecRpart\""
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#a-model-workflow-2",
    "href": "slides/intro-03-what-makes-a-model.html#a-model-workflow-2",
    "title": "3 - What makes a model?",
    "section": "A model workflow   ",
    "text": "A model workflow   \n\ntree_spec &lt;-\n  decision_tree() %&gt;% \n  set_mode(\"censored regression\")\n\nworkflow() %&gt;%\n  add_formula(event_time ~ .) %&gt;%\n  add_model(tree_spec) %&gt;%\n  fit(data = cat_train) \n#&gt; â•â• Workflow [trained] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n#&gt; Preprocessor: Formula\n#&gt; Model: decision_tree()\n#&gt; \n#&gt; â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#&gt; event_time ~ .\n#&gt; \n#&gt; â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#&gt; $rpart\n#&gt; n= 1805 \n#&gt; \n#&gt; node), split, n, deviance, yval\n#&gt;       * denotes terminal node\n#&gt; \n#&gt; 1) root 1805 2025.6490 1.0000000  \n#&gt;   2) neutered=no,unknown 724  601.9346 0.5563459 *\n#&gt;   3) neutered=yes 1081 1309.8090 1.2024000  \n#&gt;     6) intake_condition=ill_mild,ill_moderatete,normal,under_age_or_weight,other 934 1067.3560 1.1130980 *\n#&gt;     7) intake_condition=feral,fractious 147  186.0952 2.4153980 *\n#&gt; \n#&gt; $survfit\n#&gt; \n#&gt; Call: prodlim::prodlim(formula = form, data = data)\n#&gt; \n#&gt; \n#&gt; \n#&gt; Right-censored response of a survival model\n#&gt; \n#&gt; No.Observations: 1805 \n#&gt; \n#&gt; Pattern:\n#&gt;                 Freq\n#&gt;  event          1134\n#&gt;  right.censored 671 \n#&gt; \n#&gt; $levels\n#&gt; [1] \"0.556345939526914\" \"1.11309762791995\"  \"2.41539768185841\" \n#&gt; \n#&gt; attr(,\"class\")\n#&gt; [1] \"pecRpart\""
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#a-model-workflow-3",
    "href": "slides/intro-03-what-makes-a-model.html#a-model-workflow-3",
    "title": "3 - What makes a model?",
    "section": "A model workflow   ",
    "text": "A model workflow   \n\ntree_spec &lt;-\n  decision_tree() %&gt;% \n  set_mode(\"censored regression\")\n\nworkflow(event_time ~ ., tree_spec) %&gt;% \n  fit(data = cat_train) \n#&gt; â•â• Workflow [trained] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n#&gt; Preprocessor: Formula\n#&gt; Model: decision_tree()\n#&gt; \n#&gt; â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#&gt; event_time ~ .\n#&gt; \n#&gt; â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#&gt; $rpart\n#&gt; n= 1805 \n#&gt; \n#&gt; node), split, n, deviance, yval\n#&gt;       * denotes terminal node\n#&gt; \n#&gt; 1) root 1805 2025.6490 1.0000000  \n#&gt;   2) neutered=no,unknown 724  601.9346 0.5563459 *\n#&gt;   3) neutered=yes 1081 1309.8090 1.2024000  \n#&gt;     6) intake_condition=ill_mild,ill_moderatete,normal,under_age_or_weight,other 934 1067.3560 1.1130980 *\n#&gt;     7) intake_condition=feral,fractious 147  186.0952 2.4153980 *\n#&gt; \n#&gt; $survfit\n#&gt; \n#&gt; Call: prodlim::prodlim(formula = form, data = data)\n#&gt; \n#&gt; \n#&gt; \n#&gt; Right-censored response of a survival model\n#&gt; \n#&gt; No.Observations: 1805 \n#&gt; \n#&gt; Pattern:\n#&gt;                 Freq\n#&gt;  event          1134\n#&gt;  right.censored 671 \n#&gt; \n#&gt; $levels\n#&gt; [1] \"0.556345939526914\" \"1.11309762791995\"  \"2.41539768185841\" \n#&gt; \n#&gt; attr(,\"class\")\n#&gt; [1] \"pecRpart\""
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#your-turn-2",
    "href": "slides/intro-03-what-makes-a-model.html#your-turn-2",
    "title": "3 - What makes a model?",
    "section": "Your turn",
    "text": "Your turn\n\nMake a workflow with your own model of choice.\n\nExtension/Challenge: Other than formulas, what kinds of preprocessors are supported?\n\n\n\nâˆ’+\n05:00"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#predict-with-your-model",
    "href": "slides/intro-03-what-makes-a-model.html#predict-with-your-model",
    "title": "3 - What makes a model?",
    "section": "Predict with your model   ",
    "text": "Predict with your model   \nHow do you use your new tree_fit model?\n\ntree_spec &lt;-\n  decision_tree() %&gt;% \n  set_mode(\"censored regression\")\n\ntree_fit &lt;-\n  workflow(event_time ~ ., tree_spec) %&gt;% \n  fit(data = cat_train)"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#your-turn-3",
    "href": "slides/intro-03-what-makes-a-model.html#your-turn-3",
    "title": "3 - What makes a model?",
    "section": "Your turn",
    "text": "Your turn\n\nRun:\naugment(tree_fit, new_data = cat_test)\nWhat do you get?\n\n\n\nâˆ’+\n03:00"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#your-turn-4",
    "href": "slides/intro-03-what-makes-a-model.html#your-turn-4",
    "title": "3 - What makes a model?",
    "section": "Your turn",
    "text": "Your turn\n\nRun:\naugment(tree_fit, new_data = cat_test)\nWhat do you get?\n\n\n\nâˆ’+\n03:00"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#understand-your-model",
    "href": "slides/intro-03-what-makes-a-model.html#understand-your-model",
    "title": "3 - What makes a model?",
    "section": "Understand your model  ",
    "text": "Understand your model  \nHow do you understand your new tree_fit model?"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#understand-your-model-1",
    "href": "slides/intro-03-what-makes-a-model.html#understand-your-model-1",
    "title": "3 - What makes a model?",
    "section": "Understand your model  ",
    "text": "Understand your model  \nHow do you understand your new tree_fit model?\n\nlibrary(rpart.plot)\ntree_fit %&gt;%\n  extract_fit_engine() %&gt;%\n  rpart.plot(roundint = FALSE)\n\nYou can extract_*() several components of your fitted workflow.\n\nâš ï¸ Never predict() with any extracted components!\n\nroundint = FALSE is only to quiet a warning"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#understand-your-model-2",
    "href": "slides/intro-03-what-makes-a-model.html#understand-your-model-2",
    "title": "3 - What makes a model?",
    "section": "Understand your model  ",
    "text": "Understand your model  \nHow do you understand your new tree_fit model?\n\nYou can use your fitted workflow for model and/or prediction explanations:\n\n\n\noverall variable importance, such as with the vip package\n\n\n\n\nflexible model explainers, such as with the DALEXtra package\n\n\n\nLearn more at https://www.tmwr.org/explain.html"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#your-turn-5",
    "href": "slides/intro-03-what-makes-a-model.html#your-turn-5",
    "title": "3 - What makes a model?",
    "section": "Your turn",
    "text": "Your turn\n\n\nExtract the model engine object from your fitted workflow and check it out.\n\n\n\nâˆ’+\n05:00\n\n\n\n\nAfterward, ask what kind of object people got from the extraction, and what they did with it (e.g.Â give it to summary(), plot(), broom::tidy() ). Live code along"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#the-whole-game---status-update",
    "href": "slides/intro-03-what-makes-a-model.html#the-whole-game---status-update",
    "title": "3 - What makes a model?",
    "section": "The whole game - status update",
    "text": "The whole game - status update\n\n\nStress that fitting a model on the entire training set was only for illustrating how to fit a model\n\n\n\n\nhttps://workshops.tidymodels.org"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#looking-at-predictions",
    "href": "slides/intro-04-evaluating-models.html#looking-at-predictions",
    "title": "4 - Evaluating models",
    "section": "Looking at predictions",
    "text": "Looking at predictions\n\naugment(taxi_fit, new_data = taxi_train) %&gt;%\n  relocate(tip, .pred_class, .pred_yes, .pred_no)\n#&gt; # A tibble: 8,000 Ã— 10\n#&gt;    tip   .pred_class .pred_yes .pred_no distance company local dow   month  hour\n#&gt;    &lt;fct&gt; &lt;fct&gt;           &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;   &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt;\n#&gt;  1 yes   yes             0.967   0.0333    17.2  Chicagâ€¦ no    Thu   Feb      16\n#&gt;  2 yes   yes             0.935   0.0646     0.88 City Sâ€¦ yes   Thu   Mar       8\n#&gt;  3 yes   yes             0.967   0.0333    18.1  other   no    Mon   Feb      18\n#&gt;  4 yes   yes             0.949   0.0507    12.2  Chicagâ€¦ no    Sun   Mar      21\n#&gt;  5 yes   yes             0.821   0.179      0.94 Sun Taâ€¦ yes   Sat   Apr      23\n#&gt;  6 yes   yes             0.967   0.0333    17.5  Flash â€¦ no    Fri   Mar      12\n#&gt;  7 yes   yes             0.967   0.0333    17.7  other   no    Sun   Jan       6\n#&gt;  8 yes   yes             0.938   0.0616     1.85 Taxicaâ€¦ no    Fri   Apr      12\n#&gt;  9 yes   yes             0.938   0.0616     0.53 Sun Taâ€¦ no    Tue   Mar      18\n#&gt; 10 yes   yes             0.931   0.0694     6.65 Taxicaâ€¦ no    Sun   Apr      11\n#&gt; # â„¹ 7,990 more rows"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#confusion-matrix",
    "href": "slides/intro-04-evaluating-models.html#confusion-matrix",
    "title": "4 - Evaluating models",
    "section": "Confusion matrix ",
    "text": "Confusion matrix"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#confusion-matrix-1",
    "href": "slides/intro-04-evaluating-models.html#confusion-matrix-1",
    "title": "4 - Evaluating models",
    "section": "Confusion matrix ",
    "text": "Confusion matrix \n\naugment(taxi_fit, new_data = taxi_train) %&gt;%\n  conf_mat(truth = tip, estimate = .pred_class)\n#&gt;           Truth\n#&gt; Prediction  yes   no\n#&gt;        yes 7341  536\n#&gt;        no    43   80"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#confusion-matrix-2",
    "href": "slides/intro-04-evaluating-models.html#confusion-matrix-2",
    "title": "4 - Evaluating models",
    "section": "Confusion matrix ",
    "text": "Confusion matrix \n\naugment(taxi_fit, new_data = taxi_train) %&gt;%\n  conf_mat(truth = tip, estimate = .pred_class) %&gt;%\n  autoplot(type = \"heatmap\")"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#metrics-for-model-performance",
    "href": "slides/intro-04-evaluating-models.html#metrics-for-model-performance",
    "title": "4 - Evaluating models",
    "section": "Metrics for model performance ",
    "text": "Metrics for model performance \n\n\n\naugment(taxi_fit, new_data = taxi_train) %&gt;%\n  accuracy(truth = tip, estimate = .pred_class)\n#&gt; # A tibble: 1 Ã— 3\n#&gt;   .metric  .estimator .estimate\n#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 accuracy binary         0.928"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#dangers-of-accuracy",
    "href": "slides/intro-04-evaluating-models.html#dangers-of-accuracy",
    "title": "4 - Evaluating models",
    "section": "Dangers of accuracy ",
    "text": "Dangers of accuracy \nWe need to be careful of using accuracy() since it can give â€œgoodâ€ performance by only predicting one way with imbalanced data\n\naugment(taxi_fit, new_data = taxi_train) %&gt;%\n  mutate(.pred_class = factor(\"yes\", levels = c(\"yes\", \"no\"))) %&gt;%\n  accuracy(truth = tip, estimate = .pred_class)\n#&gt; # A tibble: 1 Ã— 3\n#&gt;   .metric  .estimator .estimate\n#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 accuracy binary         0.923"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#metrics-for-model-performance-1",
    "href": "slides/intro-04-evaluating-models.html#metrics-for-model-performance-1",
    "title": "4 - Evaluating models",
    "section": "Metrics for model performance ",
    "text": "Metrics for model performance \n\n\n\naugment(taxi_fit, new_data = taxi_train) %&gt;%\n  sensitivity(truth = tip, estimate = .pred_class)\n#&gt; # A tibble: 1 Ã— 3\n#&gt;   .metric     .estimator .estimate\n#&gt;   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 sensitivity binary         0.994"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#metrics-for-model-performance-2",
    "href": "slides/intro-04-evaluating-models.html#metrics-for-model-performance-2",
    "title": "4 - Evaluating models",
    "section": "Metrics for model performance ",
    "text": "Metrics for model performance \n\n\n\naugment(taxi_fit, new_data = taxi_train) %&gt;%\n  sensitivity(truth = tip, estimate = .pred_class)\n#&gt; # A tibble: 1 Ã— 3\n#&gt;   .metric     .estimator .estimate\n#&gt;   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 sensitivity binary         0.994\n\n\n\naugment(taxi_fit, new_data = taxi_train) %&gt;%\n  specificity(truth = tip, estimate = .pred_class)\n#&gt; # A tibble: 1 Ã— 3\n#&gt;   .metric     .estimator .estimate\n#&gt;   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 specificity binary         0.130"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#metrics-for-model-performance-3",
    "href": "slides/intro-04-evaluating-models.html#metrics-for-model-performance-3",
    "title": "4 - Evaluating models",
    "section": "Metrics for model performance ",
    "text": "Metrics for model performance \nWe can use metric_set() to combine multiple calculations into one\n\ntaxi_metrics &lt;- metric_set(accuracy, specificity, sensitivity)\n\naugment(taxi_fit, new_data = taxi_train) %&gt;%\n  taxi_metrics(truth = tip, estimate = .pred_class)\n#&gt; # A tibble: 3 Ã— 3\n#&gt;   .metric     .estimator .estimate\n#&gt;   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 accuracy    binary         0.928\n#&gt; 2 specificity binary         0.130\n#&gt; 3 sensitivity binary         0.994"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#metrics-for-model-performance-4",
    "href": "slides/intro-04-evaluating-models.html#metrics-for-model-performance-4",
    "title": "4 - Evaluating models",
    "section": "Metrics for model performance ",
    "text": "Metrics for model performance \n\ntaxi_metrics &lt;- metric_set(accuracy, specificity, sensitivity)\n\naugment(taxi_fit, new_data = taxi_train) %&gt;%\n  group_by(local) %&gt;%\n  taxi_metrics(truth = tip, estimate = .pred_class)\n#&gt; # A tibble: 6 Ã— 4\n#&gt;   local .metric     .estimator .estimate\n#&gt;   &lt;fct&gt; &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 yes   accuracy    binary         0.898\n#&gt; 2 no    accuracy    binary         0.935\n#&gt; 3 yes   specificity binary         0.169\n#&gt; 4 no    specificity binary         0.116\n#&gt; 5 yes   sensitivity binary         0.987\n#&gt; 6 no    sensitivity binary         0.996"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#two-class-data",
    "href": "slides/intro-04-evaluating-models.html#two-class-data",
    "title": "4 - Evaluating models",
    "section": "Two class data",
    "text": "Two class data\nThese metrics assume that we know the threshold for converting â€œsoftâ€ probability predictions into â€œhardâ€ class predictions.\n\nIs a 50% threshold good?\nWhat happens if we say that we need to be 80% sure to declare an event?\n\nsensitivity â¬‡ï¸, specificity â¬†ï¸\n\n\n\nWhat happens for a 20% threshold?\n\nsensitivity â¬†ï¸, specificity â¬‡ï¸"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#varying-the-threshold",
    "href": "slides/intro-04-evaluating-models.html#varying-the-threshold",
    "title": "4 - Evaluating models",
    "section": "Varying the threshold",
    "text": "Varying the threshold"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#roc-curves",
    "href": "slides/intro-04-evaluating-models.html#roc-curves",
    "title": "4 - Evaluating models",
    "section": "ROC curves",
    "text": "ROC curves\nTo make an ROC (receiver operator characteristic) curve, we:\n\ncalculate the sensitivity and specificity for all possible thresholds\nplot false positive rate (x-axis) versus true positive rate (y-axis)\n\ngiven that sensitivity is the true positive rate, and specificity is the true negative rate. Hence 1 - specificity is the false positive rate.\n\nWe can use the area under the ROC curve as a classification metric:\n\nROC AUC = 1 ğŸ’¯\nROC AUC = 1/2 ğŸ˜¢\n\n\nROC curves are insensitive to class imbalance."
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#roc-curves-1",
    "href": "slides/intro-04-evaluating-models.html#roc-curves-1",
    "title": "4 - Evaluating models",
    "section": "ROC curves ",
    "text": "ROC curves \n\n# Assumes _first_ factor level is event; there are options to change that\naugment(taxi_fit, new_data = taxi_train) %&gt;% \n  roc_curve(truth = tip, .pred_yes) %&gt;%\n  slice(1, 20, 50)\n#&gt; # A tibble: 3 Ã— 3\n#&gt;   .threshold specificity sensitivity\n#&gt;        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1   -Inf           0         1      \n#&gt; 2      0.783       0.209     0.981  \n#&gt; 3      1           1         0.00135\n\naugment(taxi_fit, new_data = taxi_train) %&gt;% \n  roc_auc(truth = tip, .pred_yes)\n#&gt; # A tibble: 1 Ã— 3\n#&gt;   .metric .estimator .estimate\n#&gt;   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 roc_auc binary         0.691"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#roc-curve-plot",
    "href": "slides/intro-04-evaluating-models.html#roc-curve-plot",
    "title": "4 - Evaluating models",
    "section": "ROC curve plot ",
    "text": "ROC curve plot \n\n\naugment(taxi_fit, new_data = taxi_train) %&gt;% \n  roc_curve(truth = tip, .pred_yes) %&gt;%\n  autoplot()"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#your-turn",
    "href": "slides/intro-04-evaluating-models.html#your-turn",
    "title": "4 - Evaluating models",
    "section": "Your turn",
    "text": "Your turn\n\nCompute and plot an ROC curve for your current model.\nWhat data are being used for this ROC curve plot?\n\n\n\nâˆ’+\n05:00"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#dangers-of-overfitting-1",
    "href": "slides/intro-04-evaluating-models.html#dangers-of-overfitting-1",
    "title": "4 - Evaluating models",
    "section": "Dangers of overfitting âš ï¸",
    "text": "Dangers of overfitting âš ï¸"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#dangers-of-overfitting-2",
    "href": "slides/intro-04-evaluating-models.html#dangers-of-overfitting-2",
    "title": "4 - Evaluating models",
    "section": "Dangers of overfitting âš ï¸",
    "text": "Dangers of overfitting âš ï¸"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#dangers-of-overfitting-3",
    "href": "slides/intro-04-evaluating-models.html#dangers-of-overfitting-3",
    "title": "4 - Evaluating models",
    "section": "Dangers of overfitting âš ï¸ ",
    "text": "Dangers of overfitting âš ï¸ \n\ntaxi_fit %&gt;%\n  augment(taxi_train)\n#&gt; # A tibble: 8,000 Ã— 10\n#&gt;    .pred_class .pred_yes .pred_no tip   distance company local dow   month  hour\n#&gt;    &lt;fct&gt;           &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt; &lt;fct&gt;   &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt;\n#&gt;  1 yes             0.967   0.0333 yes      17.2  Chicagâ€¦ no    Thu   Feb      16\n#&gt;  2 yes             0.935   0.0646 yes       0.88 City Sâ€¦ yes   Thu   Mar       8\n#&gt;  3 yes             0.967   0.0333 yes      18.1  other   no    Mon   Feb      18\n#&gt;  4 yes             0.949   0.0507 yes      12.2  Chicagâ€¦ no    Sun   Mar      21\n#&gt;  5 yes             0.821   0.179  yes       0.94 Sun Taâ€¦ yes   Sat   Apr      23\n#&gt;  6 yes             0.967   0.0333 yes      17.5  Flash â€¦ no    Fri   Mar      12\n#&gt;  7 yes             0.967   0.0333 yes      17.7  other   no    Sun   Jan       6\n#&gt;  8 yes             0.938   0.0616 yes       1.85 Taxicaâ€¦ no    Fri   Apr      12\n#&gt;  9 yes             0.938   0.0616 yes       0.53 Sun Taâ€¦ no    Tue   Mar      18\n#&gt; 10 yes             0.931   0.0694 yes       6.65 Taxicaâ€¦ no    Sun   Apr      11\n#&gt; # â„¹ 7,990 more rows\n\nWe call this â€œresubstitutionâ€ or â€œrepredicting the training setâ€"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#dangers-of-overfitting-4",
    "href": "slides/intro-04-evaluating-models.html#dangers-of-overfitting-4",
    "title": "4 - Evaluating models",
    "section": "Dangers of overfitting âš ï¸ ",
    "text": "Dangers of overfitting âš ï¸ \n\ntaxi_fit %&gt;%\n  augment(taxi_train) %&gt;%\n  accuracy(tip, .pred_class)\n#&gt; # A tibble: 1 Ã— 3\n#&gt;   .metric  .estimator .estimate\n#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 accuracy binary         0.928\n\nWe call this a â€œresubstitution estimateâ€"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#dangers-of-overfitting-5",
    "href": "slides/intro-04-evaluating-models.html#dangers-of-overfitting-5",
    "title": "4 - Evaluating models",
    "section": "Dangers of overfitting âš ï¸ ",
    "text": "Dangers of overfitting âš ï¸ \n\n\n\ntaxi_fit %&gt;%\n  augment(taxi_train) %&gt;%\n  accuracy(tip, .pred_class)\n#&gt; # A tibble: 1 Ã— 3\n#&gt;   .metric  .estimator .estimate\n#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 accuracy binary         0.928"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#dangers-of-overfitting-6",
    "href": "slides/intro-04-evaluating-models.html#dangers-of-overfitting-6",
    "title": "4 - Evaluating models",
    "section": "Dangers of overfitting âš ï¸ ",
    "text": "Dangers of overfitting âš ï¸ \n\n\n\ntaxi_fit %&gt;%\n  augment(taxi_train) %&gt;%\n  accuracy(tip, .pred_class)\n#&gt; # A tibble: 1 Ã— 3\n#&gt;   .metric  .estimator .estimate\n#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 accuracy binary         0.928\n\n\n\ntaxi_fit %&gt;%\n  augment(taxi_test) %&gt;%\n  accuracy(tip, .pred_class)\n#&gt; # A tibble: 1 Ã— 3\n#&gt;   .metric  .estimator .estimate\n#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 accuracy binary         0.908\n\n\n\n\nâš ï¸ Remember that weâ€™re demonstrating overfitting\n\n\nâš ï¸ Donâ€™t use the test set until the end of your modeling analysis"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#your-turn-1",
    "href": "slides/intro-04-evaluating-models.html#your-turn-1",
    "title": "4 - Evaluating models",
    "section": "Your turn",
    "text": "Your turn\n\nUse augment() and a metric function to compute a classification metric like brier_class().\nCompute the metrics for both training and testing data to demonstrate overfitting!\nNotice the evidence of overfitting! âš ï¸\n\n\n\nâˆ’+\n05:00"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#dangers-of-overfitting-7",
    "href": "slides/intro-04-evaluating-models.html#dangers-of-overfitting-7",
    "title": "4 - Evaluating models",
    "section": "Dangers of overfitting âš ï¸ ",
    "text": "Dangers of overfitting âš ï¸ \n\n\n\ntaxi_fit %&gt;%\n  augment(taxi_train) %&gt;%\n  brier_class(tip, .pred_yes)\n#&gt; # A tibble: 1 Ã— 3\n#&gt;   .metric     .estimator .estimate\n#&gt;   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 brier_class binary        0.0632\n\n\n\ntaxi_fit %&gt;%\n  augment(taxi_test) %&gt;%\n  brier_class(tip, .pred_yes)\n#&gt; # A tibble: 1 Ã— 3\n#&gt;   .metric     .estimator .estimate\n#&gt;   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 brier_class binary        0.0782\n\n\n\n\nWhat if we want to compare more models?\n\n\nAnd/or more model configurations?\n\n\nAnd we want to understand if these are important differences?"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#cross-validation",
    "href": "slides/intro-04-evaluating-models.html#cross-validation",
    "title": "4 - Evaluating models",
    "section": "Cross-validation",
    "text": "Cross-validation"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#cross-validation-1",
    "href": "slides/intro-04-evaluating-models.html#cross-validation-1",
    "title": "4 - Evaluating models",
    "section": "Cross-validation",
    "text": "Cross-validation"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#your-turn-2",
    "href": "slides/intro-04-evaluating-models.html#your-turn-2",
    "title": "4 - Evaluating models",
    "section": "Your turn",
    "text": "Your turn\n\nIf we use 10 folds, what percent of the training data\n\nends up in analysis\nends up in assessment\n\nfor each fold?\n\n\n\n\nâˆ’+\n03:00"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#cross-validation-2",
    "href": "slides/intro-04-evaluating-models.html#cross-validation-2",
    "title": "4 - Evaluating models",
    "section": "Cross-validation ",
    "text": "Cross-validation \n\nvfold_cv(taxi_train) # v = 10 is default\n#&gt; #  10-fold cross-validation \n#&gt; # A tibble: 10 Ã— 2\n#&gt;    splits             id    \n#&gt;    &lt;list&gt;             &lt;chr&gt; \n#&gt;  1 &lt;split [7200/800]&gt; Fold01\n#&gt;  2 &lt;split [7200/800]&gt; Fold02\n#&gt;  3 &lt;split [7200/800]&gt; Fold03\n#&gt;  4 &lt;split [7200/800]&gt; Fold04\n#&gt;  5 &lt;split [7200/800]&gt; Fold05\n#&gt;  6 &lt;split [7200/800]&gt; Fold06\n#&gt;  7 &lt;split [7200/800]&gt; Fold07\n#&gt;  8 &lt;split [7200/800]&gt; Fold08\n#&gt;  9 &lt;split [7200/800]&gt; Fold09\n#&gt; 10 &lt;split [7200/800]&gt; Fold10"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#cross-validation-3",
    "href": "slides/intro-04-evaluating-models.html#cross-validation-3",
    "title": "4 - Evaluating models",
    "section": "Cross-validation ",
    "text": "Cross-validation \nWhat is in this?\n\ntaxi_folds &lt;- vfold_cv(taxi_train)\ntaxi_folds$splits[1:3]\n#&gt; [[1]]\n#&gt; &lt;Analysis/Assess/Total&gt;\n#&gt; &lt;7200/800/8000&gt;\n#&gt; \n#&gt; [[2]]\n#&gt; &lt;Analysis/Assess/Total&gt;\n#&gt; &lt;7200/800/8000&gt;\n#&gt; \n#&gt; [[3]]\n#&gt; &lt;Analysis/Assess/Total&gt;\n#&gt; &lt;7200/800/8000&gt;\n\n\nTalk about a list column, storing non-atomic types in dataframe"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#cross-validation-4",
    "href": "slides/intro-04-evaluating-models.html#cross-validation-4",
    "title": "4 - Evaluating models",
    "section": "Cross-validation ",
    "text": "Cross-validation \n\nvfold_cv(taxi_train, v = 5)\n#&gt; #  5-fold cross-validation \n#&gt; # A tibble: 5 Ã— 2\n#&gt;   splits              id   \n#&gt;   &lt;list&gt;              &lt;chr&gt;\n#&gt; 1 &lt;split [6400/1600]&gt; Fold1\n#&gt; 2 &lt;split [6400/1600]&gt; Fold2\n#&gt; 3 &lt;split [6400/1600]&gt; Fold3\n#&gt; 4 &lt;split [6400/1600]&gt; Fold4\n#&gt; 5 &lt;split [6400/1600]&gt; Fold5"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#cross-validation-5",
    "href": "slides/intro-04-evaluating-models.html#cross-validation-5",
    "title": "4 - Evaluating models",
    "section": "Cross-validation ",
    "text": "Cross-validation \n\nvfold_cv(taxi_train, strata = tip)\n#&gt; #  10-fold cross-validation using stratification \n#&gt; # A tibble: 10 Ã— 2\n#&gt;    splits             id    \n#&gt;    &lt;list&gt;             &lt;chr&gt; \n#&gt;  1 &lt;split [7200/800]&gt; Fold01\n#&gt;  2 &lt;split [7200/800]&gt; Fold02\n#&gt;  3 &lt;split [7200/800]&gt; Fold03\n#&gt;  4 &lt;split [7200/800]&gt; Fold04\n#&gt;  5 &lt;split [7200/800]&gt; Fold05\n#&gt;  6 &lt;split [7200/800]&gt; Fold06\n#&gt;  7 &lt;split [7200/800]&gt; Fold07\n#&gt;  8 &lt;split [7200/800]&gt; Fold08\n#&gt;  9 &lt;split [7200/800]&gt; Fold09\n#&gt; 10 &lt;split [7200/800]&gt; Fold10\n\n\nStratification often helps, with very little downside"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#cross-validation-6",
    "href": "slides/intro-04-evaluating-models.html#cross-validation-6",
    "title": "4 - Evaluating models",
    "section": "Cross-validation ",
    "text": "Cross-validation \nWeâ€™ll use this setup:\n\nset.seed(123)\ntaxi_folds &lt;- vfold_cv(taxi_train, v = 10, strata = tip)\ntaxi_folds\n#&gt; #  10-fold cross-validation using stratification \n#&gt; # A tibble: 10 Ã— 2\n#&gt;    splits             id    \n#&gt;    &lt;list&gt;             &lt;chr&gt; \n#&gt;  1 &lt;split [7200/800]&gt; Fold01\n#&gt;  2 &lt;split [7200/800]&gt; Fold02\n#&gt;  3 &lt;split [7200/800]&gt; Fold03\n#&gt;  4 &lt;split [7200/800]&gt; Fold04\n#&gt;  5 &lt;split [7200/800]&gt; Fold05\n#&gt;  6 &lt;split [7200/800]&gt; Fold06\n#&gt;  7 &lt;split [7200/800]&gt; Fold07\n#&gt;  8 &lt;split [7200/800]&gt; Fold08\n#&gt;  9 &lt;split [7200/800]&gt; Fold09\n#&gt; 10 &lt;split [7200/800]&gt; Fold10\n\n\nSet the seed when creating resamples"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#fit-our-model-to-the-resamples",
    "href": "slides/intro-04-evaluating-models.html#fit-our-model-to-the-resamples",
    "title": "4 - Evaluating models",
    "section": "Fit our model to the resamples",
    "text": "Fit our model to the resamples\n\ntaxi_res &lt;- fit_resamples(taxi_wflow, taxi_folds)\ntaxi_res\n#&gt; # Resampling results\n#&gt; # 10-fold cross-validation using stratification \n#&gt; # A tibble: 10 Ã— 4\n#&gt;    splits             id     .metrics         .notes          \n#&gt;    &lt;list&gt;             &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;          \n#&gt;  1 &lt;split [7200/800]&gt; Fold01 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt;\n#&gt;  2 &lt;split [7200/800]&gt; Fold02 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt;\n#&gt;  3 &lt;split [7200/800]&gt; Fold03 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt;\n#&gt;  4 &lt;split [7200/800]&gt; Fold04 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt;\n#&gt;  5 &lt;split [7200/800]&gt; Fold05 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt;\n#&gt;  6 &lt;split [7200/800]&gt; Fold06 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt;\n#&gt;  7 &lt;split [7200/800]&gt; Fold07 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt;\n#&gt;  8 &lt;split [7200/800]&gt; Fold08 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt;\n#&gt;  9 &lt;split [7200/800]&gt; Fold09 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt;\n#&gt; 10 &lt;split [7200/800]&gt; Fold10 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt;"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#evaluating-model-performance",
    "href": "slides/intro-04-evaluating-models.html#evaluating-model-performance",
    "title": "4 - Evaluating models",
    "section": "Evaluating model performance ",
    "text": "Evaluating model performance \n\ntaxi_res %&gt;%\n  collect_metrics()\n#&gt; # A tibble: 3 Ã— 6\n#&gt;   .metric     .estimator   mean     n std_err .config             \n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n#&gt; 1 accuracy    binary     0.915     10 0.00309 Preprocessor1_Model1\n#&gt; 2 brier_class binary     0.0721    10 0.00245 Preprocessor1_Model1\n#&gt; 3 roc_auc     binary     0.624     10 0.0105  Preprocessor1_Model1\n\n\ncollect_metrics() is one of a suite of collect_*() functions that can be used to work with columns of tuning results. Most columns in a tuning result prefixed with . have a corresponding collect_*() function with options for common summaries.\n\n\nWe can reliably measure performance using only the training data ğŸ‰"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#comparing-metrics",
    "href": "slides/intro-04-evaluating-models.html#comparing-metrics",
    "title": "4 - Evaluating models",
    "section": "Comparing metrics ",
    "text": "Comparing metrics \nHow do the metrics from resampling compare to the metrics from training and testing?\n\n\n\ntaxi_res %&gt;%\n  collect_metrics() %&gt;% \n  select(.metric, mean, n)\n#&gt; # A tibble: 3 Ã— 3\n#&gt;   .metric       mean     n\n#&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 accuracy    0.915     10\n#&gt; 2 brier_class 0.0721    10\n#&gt; 3 roc_auc     0.624     10\n\n\nThe ROC AUC previously was\n\n0.69 for the training set\n0.64 for test set\n\n\n\n\nRemember that:\nâš ï¸ the training set gives you overly optimistic metrics\nâš ï¸ the test set is precious"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#evaluating-model-performance-1",
    "href": "slides/intro-04-evaluating-models.html#evaluating-model-performance-1",
    "title": "4 - Evaluating models",
    "section": "Evaluating model performance ",
    "text": "Evaluating model performance \n\n# Save the assessment set results\nctrl_taxi &lt;- control_resamples(save_pred = TRUE)\ntaxi_res &lt;- fit_resamples(taxi_wflow, taxi_folds, control = ctrl_taxi)\n\ntaxi_res\n#&gt; # Resampling results\n#&gt; # 10-fold cross-validation using stratification \n#&gt; # A tibble: 10 Ã— 5\n#&gt;    splits             id     .metrics         .notes           .predictions\n#&gt;    &lt;list&gt;             &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;           &lt;list&gt;      \n#&gt;  1 &lt;split [7200/800]&gt; Fold01 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n#&gt;  2 &lt;split [7200/800]&gt; Fold02 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n#&gt;  3 &lt;split [7200/800]&gt; Fold03 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n#&gt;  4 &lt;split [7200/800]&gt; Fold04 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n#&gt;  5 &lt;split [7200/800]&gt; Fold05 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n#&gt;  6 &lt;split [7200/800]&gt; Fold06 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n#&gt;  7 &lt;split [7200/800]&gt; Fold07 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n#&gt;  8 &lt;split [7200/800]&gt; Fold08 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n#&gt;  9 &lt;split [7200/800]&gt; Fold09 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n#&gt; 10 &lt;split [7200/800]&gt; Fold10 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#evaluating-model-performance-2",
    "href": "slides/intro-04-evaluating-models.html#evaluating-model-performance-2",
    "title": "4 - Evaluating models",
    "section": "Evaluating model performance ",
    "text": "Evaluating model performance \n\n# Save the assessment set results\ntaxi_preds &lt;- collect_predictions(taxi_res)\ntaxi_preds\n#&gt; # A tibble: 8,000 Ã— 7\n#&gt;    .pred_class .pred_yes .pred_no id      .row tip   .config             \n#&gt;    &lt;fct&gt;           &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;  &lt;int&gt; &lt;fct&gt; &lt;chr&gt;               \n#&gt;  1 yes             0.938   0.0615 Fold01    14 yes   Preprocessor1_Model1\n#&gt;  2 yes             0.946   0.0544 Fold01    19 yes   Preprocessor1_Model1\n#&gt;  3 yes             0.973   0.0269 Fold01    33 yes   Preprocessor1_Model1\n#&gt;  4 yes             0.903   0.0971 Fold01    43 yes   Preprocessor1_Model1\n#&gt;  5 yes             0.973   0.0269 Fold01    74 yes   Preprocessor1_Model1\n#&gt;  6 yes             0.903   0.0971 Fold01   103 yes   Preprocessor1_Model1\n#&gt;  7 yes             0.915   0.0851 Fold01   104 no    Preprocessor1_Model1\n#&gt;  8 yes             0.903   0.0971 Fold01   124 yes   Preprocessor1_Model1\n#&gt;  9 yes             0.667   0.333  Fold01   126 yes   Preprocessor1_Model1\n#&gt; 10 yes             0.949   0.0510 Fold01   128 yes   Preprocessor1_Model1\n#&gt; # â„¹ 7,990 more rows"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#evaluating-model-performance-3",
    "href": "slides/intro-04-evaluating-models.html#evaluating-model-performance-3",
    "title": "4 - Evaluating models",
    "section": "Evaluating model performance ",
    "text": "Evaluating model performance \n\ntaxi_preds %&gt;% \n  group_by(id) %&gt;%\n  taxi_metrics(truth = tip, estimate = .pred_class)\n#&gt; # A tibble: 30 Ã— 4\n#&gt;    id     .metric  .estimator .estimate\n#&gt;    &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n#&gt;  1 Fold01 accuracy binary         0.905\n#&gt;  2 Fold02 accuracy binary         0.925\n#&gt;  3 Fold03 accuracy binary         0.926\n#&gt;  4 Fold04 accuracy binary         0.915\n#&gt;  5 Fold05 accuracy binary         0.902\n#&gt;  6 Fold06 accuracy binary         0.912\n#&gt;  7 Fold07 accuracy binary         0.906\n#&gt;  8 Fold08 accuracy binary         0.91 \n#&gt;  9 Fold09 accuracy binary         0.918\n#&gt; 10 Fold10 accuracy binary         0.931\n#&gt; # â„¹ 20 more rows"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#where-are-the-fitted-models",
    "href": "slides/intro-04-evaluating-models.html#where-are-the-fitted-models",
    "title": "4 - Evaluating models",
    "section": "Where are the fitted models? ",
    "text": "Where are the fitted models? \n\ntaxi_res\n#&gt; # Resampling results\n#&gt; # 10-fold cross-validation using stratification \n#&gt; # A tibble: 10 Ã— 5\n#&gt;    splits             id     .metrics         .notes           .predictions\n#&gt;    &lt;list&gt;             &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;           &lt;list&gt;      \n#&gt;  1 &lt;split [7200/800]&gt; Fold01 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n#&gt;  2 &lt;split [7200/800]&gt; Fold02 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n#&gt;  3 &lt;split [7200/800]&gt; Fold03 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n#&gt;  4 &lt;split [7200/800]&gt; Fold04 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n#&gt;  5 &lt;split [7200/800]&gt; Fold05 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n#&gt;  6 &lt;split [7200/800]&gt; Fold06 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n#&gt;  7 &lt;split [7200/800]&gt; Fold07 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n#&gt;  8 &lt;split [7200/800]&gt; Fold08 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n#&gt;  9 &lt;split [7200/800]&gt; Fold09 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n#&gt; 10 &lt;split [7200/800]&gt; Fold10 &lt;tibble [3 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;\n\n\nğŸ—‘ï¸"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#bootstrapping",
    "href": "slides/intro-04-evaluating-models.html#bootstrapping",
    "title": "4 - Evaluating models",
    "section": "Bootstrapping",
    "text": "Bootstrapping"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#bootstrapping-1",
    "href": "slides/intro-04-evaluating-models.html#bootstrapping-1",
    "title": "4 - Evaluating models",
    "section": "Bootstrapping ",
    "text": "Bootstrapping \n\nset.seed(3214)\nbootstraps(taxi_train)\n#&gt; # Bootstrap sampling \n#&gt; # A tibble: 25 Ã— 2\n#&gt;    splits              id         \n#&gt;    &lt;list&gt;              &lt;chr&gt;      \n#&gt;  1 &lt;split [8000/2902]&gt; Bootstrap01\n#&gt;  2 &lt;split [8000/2916]&gt; Bootstrap02\n#&gt;  3 &lt;split [8000/3004]&gt; Bootstrap03\n#&gt;  4 &lt;split [8000/2979]&gt; Bootstrap04\n#&gt;  5 &lt;split [8000/2961]&gt; Bootstrap05\n#&gt;  6 &lt;split [8000/2962]&gt; Bootstrap06\n#&gt;  7 &lt;split [8000/3026]&gt; Bootstrap07\n#&gt;  8 &lt;split [8000/2926]&gt; Bootstrap08\n#&gt;  9 &lt;split [8000/2972]&gt; Bootstrap09\n#&gt; 10 &lt;split [8000/2972]&gt; Bootstrap10\n#&gt; # â„¹ 15 more rows"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#the-whole-game---status-update",
    "href": "slides/intro-04-evaluating-models.html#the-whole-game---status-update",
    "title": "4 - Evaluating models",
    "section": "The whole game - status update",
    "text": "The whole game - status update"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#your-turn-3",
    "href": "slides/intro-04-evaluating-models.html#your-turn-3",
    "title": "4 - Evaluating models",
    "section": "Your turn",
    "text": "Your turn\n\nCreate:\n\nMonte Carlo Cross-Validation sets\nvalidation set\n\n(use the reference guide to find the functions)\nDonâ€™t forget to set a seed when you resample!\n\n\n\nâˆ’+\n05:00"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#monte-carlo-cross-validation",
    "href": "slides/intro-04-evaluating-models.html#monte-carlo-cross-validation",
    "title": "4 - Evaluating models",
    "section": "Monte Carlo Cross-Validation ",
    "text": "Monte Carlo Cross-Validation \n\nset.seed(322)\nmc_cv(taxi_train, times = 10)\n#&gt; # Monte Carlo cross-validation (0.75/0.25) with 10 resamples  \n#&gt; # A tibble: 10 Ã— 2\n#&gt;    splits              id        \n#&gt;    &lt;list&gt;              &lt;chr&gt;     \n#&gt;  1 &lt;split [6000/2000]&gt; Resample01\n#&gt;  2 &lt;split [6000/2000]&gt; Resample02\n#&gt;  3 &lt;split [6000/2000]&gt; Resample03\n#&gt;  4 &lt;split [6000/2000]&gt; Resample04\n#&gt;  5 &lt;split [6000/2000]&gt; Resample05\n#&gt;  6 &lt;split [6000/2000]&gt; Resample06\n#&gt;  7 &lt;split [6000/2000]&gt; Resample07\n#&gt;  8 &lt;split [6000/2000]&gt; Resample08\n#&gt;  9 &lt;split [6000/2000]&gt; Resample09\n#&gt; 10 &lt;split [6000/2000]&gt; Resample10"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#validation-set",
    "href": "slides/intro-04-evaluating-models.html#validation-set",
    "title": "4 - Evaluating models",
    "section": "Validation set ",
    "text": "Validation set \n\nset.seed(853)\ntaxi_val_split &lt;- initial_validation_split(taxi, strata = tip)\nvalidation_set(taxi_val_split)\n#&gt; # A tibble: 1 Ã— 2\n#&gt;   splits              id        \n#&gt;   &lt;list&gt;              &lt;chr&gt;     \n#&gt; 1 &lt;split [6000/2000]&gt; validation\n\n\nA validation set is just another type of resample"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#random-forest-1",
    "href": "slides/intro-04-evaluating-models.html#random-forest-1",
    "title": "4 - Evaluating models",
    "section": "Random forest ğŸŒ³ğŸŒ²ğŸŒ´ğŸŒµğŸŒ³ğŸŒ³ğŸŒ´ğŸŒ²ğŸŒµğŸŒ´ğŸŒ³ğŸŒµ",
    "text": "Random forest ğŸŒ³ğŸŒ²ğŸŒ´ğŸŒµğŸŒ³ğŸŒ³ğŸŒ´ğŸŒ²ğŸŒµğŸŒ´ğŸŒ³ğŸŒµ\n\nEnsemble many decision tree models\nAll the trees vote! ğŸ—³ï¸\nBootstrap aggregating + random predictor sampling\n\n\n\nOften works well without tuning hyperparameters (more on this in Advanced tidymodels!), as long as there are enough trees"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#create-a-random-forest-model",
    "href": "slides/intro-04-evaluating-models.html#create-a-random-forest-model",
    "title": "4 - Evaluating models",
    "section": "Create a random forest model ",
    "text": "Create a random forest model \n\nrf_spec &lt;- rand_forest(trees = 1000, mode = \"classification\")\nrf_spec\n#&gt; Random Forest Model Specification (classification)\n#&gt; \n#&gt; Main Arguments:\n#&gt;   trees = 1000\n#&gt; \n#&gt; Computational engine: ranger"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#create-a-random-forest-model-1",
    "href": "slides/intro-04-evaluating-models.html#create-a-random-forest-model-1",
    "title": "4 - Evaluating models",
    "section": "Create a random forest model ",
    "text": "Create a random forest model \n\nrf_wflow &lt;- workflow(tip ~ ., rf_spec)\nrf_wflow\n#&gt; â•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n#&gt; Preprocessor: Formula\n#&gt; Model: rand_forest()\n#&gt; \n#&gt; â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#&gt; tip ~ .\n#&gt; \n#&gt; â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#&gt; Random Forest Model Specification (classification)\n#&gt; \n#&gt; Main Arguments:\n#&gt;   trees = 1000\n#&gt; \n#&gt; Computational engine: ranger"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#your-turn-4",
    "href": "slides/intro-04-evaluating-models.html#your-turn-4",
    "title": "4 - Evaluating models",
    "section": "Your turn",
    "text": "Your turn\n\nUse fit_resamples() and rf_wflow to:\n\nkeep predictions\ncompute metrics\n\n\n\n\nâˆ’+\n08:00"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#evaluating-model-performance-4",
    "href": "slides/intro-04-evaluating-models.html#evaluating-model-performance-4",
    "title": "4 - Evaluating models",
    "section": "Evaluating model performance ",
    "text": "Evaluating model performance \n\nctrl_taxi &lt;- control_resamples(save_pred = TRUE)\n\n# Random forest uses random numbers so set the seed first\n\nset.seed(2)\nrf_res &lt;- fit_resamples(rf_wflow, taxi_folds, control = ctrl_taxi)\ncollect_metrics(rf_res)\n#&gt; # A tibble: 3 Ã— 6\n#&gt;   .metric     .estimator   mean     n std_err .config             \n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n#&gt; 1 accuracy    binary     0.923     10 0.00317 Preprocessor1_Model1\n#&gt; 2 brier_class binary     0.0706    10 0.00243 Preprocessor1_Model1\n#&gt; 3 roc_auc     binary     0.616     10 0.0147  Preprocessor1_Model1"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#the-whole-game---status-update-1",
    "href": "slides/intro-04-evaluating-models.html#the-whole-game---status-update-1",
    "title": "4 - Evaluating models",
    "section": "The whole game - status update",
    "text": "The whole game - status update"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#the-final-fit",
    "href": "slides/intro-04-evaluating-models.html#the-final-fit",
    "title": "4 - Evaluating models",
    "section": "The final fit ",
    "text": "The final fit \nSuppose that we are happy with our random forest model.\nLetâ€™s fit the model on the training set and verify our performance using the test set.\n\nWeâ€™ve shown you fit() and predict() (+ augment()) but there is a shortcut:\n\n# taxi_split has train + test info\nfinal_fit &lt;- last_fit(rf_wflow, taxi_split) \n\nfinal_fit\n#&gt; # Resampling results\n#&gt; # Manual resampling \n#&gt; # A tibble: 1 Ã— 6\n#&gt;   splits              id               .metrics .notes   .predictions .workflow \n#&gt;   &lt;list&gt;              &lt;chr&gt;            &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    \n#&gt; 1 &lt;split [8000/2000]&gt; train/test split &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#what-is-in-final_fit",
    "href": "slides/intro-04-evaluating-models.html#what-is-in-final_fit",
    "title": "4 - Evaluating models",
    "section": "What is in final_fit? ",
    "text": "What is in final_fit? \n\ncollect_metrics(final_fit)\n#&gt; # A tibble: 3 Ã— 4\n#&gt;   .metric     .estimator .estimate .config             \n#&gt;   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n#&gt; 1 accuracy    binary        0.914  Preprocessor1_Model1\n#&gt; 2 roc_auc     binary        0.638  Preprocessor1_Model1\n#&gt; 3 brier_class binary        0.0772 Preprocessor1_Model1\n\n\nThese are metrics computed with the test set"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#what-is-in-final_fit-1",
    "href": "slides/intro-04-evaluating-models.html#what-is-in-final_fit-1",
    "title": "4 - Evaluating models",
    "section": "What is in final_fit? ",
    "text": "What is in final_fit? \n\ncollect_predictions(final_fit)\n#&gt; # A tibble: 2,000 Ã— 7\n#&gt;    .pred_class .pred_yes .pred_no id                .row tip   .config          \n#&gt;    &lt;fct&gt;           &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;            &lt;int&gt; &lt;fct&gt; &lt;chr&gt;            \n#&gt;  1 yes             0.957   0.0426 train/test split     4 yes   Preprocessor1_Moâ€¦\n#&gt;  2 yes             0.938   0.0621 train/test split    10 yes   Preprocessor1_Moâ€¦\n#&gt;  3 yes             0.958   0.0416 train/test split    19 yes   Preprocessor1_Moâ€¦\n#&gt;  4 yes             0.894   0.106  train/test split    23 yes   Preprocessor1_Moâ€¦\n#&gt;  5 yes             0.943   0.0573 train/test split    28 yes   Preprocessor1_Moâ€¦\n#&gt;  6 yes             0.979   0.0213 train/test split    34 yes   Preprocessor1_Moâ€¦\n#&gt;  7 yes             0.954   0.0463 train/test split    35 yes   Preprocessor1_Moâ€¦\n#&gt;  8 yes             0.928   0.0722 train/test split    38 yes   Preprocessor1_Moâ€¦\n#&gt;  9 yes             0.985   0.0147 train/test split    40 yes   Preprocessor1_Moâ€¦\n#&gt; 10 yes             0.948   0.0523 train/test split    42 no    Preprocessor1_Moâ€¦\n#&gt; # â„¹ 1,990 more rows"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#what-is-in-final_fit-2",
    "href": "slides/intro-04-evaluating-models.html#what-is-in-final_fit-2",
    "title": "4 - Evaluating models",
    "section": "What is in final_fit? ",
    "text": "What is in final_fit? \n\nextract_workflow(final_fit)\n#&gt; â•â• Workflow [trained] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n#&gt; Preprocessor: Formula\n#&gt; Model: rand_forest()\n#&gt; \n#&gt; â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#&gt; tip ~ .\n#&gt; \n#&gt; â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#&gt; Ranger result\n#&gt; \n#&gt; Call:\n#&gt;  ranger::ranger(x = maybe_data_frame(x), y = y, num.trees = ~1000,      num.threads = 1, verbose = FALSE, seed = sample.int(10^5,          1), probability = TRUE) \n#&gt; \n#&gt; Type:                             Probability estimation \n#&gt; Number of trees:                  1000 \n#&gt; Sample size:                      8000 \n#&gt; Number of independent variables:  6 \n#&gt; Mtry:                             2 \n#&gt; Target node size:                 10 \n#&gt; Variable importance mode:         none \n#&gt; Splitrule:                        gini \n#&gt; OOB prediction error (Brier s.):  0.07069778\n\n\nUse this for prediction on new data, like for deploying"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#the-whole-game",
    "href": "slides/intro-04-evaluating-models.html#the-whole-game",
    "title": "4 - Evaluating models",
    "section": "The whole game",
    "text": "The whole game\n\n\n\n\nhttps://workshops.tidymodels.org"
  },
  {
    "objectID": "slides/intro-05-tuning-models.html#tuning-parameters",
    "href": "slides/intro-05-tuning-models.html#tuning-parameters",
    "title": "5 - Tuning models",
    "section": "Tuning parameters",
    "text": "Tuning parameters\nSome model or preprocessing parameters cannot be estimated directly from the data.\n\nSome examples:\n\nTree depth in decision trees\nNumber of neighbors in a K-nearest neighbor model"
  },
  {
    "objectID": "slides/intro-05-tuning-models.html#optimize-tuning-parameters",
    "href": "slides/intro-05-tuning-models.html#optimize-tuning-parameters",
    "title": "5 - Tuning models",
    "section": "Optimize tuning parameters",
    "text": "Optimize tuning parameters\n\nTry different values and measure their performance.\n\n\n\nFind good values for these parameters.\n\n\n\n\nOnce the value(s) of the parameter(s) are determined, a model can be finalized by fitting the model to the entire training set."
  },
  {
    "objectID": "slides/intro-05-tuning-models.html#optimize-tuning-parameters-1",
    "href": "slides/intro-05-tuning-models.html#optimize-tuning-parameters-1",
    "title": "5 - Tuning models",
    "section": "Optimize tuning parameters",
    "text": "Optimize tuning parameters\nThe main two strategies for optimization are:\n\n\nGrid search ğŸ’  which tests a pre-defined set of candidate values\nIterative search ğŸŒ€ which suggests/estimates new values of candidate parameters to evaluate"
  },
  {
    "objectID": "slides/intro-05-tuning-models.html#specifying-tuning-parameters",
    "href": "slides/intro-05-tuning-models.html#specifying-tuning-parameters",
    "title": "5 - Tuning models",
    "section": "Specifying tuning parameters",
    "text": "Specifying tuning parameters\nLetâ€™s take our previous random forest workflow and tag for tuning the minimum number of data points in each node:\n\nrf_spec &lt;- rand_forest(min_n = tune()) %&gt;% \n  set_mode(\"classification\")\n\nrf_wflow &lt;- workflow(tip ~ ., rf_spec)\nrf_wflow\n#&gt; â•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n#&gt; Preprocessor: Formula\n#&gt; Model: rand_forest()\n#&gt; \n#&gt; â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#&gt; tip ~ .\n#&gt; \n#&gt; â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#&gt; Random Forest Model Specification (classification)\n#&gt; \n#&gt; Main Arguments:\n#&gt;   min_n = tune()\n#&gt; \n#&gt; Computational engine: ranger"
  },
  {
    "objectID": "slides/intro-05-tuning-models.html#try-out-multiple-values",
    "href": "slides/intro-05-tuning-models.html#try-out-multiple-values",
    "title": "5 - Tuning models",
    "section": "Try out multiple values",
    "text": "Try out multiple values\ntune_grid() works similar to fit_resamples() but covers multiple parameter values:\n\nset.seed(22)\nrf_res &lt;- tune_grid(\n  rf_wflow,\n  taxi_folds,\n  grid = 5\n)"
  },
  {
    "objectID": "slides/intro-05-tuning-models.html#compare-results",
    "href": "slides/intro-05-tuning-models.html#compare-results",
    "title": "5 - Tuning models",
    "section": "Compare results",
    "text": "Compare results\nInspecting results and selecting the best-performing hyperparameter(s):\n\nshow_best(rf_res)\n#&gt; # A tibble: 5 Ã— 7\n#&gt;   min_n .metric .estimator  mean     n std_err .config             \n#&gt;   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n#&gt; 1    33 roc_auc binary     0.623    10  0.0149 Preprocessor1_Model1\n#&gt; 2    31 roc_auc binary     0.622    10  0.0154 Preprocessor1_Model3\n#&gt; 3    21 roc_auc binary     0.620    10  0.0149 Preprocessor1_Model4\n#&gt; 4    13 roc_auc binary     0.617    10  0.0137 Preprocessor1_Model5\n#&gt; 5     6 roc_auc binary     0.611    10  0.0156 Preprocessor1_Model2\n\nbest_parameter &lt;- select_best(rf_res)\nbest_parameter\n#&gt; # A tibble: 1 Ã— 2\n#&gt;   min_n .config             \n#&gt;   &lt;int&gt; &lt;chr&gt;               \n#&gt; 1    33 Preprocessor1_Model1\n\ncollect_metrics() and autoplot() are also available."
  },
  {
    "objectID": "slides/intro-05-tuning-models.html#the-final-fit",
    "href": "slides/intro-05-tuning-models.html#the-final-fit",
    "title": "5 - Tuning models",
    "section": "The final fit",
    "text": "The final fit\n\nrf_wflow &lt;- finalize_workflow(rf_wflow, best_parameter)\n\nfinal_fit &lt;- last_fit(rf_wflow, taxi_split) \n\ncollect_metrics(final_fit)\n#&gt; # A tibble: 3 Ã— 4\n#&gt;   .metric     .estimator .estimate .config             \n#&gt;   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n#&gt; 1 accuracy    binary        0.913  Preprocessor1_Model1\n#&gt; 2 roc_auc     binary        0.648  Preprocessor1_Model1\n#&gt; 3 brier_class binary        0.0763 Preprocessor1_Model1"
  },
  {
    "objectID": "slides/intro-05-tuning-models.html#your-turn",
    "href": "slides/intro-05-tuning-models.html#your-turn",
    "title": "5 - Tuning models",
    "section": "Your turn",
    "text": "Your turn\n\nModify your model workflow to tune one or more parameters.\nUse grid search to find the best parameter(s).\n\n\n\nâˆ’+\n05:00\n\n\n\n\n\n\nhttps://workshops.tidymodels.org"
  },
  {
    "objectID": "slides/intro-extra-workflowsets.html",
    "href": "slides/intro-extra-workflowsets.html",
    "title": "Extras - workflowsets",
    "section": "",
    "text": "#&gt; â”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels 1.2.0 â”€â”€\n#&gt; âœ” broom        1.0.6      âœ” rsample      1.2.1 \n#&gt; âœ” dials        1.2.1      âœ” tibble       3.2.1 \n#&gt; âœ” dplyr        1.1.4      âœ” tidyr        1.3.1 \n#&gt; âœ” infer        1.0.7      âœ” tune         1.2.1 \n#&gt; âœ” modeldata    1.3.0      âœ” workflows    1.1.4 \n#&gt; âœ” parsnip      1.2.1      âœ” workflowsets 1.1.0 \n#&gt; âœ” purrr        1.0.2      âœ” yardstick    1.3.1 \n#&gt; âœ” recipes      1.0.10\n#&gt; â”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels_conflicts() â”€â”€\n#&gt; âœ– purrr::discard() masks scales::discard()\n#&gt; âœ– dplyr::filter()  masks stats::filter()\n#&gt; âœ– dplyr::lag()     masks stats::lag()\n#&gt; âœ– recipes::step()  masks stats::step()\n#&gt; â€¢ Search for functions across packages at https://www.tidymodels.org/find/"
  },
  {
    "objectID": "slides/intro-extra-workflowsets.html#how-can-we-compare-multiple-model-workflows-at-once",
    "href": "slides/intro-extra-workflowsets.html#how-can-we-compare-multiple-model-workflows-at-once",
    "title": "Extras - workflowsets",
    "section": "How can we compare multiple model workflows at once?",
    "text": "How can we compare multiple model workflows at once?"
  },
  {
    "objectID": "slides/intro-extra-workflowsets.html#evaluate-a-workflow-set",
    "href": "slides/intro-extra-workflowsets.html#evaluate-a-workflow-set",
    "title": "Extras - workflowsets",
    "section": "Evaluate a workflow set",
    "text": "Evaluate a workflow set\n\nworkflow_set(list(tip ~ .), list(tree_spec, rf_spec))\n#&gt; # A workflow set/tibble: 2 Ã— 4\n#&gt;   wflow_id              info             option    result    \n#&gt;   &lt;chr&gt;                 &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n#&gt; 1 formula_decision_tree &lt;tibble [1 Ã— 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n#&gt; 2 formula_rand_forest   &lt;tibble [1 Ã— 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;"
  },
  {
    "objectID": "slides/intro-extra-workflowsets.html#evaluate-a-workflow-set-1",
    "href": "slides/intro-extra-workflowsets.html#evaluate-a-workflow-set-1",
    "title": "Extras - workflowsets",
    "section": "Evaluate a workflow set",
    "text": "Evaluate a workflow set\n\nworkflow_set(list(tip ~ .), list(tree_spec, rf_spec)) %&gt;%\n  workflow_map(\"fit_resamples\", resamples = taxi_folds)\n#&gt; # A workflow set/tibble: 2 Ã— 4\n#&gt;   wflow_id              info             option    result   \n#&gt;   &lt;chr&gt;                 &lt;list&gt;           &lt;list&gt;    &lt;list&gt;   \n#&gt; 1 formula_decision_tree &lt;tibble [1 Ã— 4]&gt; &lt;opts[1]&gt; &lt;rsmp[+]&gt;\n#&gt; 2 formula_rand_forest   &lt;tibble [1 Ã— 4]&gt; &lt;opts[1]&gt; &lt;rsmp[+]&gt;"
  },
  {
    "objectID": "slides/intro-extra-workflowsets.html#evaluate-a-workflow-set-2",
    "href": "slides/intro-extra-workflowsets.html#evaluate-a-workflow-set-2",
    "title": "Extras - workflowsets",
    "section": "Evaluate a workflow set",
    "text": "Evaluate a workflow set\n\nworkflow_set(list(tip ~ .), list(tree_spec, rf_spec)) %&gt;%\n  workflow_map(\"fit_resamples\", resamples = taxi_folds) %&gt;%\n  rank_results()\n#&gt; # A tibble: 6 Ã— 9\n#&gt;   wflow_id         .config .metric   mean std_err     n preprocessor model  rank\n#&gt;   &lt;chr&gt;            &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n#&gt; 1 formula_decisioâ€¦ Preproâ€¦ accuraâ€¦ 0.915  0.00309    10 formula      deciâ€¦     1\n#&gt; 2 formula_decisioâ€¦ Preproâ€¦ brier_â€¦ 0.0721 0.00245    10 formula      deciâ€¦     1\n#&gt; 3 formula_decisioâ€¦ Preproâ€¦ roc_auc 0.624  0.0105     10 formula      deciâ€¦     1\n#&gt; 4 formula_rand_foâ€¦ Preproâ€¦ accuraâ€¦ 0.924  0.00326    10 formula      randâ€¦     2\n#&gt; 5 formula_rand_foâ€¦ Preproâ€¦ brier_â€¦ 0.0706 0.00242    10 formula      randâ€¦     2\n#&gt; 6 formula_rand_foâ€¦ Preproâ€¦ roc_auc 0.615  0.0151     10 formula      randâ€¦     2\n\nThe first metric of the metric set is used for ranking. Use rank_metric to change that.\n\nLots more available with workflow sets, like collect_metrics(), autoplot() methods, and more!"
  },
  {
    "objectID": "slides/intro-extra-workflowsets.html#your-turn",
    "href": "slides/intro-extra-workflowsets.html#your-turn",
    "title": "Extras - workflowsets",
    "section": "Your turn",
    "text": "Your turn\n\nWhen do you think a workflow set would be useful?\n\n\n\nâˆ’+\n03:00\n\n\n\n\n\n\nhttps://workshops.tidymodels.org"
  },
  {
    "objectID": "slides/intro-extra-recipes.html",
    "href": "slides/intro-extra-recipes.html",
    "title": "Extras - Recipes",
    "section": "",
    "text": "#&gt; â”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels 1.2.0 â”€â”€\n#&gt; âœ” broom        1.0.6      âœ” rsample      1.2.1 \n#&gt; âœ” dials        1.2.1      âœ” tibble       3.2.1 \n#&gt; âœ” dplyr        1.1.4      âœ” tidyr        1.3.1 \n#&gt; âœ” infer        1.0.7      âœ” tune         1.2.1 \n#&gt; âœ” modeldata    1.3.0      âœ” workflows    1.1.4 \n#&gt; âœ” parsnip      1.2.1      âœ” workflowsets 1.1.0 \n#&gt; âœ” purrr        1.0.2      âœ” yardstick    1.3.1 \n#&gt; âœ” recipes      1.0.10\n#&gt; â”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels_conflicts() â”€â”€\n#&gt; âœ– purrr::discard() masks scales::discard()\n#&gt; âœ– dplyr::filter()  masks stats::filter()\n#&gt; âœ– dplyr::lag()     masks stats::lag()\n#&gt; âœ– recipes::step()  masks stats::step()\n#&gt; â€¢ Search for functions across packages at https://www.tidymodels.org/find/\n\n\ntaxi_train\n#&gt; # A tibble: 8,000 Ã— 7\n#&gt;    tip   distance company                      local dow   month  hour\n#&gt;    &lt;fct&gt;    &lt;dbl&gt; &lt;fct&gt;                        &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt;\n#&gt;  1 yes      17.2  Chicago Independents         no    Thu   Feb      16\n#&gt;  2 yes       0.88 City Service                 yes   Thu   Mar       8\n#&gt;  3 yes      18.1  other                        no    Mon   Feb      18\n#&gt;  4 yes      12.2  Chicago Independents         no    Sun   Mar      21\n#&gt;  5 yes       0.94 Sun Taxi                     yes   Sat   Apr      23\n#&gt;  6 yes      17.5  Flash Cab                    no    Fri   Mar      12\n#&gt;  7 yes      17.7  other                        no    Sun   Jan       6\n#&gt;  8 yes       1.85 Taxicab Insurance Agency Llc no    Fri   Apr      12\n#&gt;  9 yes       0.53 Sun Taxi                     no    Tue   Mar      18\n#&gt; 10 yes       6.65 Taxicab Insurance Agency Llc no    Sun   Apr      11\n#&gt; # â„¹ 7,990 more rows"
  },
  {
    "objectID": "slides/intro-extra-recipes.html#looking-at-the-predictors",
    "href": "slides/intro-extra-recipes.html#looking-at-the-predictors",
    "title": "Extras - Recipes",
    "section": "Looking at the predictors",
    "text": "Looking at the predictors\n\n#&gt; â”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels 1.2.0 â”€â”€\n#&gt; âœ” broom        1.0.6      âœ” rsample      1.2.1 \n#&gt; âœ” dials        1.2.1      âœ” tibble       3.2.1 \n#&gt; âœ” dplyr        1.1.4      âœ” tidyr        1.3.1 \n#&gt; âœ” infer        1.0.7      âœ” tune         1.2.1 \n#&gt; âœ” modeldata    1.3.0      âœ” workflows    1.1.4 \n#&gt; âœ” parsnip      1.2.1      âœ” workflowsets 1.1.0 \n#&gt; âœ” purrr        1.0.2      âœ” yardstick    1.3.1 \n#&gt; âœ” recipes      1.0.10\n#&gt; â”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels_conflicts() â”€â”€\n#&gt; âœ– purrr::discard() masks scales::discard()\n#&gt; âœ– dplyr::filter()  masks stats::filter()\n#&gt; âœ– dplyr::lag()     masks stats::lag()\n#&gt; âœ– recipes::step()  masks stats::step()\n#&gt; â€¢ Search for functions across packages at https://www.tidymodels.org/find/\n\n\ntaxi_train\n#&gt; # A tibble: 8,000 Ã— 7\n#&gt;    tip   distance company                      local dow   month  hour\n#&gt;    &lt;fct&gt;    &lt;dbl&gt; &lt;fct&gt;                        &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt;\n#&gt;  1 yes      17.2  Chicago Independents         no    Thu   Feb      16\n#&gt;  2 yes       0.88 City Service                 yes   Thu   Mar       8\n#&gt;  3 yes      18.1  other                        no    Mon   Feb      18\n#&gt;  4 yes      12.2  Chicago Independents         no    Sun   Mar      21\n#&gt;  5 yes       0.94 Sun Taxi                     yes   Sat   Apr      23\n#&gt;  6 yes      17.5  Flash Cab                    no    Fri   Mar      12\n#&gt;  7 yes      17.7  other                        no    Sun   Jan       6\n#&gt;  8 yes       1.85 Taxicab Insurance Agency Llc no    Fri   Apr      12\n#&gt;  9 yes       0.53 Sun Taxi                     no    Tue   Mar      18\n#&gt; 10 yes       6.65 Taxicab Insurance Agency Llc no    Sun   Apr      11\n#&gt; # â„¹ 7,990 more rows"
  },
  {
    "objectID": "slides/intro-extra-recipes.html#working-with-other-models",
    "href": "slides/intro-extra-recipes.html#working-with-other-models",
    "title": "Extras - Recipes",
    "section": "Working with other models",
    "text": "Working with other models\nSome models canâ€™t handle non-numeric data\n\nLinear Regression\nK Nearest Neighbors\n\n\n\nSome models struggle if numeric predictors arenâ€™t scaled\n\nK Nearest Neighbors\nAnything using gradient descent"
  },
  {
    "objectID": "slides/intro-extra-recipes.html#types-of-needed-preprocessing",
    "href": "slides/intro-extra-recipes.html#types-of-needed-preprocessing",
    "title": "Extras - Recipes",
    "section": "Types of needed preprocessing",
    "text": "Types of needed preprocessing\n\nDo qualitative predictors require a numeric encoding?\nShould columns with a single unique value be removed?\nDoes the model struggle with missing data?\nDoes the model struggle with correlated predictors?\nShould predictors be centered and scaled?\nIs it helpful to transform predictors to be more symmetric?\n\n\nhttps://www.tmwr.org/pre-proc-table.html"
  },
  {
    "objectID": "slides/intro-extra-recipes.html#two-types-of-preprocessing",
    "href": "slides/intro-extra-recipes.html#two-types-of-preprocessing",
    "title": "Extras - Recipes",
    "section": "Two types of preprocessing",
    "text": "Two types of preprocessing"
  },
  {
    "objectID": "slides/intro-extra-recipes.html#two-types-of-preprocessing-1",
    "href": "slides/intro-extra-recipes.html#two-types-of-preprocessing-1",
    "title": "Extras - Recipes",
    "section": "Two types of preprocessing",
    "text": "Two types of preprocessing"
  },
  {
    "objectID": "slides/intro-extra-recipes.html#general-definitions",
    "href": "slides/intro-extra-recipes.html#general-definitions",
    "title": "Extras - Recipes",
    "section": "General definitions",
    "text": "General definitions\n\nData preprocessing are the steps that you take to make your model successful.\nFeature engineering are what you do to the original predictors to make the model do the least work to perform great."
  },
  {
    "objectID": "slides/intro-extra-recipes.html#working-with-dates",
    "href": "slides/intro-extra-recipes.html#working-with-dates",
    "title": "Extras - Recipes",
    "section": "Working with dates",
    "text": "Working with dates\nDatetime variables are automatically converted to an integer if given as a raw predictor. To avoid this, it can be re-encoded as:\n\nDays since a reference date\nDay of the week\nMonth\nYear\nLeap year\nIndicators for holidays"
  },
  {
    "objectID": "slides/intro-extra-recipes.html#your-turn",
    "href": "slides/intro-extra-recipes.html#your-turn",
    "title": "Extras - Recipes",
    "section": "Your turn",
    "text": "Your turn\n\n\nWhat other transformations could we do with the raw time variable?\nRemember that the transformations are tied to the specific modeling problem.\n\n\n\nâˆ’+\n03:00"
  },
  {
    "objectID": "slides/intro-extra-recipes.html#two-types-of-transformations",
    "href": "slides/intro-extra-recipes.html#two-types-of-transformations",
    "title": "Extras - Recipes",
    "section": "Two types of transformations",
    "text": "Two types of transformations\n\n\n\nStatic\n\nSquare root, log, inverse\nDummies for known levels\nDate time extractions\n\n\nTrained\n\nCentering & scaling\nImputation\nPCA\nAnything for unknown factor levels\n\n\n\n\nTrained methods need to calculate sufficient information to be applied again."
  },
  {
    "objectID": "slides/intro-extra-recipes.html#the-recipes-package",
    "href": "slides/intro-extra-recipes.html#the-recipes-package",
    "title": "Extras - Recipes",
    "section": "The recipes package",
    "text": "The recipes package\n\n\nModular + extensible\nWorks well with pipes ,|&gt; and %&gt;%\nDeferred evaluation\nIsolates test data from training data\nCan do things formulas canâ€™t"
  },
  {
    "objectID": "slides/intro-extra-recipes.html#how-to-write-a-recipe",
    "href": "slides/intro-extra-recipes.html#how-to-write-a-recipe",
    "title": "Extras - Recipes",
    "section": "How to write a recipe",
    "text": "How to write a recipe\n\ntaxi_rec &lt;- recipe(tip ~ ., data = taxi_train) %&gt;%\nÂ Â step_unknown(all_nominal_predictors()) %&gt;%\nÂ Â step_dummy(all_nominal_predictors()) %&gt;%\nÂ Â step_zv(all_predictors()) %&gt;%\nÂ Â step_log(distance, offset = 0.5) %&gt;%\nÂ Â step_normalize(all_numeric_predictors())"
  },
  {
    "objectID": "slides/intro-extra-recipes.html#how-to-write-a-recipe-1",
    "href": "slides/intro-extra-recipes.html#how-to-write-a-recipe-1",
    "title": "Extras - Recipes",
    "section": "How to write a recipe",
    "text": "How to write a recipe\n\ntaxi_rec &lt;- recipe(tip ~ ., data = taxi_train) %&gt;%\nÂ Â step_unknown(all_nominal_predictors()) %&gt;%\nÂ Â step_dummy(all_nominal_predictors()) %&gt;%\nÂ Â step_zv(all_predictors()) %&gt;%\nÂ Â step_log(distance, offset = 0.5) %&gt;%\nÂ Â step_normalize(all_numeric_predictors())\n\n\nStart by calling recipe() to denote the data source and variables used."
  },
  {
    "objectID": "slides/intro-extra-recipes.html#how-to-write-a-recipe-2",
    "href": "slides/intro-extra-recipes.html#how-to-write-a-recipe-2",
    "title": "Extras - Recipes",
    "section": "How to write a recipe",
    "text": "How to write a recipe\n\ntaxi_rec &lt;- recipe(tip ~ ., data = taxi_train) %&gt;%\nÂ Â step_unknown(all_nominal_predictors()) %&gt;%\nÂ Â step_dummy(all_nominal_predictors()) %&gt;%\nÂ Â step_zv(all_predictors()) %&gt;%\nÂ Â step_log(distance, offset = 0.5) %&gt;%\nÂ Â step_normalize(all_numeric_predictors())\n\n\nSpecify what actions to take by adding step_*()s."
  },
  {
    "objectID": "slides/intro-extra-recipes.html#how-to-write-a-recipe-3",
    "href": "slides/intro-extra-recipes.html#how-to-write-a-recipe-3",
    "title": "Extras - Recipes",
    "section": "How to write a recipe",
    "text": "How to write a recipe\n\ntaxi_rec &lt;- recipe(tip ~ ., data = taxi_train) %&gt;%\nÂ Â step_unknown(all_nominal_predictors()) %&gt;%\nÂ Â step_dummy(all_nominal_predictors()) %&gt;%\nÂ Â step_zv(all_predictors()) %&gt;%\nÂ Â step_log(distance, offset = 0.5) %&gt;% Â Â step_normalize(all_numeric_predictors())\n\n\nUse {tidyselect} and recipes-specific selectors to denote affected variables."
  },
  {
    "objectID": "slides/intro-extra-recipes.html#using-a-recipe",
    "href": "slides/intro-extra-recipes.html#using-a-recipe",
    "title": "Extras - Recipes",
    "section": "Using a recipe",
    "text": "Using a recipe\n\ntaxi_rec &lt;- recipe(tip ~ ., data = taxi_train) %&gt;%\nÂ Â step_unknown(all_nominal_predictors()) %&gt;%\nÂ Â step_dummy(all_nominal_predictors()) %&gt;%\nÂ Â step_zv(all_predictors()) %&gt;%\nÂ Â step_log(distance, offset = 0.5) %&gt;% Â Â step_normalize(all_numeric_predictors())\n\n\nSave the recipe we like so that we can use it in various places, e.g., with different models."
  },
  {
    "objectID": "slides/intro-extra-recipes.html#using-a-recipe-with-workflows",
    "href": "slides/intro-extra-recipes.html#using-a-recipe-with-workflows",
    "title": "Extras - Recipes",
    "section": "Using a recipe with workflows",
    "text": "Using a recipe with workflows\nRecipes are typically combined with a model in a workflow() object:\n\n\ntaxi_wflow &lt;- workflow() %&gt;%\nÂ Â add_recipe(taxi_rec) %&gt;%\nÂ Â add_model(linear_reg())"
  },
  {
    "objectID": "slides/intro-extra-recipes.html#recipes-are-estimated",
    "href": "slides/intro-extra-recipes.html#recipes-are-estimated",
    "title": "Extras - Recipes",
    "section": "Recipes are estimated",
    "text": "Recipes are estimated\nEvery preprocessing step in a recipe that involved calculations uses the training set. For example:\n\nLevels of a factor\nDetermination of zero-variance\nNormalization\nFeature extraction\n\nOnce a recipe is added to a workflow, this occurs when fit() is called."
  },
  {
    "objectID": "slides/intro-extra-recipes.html#debugging-a-recipe",
    "href": "slides/intro-extra-recipes.html#debugging-a-recipe",
    "title": "Extras - Recipes",
    "section": "Debugging a recipe",
    "text": "Debugging a recipe\n\nTypically, you will want to use a workflow to estimate and apply a recipe.\n\n\n\nIf you have an error and need to debug your recipe, the original recipe object (e.g.Â taxi_rec) can be estimated manually with a function called prep(). It is analogous to fit(). See TMwR section 16.4.\n\n\n\n\nAnother function, bake(), is analogous to predict(), and gives you the processed data back."
  },
  {
    "objectID": "slides/intro-extra-recipes.html#your-turn-1",
    "href": "slides/intro-extra-recipes.html#your-turn-1",
    "title": "Extras - Recipes",
    "section": "Your turn",
    "text": "Your turn\n\n\nTake the recipe and prep() then bake() it to see what the resulting data set looks like.\nTry removing steps to see how the result changes.\n\n\n\n\nâˆ’+\n05:00"
  },
  {
    "objectID": "slides/intro-extra-recipes.html#printing-a-recipe",
    "href": "slides/intro-extra-recipes.html#printing-a-recipe",
    "title": "Extras - Recipes",
    "section": "Printing a recipe",
    "text": "Printing a recipe\n\ntaxi_rec\n#&gt; \n#&gt; â”€â”€ Recipe â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#&gt; \n#&gt; â”€â”€ Inputs\n#&gt; Number of variables by role\n#&gt; outcome:   1\n#&gt; predictor: 6\n#&gt; \n#&gt; â”€â”€ Operations\n#&gt; â€¢ Unknown factor level assignment for: all_nominal_predictors()\n#&gt; â€¢ Dummy variables from: all_nominal_predictors()\n#&gt; â€¢ Zero variance filter on: all_predictors()\n#&gt; â€¢ Log transformation on: distance\n#&gt; â€¢ Centering and scaling for: all_numeric_predictors()"
  },
  {
    "objectID": "slides/intro-extra-recipes.html#prepping-a-recipe",
    "href": "slides/intro-extra-recipes.html#prepping-a-recipe",
    "title": "Extras - Recipes",
    "section": "Prepping a recipe",
    "text": "Prepping a recipe\n\nprep(taxi_rec)\n#&gt; \n#&gt; â”€â”€ Recipe â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#&gt; \n#&gt; â”€â”€ Inputs\n#&gt; Number of variables by role\n#&gt; outcome:   1\n#&gt; predictor: 6\n#&gt; \n#&gt; â”€â”€ Training information\n#&gt; Training data contained 8000 data points and no incomplete rows.\n#&gt; \n#&gt; â”€â”€ Operations\n#&gt; â€¢ Unknown factor level assignment for: company, ... | Trained\n#&gt; â€¢ Dummy variables from: company, local, dow, month | Trained\n#&gt; â€¢ Zero variance filter removed: company_unknown, ... | Trained\n#&gt; â€¢ Log transformation on: distance | Trained\n#&gt; â€¢ Centering and scaling for: distance and hour, ... | Trained"
  },
  {
    "objectID": "slides/intro-extra-recipes.html#baking-a-recipe",
    "href": "slides/intro-extra-recipes.html#baking-a-recipe",
    "title": "Extras - Recipes",
    "section": "Baking a recipe",
    "text": "Baking a recipe\n\nprep(taxi_rec) %&gt;%\n  bake(new_data = taxi_train)\n#&gt; # A tibble: 8,000 Ã— 19\n#&gt;    distance   hour tip   company_City.Service company_Flash.Cab company_Sun.Taxi company_Taxi.Affiliatioâ€¦Â¹ company_Taxicab.Insuâ€¦Â² company_other local_no dow_Mon dow_Tue dow_Wed dow_Thu dow_Fri dow_Sat\n#&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt;                &lt;dbl&gt;             &lt;dbl&gt;            &lt;dbl&gt;                     &lt;dbl&gt;                  &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n#&gt;  1    1.38   0.418 yes                 -0.366            -0.333           -0.403                    -0.450                 -0.379        -0.609    0.484  -0.396  -0.441  -0.461   2.01   -0.428  -0.317\n#&gt;  2   -0.729 -1.42  yes                  2.73             -0.333           -0.403                    -0.450                 -0.379        -0.609   -2.07   -0.396  -0.441  -0.461   2.01   -0.428  -0.317\n#&gt;  3    1.42   0.877 yes                 -0.366            -0.333           -0.403                    -0.450                 -0.379         1.64     0.484   2.53   -0.441  -0.461  -0.497  -0.428  -0.317\n#&gt;  4    1.11   1.57  yes                 -0.366            -0.333           -0.403                    -0.450                 -0.379        -0.609    0.484  -0.396  -0.441  -0.461  -0.497  -0.428  -0.317\n#&gt;  5   -0.694  2.03  yes                 -0.366            -0.333            2.48                     -0.450                 -0.379        -0.609   -2.07   -0.396  -0.441  -0.461  -0.497  -0.428   3.15 \n#&gt;  6    1.39  -0.502 yes                 -0.366             3.01            -0.403                    -0.450                 -0.379        -0.609    0.484  -0.396  -0.441  -0.461  -0.497   2.34   -0.317\n#&gt;  7    1.40  -1.88  yes                 -0.366            -0.333           -0.403                    -0.450                 -0.379         1.64     0.484  -0.396  -0.441  -0.461  -0.497  -0.428  -0.317\n#&gt;  8   -0.289 -0.502 yes                 -0.366            -0.333           -0.403                    -0.450                  2.64         -0.609    0.484  -0.396  -0.441  -0.461  -0.497   2.34   -0.317\n#&gt;  9   -0.971  0.877 yes                 -0.366            -0.333            2.48                     -0.450                 -0.379        -0.609    0.484  -0.396   2.27   -0.461  -0.497  -0.428  -0.317\n#&gt; 10    0.631 -0.732 yes                 -0.366            -0.333           -0.403                    -0.450                  2.64         -0.609    0.484  -0.396  -0.441  -0.461  -0.497  -0.428  -0.317\n#&gt; # â„¹ 7,990 more rows\n#&gt; # â„¹ abbreviated names: Â¹â€‹company_Taxi.Affiliation.Services, Â²â€‹company_Taxicab.Insurance.Agency.Llc\n#&gt; # â„¹ 3 more variables: month_Feb &lt;dbl&gt;, month_Mar &lt;dbl&gt;, month_Apr &lt;dbl&gt;"
  },
  {
    "objectID": "slides/intro-extra-recipes.html#tidying-a-recipe",
    "href": "slides/intro-extra-recipes.html#tidying-a-recipe",
    "title": "Extras - Recipes",
    "section": "Tidying a recipe",
    "text": "Tidying a recipe\nOnce a recipe as been estimated, there are various bits of information saved in it.\n\nThe tidy() function can be used to get specific results from the recipe."
  },
  {
    "objectID": "slides/intro-extra-recipes.html#your-turn-2",
    "href": "slides/intro-extra-recipes.html#your-turn-2",
    "title": "Extras - Recipes",
    "section": "Your turn",
    "text": "Your turn\n\nTake a prepped recipe and use the tidy() function on it.\nUse the number argument to inspect different steps.\n\n\n\n\nâˆ’+\n05:00"
  },
  {
    "objectID": "slides/intro-extra-recipes.html#tidying-a-recipe-1",
    "href": "slides/intro-extra-recipes.html#tidying-a-recipe-1",
    "title": "Extras - Recipes",
    "section": "Tidying a recipe",
    "text": "Tidying a recipe\n\nprep(taxi_rec) %&gt;%\n  tidy()\n#&gt; # A tibble: 5 Ã— 6\n#&gt;   number operation type      trained skip  id             \n#&gt;    &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;     &lt;lgl&gt;   &lt;lgl&gt; &lt;chr&gt;          \n#&gt; 1      1 step      unknown   TRUE    FALSE unknown_NTmu5  \n#&gt; 2      2 step      dummy     TRUE    FALSE dummy_cT3Uy    \n#&gt; 3      3 step      zv        TRUE    FALSE zv_z22dk       \n#&gt; 4      4 step      log       TRUE    FALSE log_QQ1iw      \n#&gt; 5      5 step      normalize TRUE    FALSE normalize_3cTJb"
  },
  {
    "objectID": "slides/intro-extra-recipes.html#tidying-a-recipe-2",
    "href": "slides/intro-extra-recipes.html#tidying-a-recipe-2",
    "title": "Extras - Recipes",
    "section": "Tidying a recipe",
    "text": "Tidying a recipe\n\nprep(taxi_rec) %&gt;%\n  tidy(number = 2)\n#&gt; # A tibble: 20 Ã— 3\n#&gt;    terms   columns                      id         \n#&gt;    &lt;chr&gt;   &lt;chr&gt;                        &lt;chr&gt;      \n#&gt;  1 company City Service                 dummy_cT3Uy\n#&gt;  2 company Flash Cab                    dummy_cT3Uy\n#&gt;  3 company Sun Taxi                     dummy_cT3Uy\n#&gt;  4 company Taxi Affiliation Services    dummy_cT3Uy\n#&gt;  5 company Taxicab Insurance Agency Llc dummy_cT3Uy\n#&gt;  6 company other                        dummy_cT3Uy\n#&gt;  7 company unknown                      dummy_cT3Uy\n#&gt;  8 local   no                           dummy_cT3Uy\n#&gt;  9 local   unknown                      dummy_cT3Uy\n#&gt; 10 dow     Mon                          dummy_cT3Uy\n#&gt; 11 dow     Tue                          dummy_cT3Uy\n#&gt; 12 dow     Wed                          dummy_cT3Uy\n#&gt; 13 dow     Thu                          dummy_cT3Uy\n#&gt; 14 dow     Fri                          dummy_cT3Uy\n#&gt; 15 dow     Sat                          dummy_cT3Uy\n#&gt; 16 dow     unknown                      dummy_cT3Uy\n#&gt; 17 month   Feb                          dummy_cT3Uy\n#&gt; 18 month   Mar                          dummy_cT3Uy\n#&gt; 19 month   Apr                          dummy_cT3Uy\n#&gt; 20 month   unknown                      dummy_cT3Uy"
  },
  {
    "objectID": "slides/intro-extra-recipes.html#using-a-recipe-in-tidymodels",
    "href": "slides/intro-extra-recipes.html#using-a-recipe-in-tidymodels",
    "title": "Extras - Recipes",
    "section": "Using a recipe in tidymodels",
    "text": "Using a recipe in tidymodels\nThe recommended way to use a recipe in tidymodels is to use it as part of a workflow().\n\ntaxi_wflow &lt;- workflow() %&gt;%  \n  add_recipe(taxi_rec) %&gt;%  \n  add_model(linear_reg())\n\nWhen used in this way, you donâ€™t need to worry about prep() and bake() as it is handled for you."
  },
  {
    "objectID": "slides/intro-extra-recipes.html#more-information",
    "href": "slides/intro-extra-recipes.html#more-information",
    "title": "Extras - Recipes",
    "section": "More information",
    "text": "More information\n\nhttps://recipes.tidymodels.org/\nhttps://www.tmwr.org/recipes.html\n\n\n\n\nhttps://workshops.tidymodels.org"
  },
  {
    "objectID": "slides/annotations.html#section",
    "href": "slides/annotations.html#section",
    "title": "Annotations",
    "section": "ğŸ‘€",
    "text": "ğŸ‘€\nThis page contains annotations for selected slides.\nThereâ€™s a lot that we want to tell you. We donâ€™t want people to have to frantically scribble down things that we say that are not on the slides.\nWeâ€™ve added sections to this document with longer explanations and links to other resources."
  },
  {
    "objectID": "slides/annotations.html#the-initial-split",
    "href": "slides/annotations.html#the-initial-split",
    "title": "Annotations",
    "section": "The initial split",
    "text": "The initial split\nWhat does set.seed() do?\nWeâ€™ll use pseudo-random numbers (PRN) to partition the data into training and testing. PRN are numbers that emulate truly random numbers (but really are not truly random).\nThink of PRN as a box that takes a starting value (the â€œseedâ€) that produces random numbers using that starting value as an input into its process.\nIf we know a seed value, we can reproduce our â€œrandomâ€ numbers. To use a different set of random numbers, choose a different seed value.\nFor example:\n\nset.seed(1)\nrunif(3)\n#&gt; [1] 0.2655087 0.3721239 0.5728534\n\n# Get a new set of random numbers:\nset.seed(2)\nrunif(3)\n#&gt; [1] 0.1848823 0.7023740 0.5733263\n\n# We can reproduce the old ones with the same seed\nset.seed(1)\nrunif(3)\n#&gt; [1] 0.2655087 0.3721239 0.5728534\n\nIf we donâ€™t set the seed, R uses the clock time and the process ID to create a seed. This isnâ€™t reproducible.\nSince we want our code to be reproducible, we set the seeds before random numbers are used.\nIn theory, you can set the seed once at the start of a script. However, if we do interactive data analysis, we might unwittingly use random numbers while coding. In that case, the stream is not the same and we donâ€™t get reproducible results.\nThe value of the seed is an integer and really has no meaning. Max has a script to generate random integers to use as seeds to â€œspread the randomness aroundâ€. It is basically:\n\ncat(paste0(\"set.seed(\", sample.int(10000, 5), \")\", collapse = \"\\n\"))\n#&gt; set.seed(9725)\n#&gt; set.seed(8462)\n#&gt; set.seed(4050)\n#&gt; set.seed(8789)\n#&gt; set.seed(1301)"
  },
  {
    "objectID": "slides/annotations.html#what-is-wrong-with-this",
    "href": "slides/annotations.html#what-is-wrong-with-this",
    "title": "Annotations",
    "section": "What is wrong with this?",
    "text": "What is wrong with this?\nIf we treat the preprocessing as a separate task, it raises the risk that we might accidentally overfit to the data at hand.\nFor example, someone might estimate something from the entire data set (such as the principle components) and treat that data as if it were known (and not estimated). Depending on the what was done with the data, consequences in doing that could be:\n\nYour performance metrics are slightly-to-moderately optimistic (e.g.Â you might think your accuracy is 85% when it is actually 75%)\nA consequential component of the analysis is not right and the model just doesnâ€™t work.\n\nThe big issue here is that you wonâ€™t be able to figure this out until you get a new piece of data, such as the test set.\nA really good example of this is in â€˜Selection bias in gene extraction on the basis of microarray gene-expression dataâ€™. The authors re-analyze a previous publication and show that the original researchers did not include feature selection in the workflow. Because of that, their performance statistics were extremely optimistic. In one case, they could do the original analysis on complete noise and still achieve zero errors.\nGenerally speaking, this problem is referred to as data leakage. Some other references:\n\nOverfitting to Predictors and External Validation\nAre We Learning Yet? A Meta Review of Evaluation Failures Across Machine Learning\nNavigating the pitfalls of applying machine learning in genomics\nA review of feature selection techniques in bioinformatics\nOn Over-fitting in Model Selection and Subsequent Selection Bias in Performance Evaluation"
  },
  {
    "objectID": "slides/annotations.html#where-are-the-fitted-models",
    "href": "slides/annotations.html#where-are-the-fitted-models",
    "title": "Annotations",
    "section": "Where are the fitted models?",
    "text": "Where are the fitted models?\nThe primary purpose of resampling is to estimate model performance. The models are almost never needed again.\nAlso, if the data set is large, the model object may require a lot of memory to save so, by default, we donâ€™t keep them.\nFor more advanced use cases, you can extract and save them. See:\n\nhttps://www.tmwr.org/resampling.html#extract\nhttps://www.tidymodels.org/learn/models/coefficients/ (an example)"
  },
  {
    "objectID": "slides/annotations.html#update-parameter-ranges",
    "href": "slides/annotations.html#update-parameter-ranges",
    "title": "Annotations",
    "section": "Update parameter ranges",
    "text": "Update parameter ranges\nIn about 90% of the cases, the dials function that you use to update the parameter range has the same name as the argument. For example, if you were to update the mtry parameter in a random forests model, the code would look like\n\nparameter_object %&gt;% \n  update(mtry = mtry(c(1, 100)))\n\nThere are some cases where the parameter function, or its associated values, are different from the argument name.\nFor example, with step_spline_naturall(), we might want to tune the deg_free argument (for the degrees of freedom of a spline function. ). In this case, the argument name is deg_free but we update it with spline_degree().\ndeg_free represents the general concept of degrees of freedom and could be associated with many different things. For example, if we ever had an argument that was the number of degrees of freedom for a \\(t\\) distribution, we would call that argument deg_free.\nFor splines, we probably want a wider range for the degrees of freedom. We made a specialized function called spline_degree() to be used in these cases.\nHow can you tell when this happens? There is a helper function called tunable() and that gives information on how we make the default ranges for parameters. There is a column in these objects names call_info:\n\nlibrary(tidymodels)\nns_tunable &lt;- \n  recipe(mpg ~ ., data = mtcars) %&gt;% \n  step_spline_natural(dis, deg_free = tune()) %&gt;% \n  tunable()\n\nns_tunable\n#&gt; # A tibble: 1 Ã— 5\n#&gt;   name     call_info        source component           component_id        \n#&gt;   &lt;chr&gt;    &lt;list&gt;           &lt;chr&gt;  &lt;chr&gt;               &lt;chr&gt;               \n#&gt; 1 deg_free &lt;named list [3]&gt; recipe step_spline_natural spline_natural_P1Tjg\nns_tunable$call_info\n#&gt; [[1]]\n#&gt; [[1]]$pkg\n#&gt; [1] \"dials\"\n#&gt; \n#&gt; [[1]]$fun\n#&gt; [1] \"spline_degree\"\n#&gt; \n#&gt; [[1]]$range\n#&gt; [1]  2 15"
  },
  {
    "objectID": "slides/annotations.html#early-stopping-for-boosted-trees",
    "href": "slides/annotations.html#early-stopping-for-boosted-trees",
    "title": "Annotations",
    "section": "Early stopping for boosted trees",
    "text": "Early stopping for boosted trees\nWhen deciding on the number of boosting iterations, there are two main strategies:\n\nDirectly tune it (trees = tune())\nSet it to one value and tune the number of early stopping iterations (trees = 500, stop_iter = tune()).\n\nEarly stopping is when we monitor the performance of the model. If the model doesnâ€™t make any improvements for stop_iter iterations, training stops.\nHereâ€™s an example where, after eleven iterations, performance starts to get worse.\n\n\n\n\n\n\n\n\n\nThis is likely due to over-fitting so we stop the model at eleven boosting iterations.\nEarly stopping usually has good results and takes far less time.\nWe could an engine argument called validation here. Thatâ€™s not an argument to any function in the lightgbm package.\nbonsai has its own wrapper around (lightgbm::lgb.train()) called bonsai::train_lightgbm(). We use that here and it has a validation argument.\nHow would you know that? There are a few different ways:\n\nLook at the documentation in ?boost_tree and click on the lightgbm entry in the engine list.\nCheck out the pkgdown reference website https://parsnip.tidymodels.org/reference/index.html\nRun the translate() function on the parsnip specification object.\n\nThe first two options are best since they tell you a lot more about the particularities of each model engine (there are a lot for lightgbm)."
  },
  {
    "objectID": "slides/annotations.html#per-agent-statistics",
    "href": "slides/annotations.html#per-agent-statistics",
    "title": "Annotations",
    "section": "Per-agent statistics",
    "text": "Per-agent statistics\nThe effect encoding method essentially takes the effect of a variable, like agent, and makes a data column for that effect. In our example, affect of the agent on the ADR is quantified by a model and then added as a data column to be used in the model.\nSuppose agent Max has a single reservation in the data and it had an ADR of â‚¬200. If we used a naive estimate for Maxâ€™s effect, the model is being told that Max should always produce an effect of â‚¬200. Thatâ€™s a very poor estimate since it is from a single data point.\nContrast this with seasoned agent Davis, who has taken 250 reservations with an average ADR of â‚¬100. Davisâ€™s mean is more predictive because it is estimated with better data (i.e., more total reservations). Partial pooling leverages the entire data set and can borrow strength from all of the agents. It is a common tool in Bayesian estimation and non-Bayesian mixed models. If a agentâ€™s data is of good quality, the partial pooling effect estimate is closer to the raw mean. Maxâ€™s data is not great and is â€œshrunkâ€ towards the center of the overall average. Since there is so little known about Maxâ€™s reservation history, this is a better effect estimate (until more data is available for him).\nThe Stan documentation has a pretty good vignette on this: https://cran.r-project.org/web/packages/rstanarm/vignettes/pooling.html\nAlso, Bayes Rules! has a nice section on this: https://www.bayesrulesbook.com/chapter-15.html\nSince this example has a numeric outcome, partial pooling is very similar to the Jamesâ€“Stein estimator: https://en.wikipedia.org/wiki/Jamesâ€“Stein_estimator"
  },
  {
    "objectID": "slides/annotations.html#agent-effects",
    "href": "slides/annotations.html#agent-effects",
    "title": "Annotations",
    "section": "Agent effects",
    "text": "Agent effects\nEffect encoding might result in a somewhat circular argument: the column is more likely to be important to the model since it is the output of a separate model. The risk here is that we might over-fit the effect to the data. For this reason, it is super important to make sure that we verify that we arenâ€™t overfitting by checking with resampling (or a validation set).\nPartial pooling somewhat lowers the risk of overfitting since it tends to correct for agents with small sample sizes. It canâ€™t correct for improper data usage or data leakage though."
  },
  {
    "objectID": "slides/intro-06-wrapping-up.html",
    "href": "slides/intro-06-wrapping-up.html",
    "title": "6 - Wrapping up",
    "section": "",
    "text": "We made it!"
  },
  {
    "objectID": "slides/intro-06-wrapping-up.html#your-turn",
    "href": "slides/intro-06-wrapping-up.html#your-turn",
    "title": "6 - Wrapping up",
    "section": "Your turn",
    "text": "Your turn\n\nWhat is one thing you learned that surprised you?\nWhat is one thing you learned that you plan to use?\n\n\n\nâˆ’+\n05:00"
  },
  {
    "objectID": "slides/intro-06-wrapping-up.html#resources-to-keep-learning",
    "href": "slides/intro-06-wrapping-up.html#resources-to-keep-learning",
    "title": "6 - Wrapping up",
    "section": "Resources to keep learning",
    "text": "Resources to keep learning\n\n\nhttps://www.tidymodels.org/\n\n\n\n\nhttps://www.tmwr.org/\n\n\n\n\nhttp://www.feat.engineering/\n\n\n\n\nhttps://smltar.com/\n\n\n\nFollow us on Mastodon and at the tidyverse blog for updates!\n\n\n\nhttps://workshops.tidymodels.org"
  },
  {
    "objectID": "slides/intro-extra-time-splits.html",
    "href": "slides/intro-extra-time-splits.html",
    "title": "Extras - Time-based data splitting",
    "section": "",
    "text": "#&gt; â”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels 1.2.0 â”€â”€\n#&gt; âœ” broom        1.0.6      âœ” rsample      1.2.1 \n#&gt; âœ” dials        1.2.1      âœ” tibble       3.2.1 \n#&gt; âœ” dplyr        1.1.4      âœ” tidyr        1.3.1 \n#&gt; âœ” infer        1.0.7      âœ” tune         1.2.1 \n#&gt; âœ” modeldata    1.3.0      âœ” workflows    1.1.4 \n#&gt; âœ” parsnip      1.2.1      âœ” workflowsets 1.1.0 \n#&gt; âœ” purrr        1.0.2      âœ” yardstick    1.3.1 \n#&gt; âœ” recipes      1.0.10\n#&gt; â”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels_conflicts() â”€â”€\n#&gt; âœ– purrr::discard() masks scales::discard()\n#&gt; âœ– dplyr::filter()  masks stats::filter()\n#&gt; âœ– dplyr::lag()     masks stats::lag()\n#&gt; âœ– recipes::step()  masks stats::step()\n#&gt; â€¢ Dig deeper into tidy modeling with R at https://www.tmwr.org"
  },
  {
    "objectID": "slides/intro-extra-time-splits.html#the-raw-taxi-data-set",
    "href": "slides/intro-extra-time-splits.html#the-raw-taxi-data-set",
    "title": "Extras - Time-based data splitting",
    "section": "The raw taxi data set",
    "text": "The raw taxi data set\nWe prepared the data set specifically for this introductory workshop.\nIt looked similar to this:\n\nglimpse(taxi_raw)\n#&gt; Rows: 10,000\n#&gt; Columns: 24\n#&gt; $ trip_id                    &lt;chr&gt; \"3ac8d4412642a35e9b9a493285814d7983d5a159\",â€¦\n#&gt; $ taxi_id                    &lt;chr&gt; \"391317d70c5d06deec744062c4595dc1958b200fdaâ€¦\n#&gt; $ trip_start_timestamp       &lt;dttm&gt; 2023-06-10 18:45:00, 2023-05-21 21:30:00, â€¦\n#&gt; $ trip_end_timestamp         &lt;dttm&gt; 2023-06-10 19:30:00, 2023-05-21 21:45:00, â€¦\n#&gt; $ trip_seconds               &lt;dbl&gt; 3258, 839, 476, 2220, 1588, 2270, 1575, 267â€¦\n#&gt; $ trip_miles                 &lt;dbl&gt; 17.02, 2.16, 1.05, 17.40, 17.62, 16.36, 18.â€¦\n#&gt; $ pickup_census_tract        &lt;dbl&gt; 17031980000, 17031839100, 17031320100, 1703â€¦\n#&gt; $ dropoff_census_tract       &lt;dbl&gt; 17031081403, 17031081300, 17031081403, 1703â€¦\n#&gt; $ pickup_community_area      &lt;dbl&gt; 76, 32, 32, 76, 32, 76, 76, 32, 32, 33, 8, â€¦\n#&gt; $ dropoff_community_area     &lt;dbl&gt; 8, 8, 8, 32, 76, 8, 32, 76, 28, 32, 7, 33, â€¦\n#&gt; $ fare                       &lt;dbl&gt; 44.50, 10.00, 6.75, 45.00, 44.25, 41.25, 44â€¦\n#&gt; $ tips                       &lt;dbl&gt; 12.25, 4.00, 2.00, 9.90, 8.00, 9.15, 12.31,â€¦\n#&gt; $ tolls                      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n#&gt; $ extras                     &lt;dbl&gt; 4.0, 1.0, 0.0, 4.0, 2.0, 4.0, 4.0, 0.0, 0.0â€¦\n#&gt; $ trip_total                 &lt;dbl&gt; 61.25, 15.50, 9.25, 58.90, 54.75, 54.90, 61â€¦\n#&gt; $ payment_type               &lt;chr&gt; \"Credit Card\", \"Credit Card\", \"Credit Card\"â€¦\n#&gt; $ company                    &lt;chr&gt; \"Taxicab Insurance Agency Llc\", \"Chicago Inâ€¦\n#&gt; $ pickup_centroid_latitude   &lt;dbl&gt; 41.97907, 41.88099, 41.88499, 41.97907, 41.â€¦\n#&gt; $ pickup_centroid_longitude  &lt;dbl&gt; -87.90304, -87.63275, -87.62099, -87.90304,â€¦\n#&gt; $ pickup_centroid_location   &lt;chr&gt; \"POINT (-87.9030396611 41.9790708201)\", \"POâ€¦\n#&gt; $ dropoff_centroid_latitude  &lt;dbl&gt; 41.89092, 41.89833, 41.89092, 41.87102, 41.â€¦\n#&gt; $ dropoff_centroid_longitude &lt;dbl&gt; -87.61887, -87.62076, -87.61887, -87.63141,â€¦\n#&gt; $ dropoff_centroid_location  &lt;chr&gt; \"POINT (-87.6188683546 41.8909220259)\", \"POâ€¦\n#&gt; $ tip                        &lt;fct&gt; yes, yes, yes, yes, yes, yes, yes, yes, yesâ€¦\n\n\ntrip_start_time has date and time rounded to â€œquarters of the hourâ€."
  },
  {
    "objectID": "slides/intro-extra-time-splits.html#time-nature-of-the-data",
    "href": "slides/intro-extra-time-splits.html#time-nature-of-the-data",
    "title": "Extras - Time-based data splitting",
    "section": "Time nature of the data",
    "text": "Time nature of the data\nWe assumed only the month, day of the week, and hour mattered and treated each observation as independent.\n\nIf the data have a strong time component, all your data splitting strategies should support the model in estimating temporal trends.\n\n\nThus, donâ€™t sample randomly because this breaks up the time component!"
  },
  {
    "objectID": "slides/intro-extra-time-splits.html#splitting-with-time-component",
    "href": "slides/intro-extra-time-splits.html#splitting-with-time-component",
    "title": "Extras - Time-based data splitting",
    "section": "Splitting with time component ",
    "text": "Splitting with time component \nThe more recent observations are assumed to be more similar to new data, so initial_time_split() puts them into the test set.\nThe function assumes that the data are already ordered.\n\ntaxi_raw &lt;- taxi_raw %&gt;%\n  arrange(trip_start_timestamp)\n\ntaxi_split &lt;- initial_time_split(taxi_raw, prop = 3 / 4)\ntaxi_split\n#&gt; &lt;Training/Testing/Total&gt;\n#&gt; &lt;7500/2500/10000&gt;\n\ntaxi_train &lt;- training(taxi_split)\ntaxi_test  &lt;- testing(taxi_split)\n\nnrow(taxi_train)\n#&gt; [1] 7500\n \nnrow(taxi_test)\n#&gt; [1] 2500"
  },
  {
    "objectID": "slides/intro-extra-time-splits.html#time-series-resampling",
    "href": "slides/intro-extra-time-splits.html#time-series-resampling",
    "title": "Extras - Time-based data splitting",
    "section": "Time series resampling",
    "text": "Time series resampling\nThe same idea also applies to resampling: the newer observations go into the assessment set.\nFor example:\n\nFold 1: Take the first X weeks of data as the analysis set, and the next 3 weeks as the assessment set.\nFold 2: Take weeks 2 to X + 1 as the analysis set, and the next 3 weeks as the assessment set.\nand so on"
  },
  {
    "objectID": "slides/intro-extra-time-splits.html#rolling-origin-forecast-resampling",
    "href": "slides/intro-extra-time-splits.html#rolling-origin-forecast-resampling",
    "title": "Extras - Time-based data splitting",
    "section": "Rolling origin forecast resampling",
    "text": "Rolling origin forecast resampling\n\n\nThis image shows overlapping assessment sets. We will use non-overlapping data but it could be done either way."
  },
  {
    "objectID": "slides/intro-extra-time-splits.html#times-series-resampling",
    "href": "slides/intro-extra-time-splits.html#times-series-resampling",
    "title": "Extras - Time-based data splitting",
    "section": "Times series resampling ",
    "text": "Times series resampling \n\ntaxi_rs &lt;-\n  taxi_train %&gt;%\n  sliding_period(\n    index = \"trip_start_timestamp\",  \n\n\n\n\n  )\n\nUse the trip_start_timestamp column to find the date data."
  },
  {
    "objectID": "slides/intro-extra-time-splits.html#times-series-resampling-1",
    "href": "slides/intro-extra-time-splits.html#times-series-resampling-1",
    "title": "Extras - Time-based data splitting",
    "section": "Times series resampling ",
    "text": "Times series resampling \n\ntaxi_rs &lt;-\n  taxi_train %&gt;%\n  sliding_period(\n    index = \"trip_start_timestamp\",  \n    period = \"week\",\n\n\n\n  )\n\nOur units will be in weeks."
  },
  {
    "objectID": "slides/intro-extra-time-splits.html#times-series-resampling-2",
    "href": "slides/intro-extra-time-splits.html#times-series-resampling-2",
    "title": "Extras - Time-based data splitting",
    "section": "Times series resampling ",
    "text": "Times series resampling \n\ntaxi_rs &lt;-\n  taxi_train %&gt;%\n  sliding_period(\n    index = \"trip_start_timestamp\",  \n    period = \"week\",\n    lookback = 8\n    \n    \n  )\n\nEvery analysis set has 8 weeks of data."
  },
  {
    "objectID": "slides/intro-extra-time-splits.html#times-series-resampling-3",
    "href": "slides/intro-extra-time-splits.html#times-series-resampling-3",
    "title": "Extras - Time-based data splitting",
    "section": "Times series resampling ",
    "text": "Times series resampling \n\ntaxi_rs &lt;-\n  taxi_train %&gt;%\n  sliding_period(\n    index = \"trip_start_timestamp\",  \n    period = \"week\",\n    lookback = 8,\n    assess_stop = 3,\n\n  )\n\nEvery assessment set has 3 weeks of data."
  },
  {
    "objectID": "slides/intro-extra-time-splits.html#times-series-resampling-4",
    "href": "slides/intro-extra-time-splits.html#times-series-resampling-4",
    "title": "Extras - Time-based data splitting",
    "section": "Times series resampling ",
    "text": "Times series resampling \n\ntaxi_rs &lt;-\n  taxi_train %&gt;%\n  sliding_period(\n    index = \"trip_start_timestamp\",  \n    period = \"week\",\n    lookback = 8,\n    assess_stop = 3,\n    step = 1\n  )\n\nIncrement by 1 week\n\n\ntaxi_rs$splits[[1]] %&gt;% assessment() %&gt;% pluck(\"trip_start_timestamp\") %&gt;% range()\n#&gt; [1] \"2023-03-02 05:15:00 UTC\" \"2023-03-22 22:00:00 UTC\"\n\ntaxi_rs$splits[[2]] %&gt;% assessment() %&gt;% pluck(\"trip_start_timestamp\") %&gt;% range()\n#&gt; [1] \"2023-03-09 07:00:00 UTC\" \"2023-03-29 21:15:00 UTC\"\n\ntaxi_rs$splits[[3]] %&gt;% assessment() %&gt;% pluck(\"trip_start_timestamp\") %&gt;% range()\n#&gt; [1] \"2023-03-16 06:30:00 UTC\" \"2023-04-05 23:45:00 UTC\"\n\n\n\n\nhttps://workshops.tidymodels.org"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#proportional-hazards-model",
    "href": "slides/intro-03-what-makes-a-model.html#proportional-hazards-model",
    "title": "3 - What makes a model?",
    "section": "Proportional hazards model",
    "text": "Proportional hazards model"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#proportional-hazards-model-1",
    "href": "slides/intro-03-what-makes-a-model.html#proportional-hazards-model-1",
    "title": "3 - What makes a model?",
    "section": "Proportional hazards model",
    "text": "Proportional hazards model"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#proportional-hazards-model-2",
    "href": "slides/intro-03-what-makes-a-model.html#proportional-hazards-model-2",
    "title": "3 - What makes a model?",
    "section": "Proportional hazards model",
    "text": "Proportional hazards model\n\n\n\n\n\n\n\n\n\n\n\n\n\nHazard modeled via a baseline hazard and a linear combination of predictors:\n\n\\(\\lambda(t | x_i) = \\lambda_0(t) \\cdot \\exp (x_i^T \\beta)\\)\n\nThe hazard is proportional over all time \\(t\\), and thus also the probability of survival is proportional."
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#decision-tree",
    "href": "slides/intro-03-what-makes-a-model.html#decision-tree",
    "title": "3 - What makes a model?",
    "section": "Decision tree",
    "text": "Decision tree"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#decision-tree-1",
    "href": "slides/intro-03-what-makes-a-model.html#decision-tree-1",
    "title": "3 - What makes a model?",
    "section": "Decision tree",
    "text": "Decision tree\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeries of splits or if/then statements based on predictors\nFirst the tree grows until some condition is met (maximum depth, no more data)\nThen the tree is pruned to reduce its complexity"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#section-1",
    "href": "slides/intro-03-what-makes-a-model.html#section-1",
    "title": "3 - What makes a model?",
    "section": "",
    "text": "model\nengine\ntime\nsurvival\nlinear_pred\nraw\nquantile\nhazard\n\n\n\n\nbag_tree\nrpart\nâœ”\nâœ”\nâœ–\nâœ–\nâœ–\nâœ–\n\n\nboost_tree\nmboost\nâœ”\nâœ”\nâœ”\nâœ–\nâœ–\nâœ–\n\n\ndecision_tree\nrpart\nâœ”\nâœ”\nâœ–\nâœ–\nâœ–\nâœ–\n\n\ndecision_tree\npartykit\nâœ”\nâœ”\nâœ–\nâœ–\nâœ–\nâœ–\n\n\nproportional_hazards\nsurvival\nâœ”\nâœ”\nâœ”\nâœ–\nâœ–\nâœ–\n\n\nproportional_hazards\nglmnet\nâœ”\nâœ”\nâœ”\nâœ”\nâœ–\nâœ–\n\n\nrand_forest\npartykit\nâœ”\nâœ”\nâœ–\nâœ–\nâœ–\nâœ–\n\n\nrand_forest\naorsf\nâœ”\nâœ”\nâœ–\nâœ–\nâœ–\nâœ–\n\n\nsurvival_reg\nsurvival\nâœ”\nâœ”\nâœ”\nâœ–\nâœ”\nâœ”\n\n\nsurvival_reg\nflexsurv\nâœ”\nâœ”\nâœ”\nâœ–\nâœ”\nâœ”\n\n\nsurvival_reg\nflexsurvspline\nâœ”\nâœ”\nâœ”\nâœ–\nâœ”\nâœ”"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#section-2",
    "href": "slides/intro-03-what-makes-a-model.html#section-2",
    "title": "3 - What makes a model?",
    "section": "",
    "text": "model\nengine\ntime\nsurvival\nlinear_pred\nraw\nquantile\nhazard\n\n\n\n\nbag_tree\nrpart\nâœ”\nâœ”\nâœ–\nâœ–\nâœ–\nâœ–\n\n\nboost_tree\nmboost\nâœ”\nâœ”\nâœ”\nâœ–\nâœ–\nâœ–\n\n\ndecision_tree\nrpart\nâœ”\nâœ”\nâœ–\nâœ–\nâœ–\nâœ–\n\n\ndecision_tree\npartykit\nâœ”\nâœ”\nâœ–\nâœ–\nâœ–\nâœ–\n\n\nproportional_hazards\nsurvival\nâœ”\nâœ”\nâœ”\nâœ–\nâœ–\nâœ–\n\n\nproportional_hazards\nglmnet\nâœ”\nâœ”\nâœ”\nâœ”\nâœ–\nâœ–\n\n\nrand_forest\npartykit\nâœ”\nâœ”\nâœ–\nâœ–\nâœ–\nâœ–\n\n\nrand_forest\naorsf\nâœ”\nâœ”\nâœ–\nâœ–\nâœ–\nâœ–\n\n\nsurvival_reg\nsurvival\nâœ”\nâœ”\nâœ”\nâœ–\nâœ”\nâœ”\n\n\nsurvival_reg\nflexsurv\nâœ”\nâœ”\nâœ”\nâœ–\nâœ”\nâœ”\n\n\nsurvival_reg\nflexsurvspline\nâœ”\nâœ”\nâœ”\nâœ–\nâœ”\nâœ”"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#predict-with-your-model-1",
    "href": "slides/intro-03-what-makes-a-model.html#predict-with-your-model-1",
    "title": "3 - What makes a model?",
    "section": "Predict with your model   ",
    "text": "Predict with your model   \nHow do you use your new tree_fit model?\n\npredict(tree_fit, new_data = cat_test)\n#&gt; # A tibble: 452 Ã— 1\n#&gt;    .pred_time\n#&gt;         &lt;dbl&gt;\n#&gt;  1      1.11 \n#&gt;  2      1.11 \n#&gt;  3      1.11 \n#&gt;  4      1.11 \n#&gt;  5      1.11 \n#&gt;  6      2.42 \n#&gt;  7      0.556\n#&gt;  8      2.42 \n#&gt;  9      1.11 \n#&gt; 10      2.42 \n#&gt; # â„¹ 442 more rows"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#predict-with-your-model-2",
    "href": "slides/intro-03-what-makes-a-model.html#predict-with-your-model-2",
    "title": "3 - What makes a model?",
    "section": "Predict with your model   ",
    "text": "Predict with your model   \nHow do you use your new tree_fit model?\n\npredict(tree_fit, new_data = cat_test, type = \"time\")\n#&gt; # A tibble: 452 Ã— 1\n#&gt;    .pred_time\n#&gt;         &lt;dbl&gt;\n#&gt;  1      1.11 \n#&gt;  2      1.11 \n#&gt;  3      1.11 \n#&gt;  4      1.11 \n#&gt;  5      1.11 \n#&gt;  6      2.42 \n#&gt;  7      0.556\n#&gt;  8      2.42 \n#&gt;  9      1.11 \n#&gt; 10      2.42 \n#&gt; # â„¹ 442 more rows"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#predict-with-your-model-3",
    "href": "slides/intro-03-what-makes-a-model.html#predict-with-your-model-3",
    "title": "3 - What makes a model?",
    "section": "Predict with your model   ",
    "text": "Predict with your model   \n\npreds &lt;- predict(tree_fit, new_data = cat_test, type = \"survival\", eval_time = c(30, 365))\npreds\n#&gt; # A tibble: 452 Ã— 1\n#&gt;    .pred           \n#&gt;    &lt;list&gt;          \n#&gt;  1 &lt;tibble [2 Ã— 2]&gt;\n#&gt;  2 &lt;tibble [2 Ã— 2]&gt;\n#&gt;  3 &lt;tibble [2 Ã— 2]&gt;\n#&gt;  4 &lt;tibble [2 Ã— 2]&gt;\n#&gt;  5 &lt;tibble [2 Ã— 2]&gt;\n#&gt;  6 &lt;tibble [2 Ã— 2]&gt;\n#&gt;  7 &lt;tibble [2 Ã— 2]&gt;\n#&gt;  8 &lt;tibble [2 Ã— 2]&gt;\n#&gt;  9 &lt;tibble [2 Ã— 2]&gt;\n#&gt; 10 &lt;tibble [2 Ã— 2]&gt;\n#&gt; # â„¹ 442 more rows"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#predict-with-your-model-4",
    "href": "slides/intro-03-what-makes-a-model.html#predict-with-your-model-4",
    "title": "3 - What makes a model?",
    "section": "Predict with your model   ",
    "text": "Predict with your model   \n\npreds &lt;- predict(tree_fit, new_data = cat_test, type = \"survival\", eval_time = c(30, 365))\n\npreds$.pred[[1]]\n#&gt; # A tibble: 2 Ã— 2\n#&gt;   .eval_time .pred_survival\n#&gt;        &lt;dbl&gt;          &lt;dbl&gt;\n#&gt; 1         30        0.613  \n#&gt; 2        365        0.00810"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#decision-tree-2",
    "href": "slides/intro-03-what-makes-a-model.html#decision-tree-2",
    "title": "3 - What makes a model?",
    "section": "Decision tree",
    "text": "Decision tree"
  }
]