[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Survival analysis with tidymodels",
    "section": "",
    "text": "These are the materials for workshops on survival analysis with tidymodels. The tidymodels framework is a collection of packages for modeling and machine learning using tidyverse principles.\nThis course will teach you core tidymodels packages and their uses: data splitting/resampling with rsample, model fitting with parsnip, measuring model performance with yardstick, and basic model optimization with tune. Time permitting, you’ll be introduced to pre-processing using the recipes package. You’ll learn tidymodels syntax as well as the process of predictive modeling for tabular data."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Survival analysis with tidymodels",
    "section": "",
    "text": "These are the materials for workshops on survival analysis with tidymodels. The tidymodels framework is a collection of packages for modeling and machine learning using tidyverse principles.\nThis course will teach you core tidymodels packages and their uses: data splitting/resampling with rsample, model fitting with parsnip, measuring model performance with yardstick, and basic model optimization with tune. Time permitting, you’ll be introduced to pre-processing using the recipes package. You’ll learn tidymodels syntax as well as the process of predictive modeling for tabular data."
  },
  {
    "objectID": "index.html#is-this-workshop-for-me",
    "href": "index.html#is-this-workshop-for-me",
    "title": "Survival analysis with tidymodels",
    "section": "Is this workshop for me? ",
    "text": "Is this workshop for me? \nThis workshop is for you if you:\n\nare familiar with basic survival analysis such as censoring of time-to-event data, Kaplan-Meier curves, proportional hazards models\nare familiar with the basic predictive modeling workflow such as split in train and test set, resampling, tuning via grid search\nwant to learn how to leverage the tidymodels framework for survival analysis\n\nIntermediate or expert familiarity with modeling or machine learning is not required."
  },
  {
    "objectID": "index.html#preparation",
    "href": "index.html#preparation",
    "title": "Survival analysis with tidymodels",
    "section": "Preparation",
    "text": "Preparation\nThe process to set up your computer for either workshop will look the same. Please join the workshop with a computer that has the following installed (all available for free):\n\nA recent version of R, available at https://cran.r-project.org/\nA recent version of RStudio Desktop (RStudio Desktop Open Source License, at least v2022.02), available at https://posit.co/download/rstudio-desktop/\nThe following R packages, which you can install from the R console:\n\n\n# Install the packages for the workshop\npkgs &lt;- \n  c(\"aorsf\", \"censored\", \"glmnet\", \"partykit\", \"pec\", \"rpart\", \"tidymodels\")\n\ninstall.packages(pkgs)\n\nIf you’re a Windows user and encounter an error message during installation noting a missing Rtools installation, install Rtools using the installer linked here."
  },
  {
    "objectID": "index.html#slides",
    "href": "index.html#slides",
    "title": "Survival analysis with tidymodels",
    "section": "Slides",
    "text": "Slides\nThese slides are designed to use with live teaching and are published for workshop participants’ convenience. There are not meant as standalone learning materials. For that, we recommend tidymodels.org and Tidy Modeling with R.\n\n01: Introduction\n02: Your data budget\n03: What makes a model?\n04: Evaluating models\n05: Tuning models\n06: Wrapping up\n\nThere’s also a page for slide annotations; these are extra notes for selected slides."
  },
  {
    "objectID": "index.html#code",
    "href": "index.html#code",
    "title": "Survival analysis with tidymodels",
    "section": "Code",
    "text": "Code\nQuarto files for working along are available on GitHub. (Don’t worry if you haven’t used Quarto before; it will feel familiar to R Markdown users.)"
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "Survival analysis with tidymodels",
    "section": "Acknowledgments",
    "text": "Acknowledgments\n\nThis website, including the slides, is made with Quarto. Please submit an issue on the GitHub repo for this workshop if you find something that could be fixed or improved."
  },
  {
    "objectID": "index.html#reuse-and-licensing",
    "href": "index.html#reuse-and-licensing",
    "title": "Survival analysis with tidymodels",
    "section": "Reuse and licensing",
    "text": "Reuse and licensing\n\nUnless otherwise noted (i.e. not an original creation and reused from another source), these educational materials are licensed under Creative Commons Attribution CC BY-SA 4.0."
  },
  {
    "objectID": "slides/intro-06-wrapping-up.html",
    "href": "slides/intro-06-wrapping-up.html",
    "title": "6 - Wrapping up",
    "section": "",
    "text": "We made it!"
  },
  {
    "objectID": "slides/intro-06-wrapping-up.html#your-turn",
    "href": "slides/intro-06-wrapping-up.html#your-turn",
    "title": "6 - Wrapping up",
    "section": "Your turn",
    "text": "Your turn\n\nWhat is one thing you learned that surprised you?\nWhat is one thing you learned that you plan to use?\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/intro-06-wrapping-up.html#resources-to-keep-learning",
    "href": "slides/intro-06-wrapping-up.html#resources-to-keep-learning",
    "title": "6 - Wrapping up",
    "section": "Resources to keep learning",
    "text": "Resources to keep learning\n\n\nhttps://www.tidymodels.org/\n\n\n\n\nhttps://www.tmwr.org/\n\n\n\n\nhttp://www.feat.engineering/\n\n\n\n\nhttps://smltar.com/\n\n\n\nFollow us on Mastodon and at the tidyverse blog for updates!\n\n\n\nhttps://hfrick.github.io/tidymodels-survival-workshop"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html",
    "href": "slides/intro-04-evaluating-models.html",
    "title": "4 - Evaluating models",
    "section": "",
    "text": "#&gt; ── Attaching packages ──────────────────────────── tidymodels 1.2.0 ──\n#&gt; ✔ broom        1.0.6      ✔ rsample      1.2.1 \n#&gt; ✔ dials        1.2.1      ✔ tibble       3.2.1 \n#&gt; ✔ dplyr        1.1.4      ✔ tidyr        1.3.1 \n#&gt; ✔ infer        1.0.7      ✔ tune         1.2.1 \n#&gt; ✔ modeldata    1.4.0      ✔ workflows    1.1.4 \n#&gt; ✔ parsnip      1.2.1      ✔ workflowsets 1.1.0 \n#&gt; ✔ purrr        1.0.2      ✔ yardstick    1.3.1 \n#&gt; ✔ recipes      1.0.10\n#&gt; ── Conflicts ─────────────────────────────── tidymodels_conflicts() ──\n#&gt; ✖ purrr::discard() masks scales::discard()\n#&gt; ✖ dplyr::filter()  masks stats::filter()\n#&gt; ✖ dplyr::lag()     masks stats::lag()\n#&gt; ✖ recipes::step()  masks stats::step()\n#&gt; • Use tidymodels_prefer() to resolve common conflicts.\n#&gt; Loading required package: survival"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#an-example-model-fit",
    "href": "slides/intro-04-evaluating-models.html#an-example-model-fit",
    "title": "4 - Evaluating models",
    "section": "An Example Model Fit",
    "text": "An Example Model Fit\nLet’s fit another PH and add some nonlinear terms via splines:\n\n# First add all of the predictors...\nf &lt;- event_time ~ . -\n  # Then remove geocoded columns\n  longitude - latitude +\n  # Then add them back as spline terms\n  ns(longitude, df = 5) + ns(latitude, df = 5)\n\ncat_wflow &lt;- workflow(f, proportional_hazards())\n\ncph_spline_fit &lt;- cat_wflow %&gt;%\n  fit(data = cat_train)"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#predictions",
    "href": "slides/intro-04-evaluating-models.html#predictions",
    "title": "4 - Evaluating models",
    "section": "Predictions",
    "text": "Predictions\nFor our demo data set of n = 50 cats, the largest event time was 329.\nWe’ll make predictions from 8 days to 320 days:\n\ndemo_cat_preds &lt;- augment(cph_spline_fit, demo_cats, eval_time = 8:320)\ndemo_cat_preds %&gt;% select(1:3)\n#&gt; # A tibble: 50 × 3\n#&gt;    .pred              .pred_time event_time\n#&gt;    &lt;list&gt;                  &lt;dbl&gt;     &lt;Surv&gt;\n#&gt;  1 &lt;tibble [313 × 5]&gt;       58.9        36 \n#&gt;  2 &lt;tibble [313 × 5]&gt;      181.         16+\n#&gt;  3 &lt;tibble [313 × 5]&gt;      106.         12+\n#&gt;  4 &lt;tibble [313 × 5]&gt;       62.7        16 \n#&gt;  5 &lt;tibble [313 × 5]&gt;       31.4        22 \n#&gt;  6 &lt;tibble [313 × 5]&gt;       88.5        16 \n#&gt;  7 &lt;tibble [313 × 5]&gt;       48.2       294 \n#&gt;  8 &lt;tibble [313 × 5]&gt;      109.         68+\n#&gt;  9 &lt;tibble [313 × 5]&gt;       60.9        31 \n#&gt; 10 &lt;tibble [313 × 5]&gt;      104.         24+\n#&gt; # ℹ 40 more rows"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#concordance",
    "href": "slides/intro-04-evaluating-models.html#concordance",
    "title": "4 - Evaluating models",
    "section": "Concordance",
    "text": "Concordance\nThe concordance statistic (“c-index”, Harrell et al (1996)) is a metric that quantifies that the rank order of the times is consistent with some model score (e.g., a survival probability).\n\nIt takes into account censoring and does not depend on a specific evaluation time. The range of values is \\([-1, 1]\\).\n\ndemo_cat_preds %&gt;% \n  concordance_survival(event_time, estimate = .pred_time)\n#&gt; # A tibble: 1 × 3\n#&gt;   .metric              .estimator .estimate\n#&gt;   &lt;chr&gt;                &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 concordance_survival standard       0.668"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#time-dependent-metrics",
    "href": "slides/intro-04-evaluating-models.html#time-dependent-metrics",
    "title": "4 - Evaluating models",
    "section": "Time-dependent metrics",
    "text": "Time-dependent metrics\nWe pick specific time points to evaluate the model (depending on our problem) such as every 30 days:"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#classificationish-metrics",
    "href": "slides/intro-04-evaluating-models.html#classificationish-metrics",
    "title": "4 - Evaluating models",
    "section": "Classification(ish) Metrics",
    "text": "Classification(ish) Metrics\nMost dynamic metrics convert the survival probabilities to events and non-events based on some probability threshold.\nFrom there, we can apply existing classification metrics, such as\n\nBrier Score (for calibration)\nArea under the ROC curve (for separation)\n\nWe’ll talk about both of these.\nThere are more details on dynamics metrics at tidymodels.org."
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#converting-to-events",
    "href": "slides/intro-04-evaluating-models.html#converting-to-events",
    "title": "4 - Evaluating models",
    "section": "Converting to Events",
    "text": "Converting to Events\nFor a specific evaluation time point \\(\\tau\\), we convert the observed event time to a binary event/non-event version (if possible) (\\(y_{i\\tau} \\in \\{0, 1\\}\\)).\n\\[\ny_{i\\tau} =\n\\begin{cases}\n1 & \\text{if } t_{i} \\leq \\tau\\text{ and  event} \\notag \\\\\n0 & \\text{if } t_{i} \\gt \\tau \\text{ and } either \\notag \\\\\nmissing & \\text{if } t_{i} \\leq \\tau\\text{ and censored }\n\\end{cases}\n\\]"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#converting-to-events-1",
    "href": "slides/intro-04-evaluating-models.html#converting-to-events-1",
    "title": "4 - Evaluating models",
    "section": "Converting to Events",
    "text": "Converting to Events"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#dealing-with-missing-outcome-data",
    "href": "slides/intro-04-evaluating-models.html#dealing-with-missing-outcome-data",
    "title": "4 - Evaluating models",
    "section": "Dealing with Missing Outcome Data",
    "text": "Dealing with Missing Outcome Data\nWithout censored data points, this conversion would yield appropriate performance estimates since no event outcomes would be missing.\n\nOtherwise, there is the potential for bias due to missingness.\n\nWe’ll use tools from causal inference to compensate by creating a propensity score that uses the probability of being censored/missing.\nCase weights use the inverse of this probability. See Graf et al (1999)."
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#brier-score",
    "href": "slides/intro-04-evaluating-models.html#brier-score",
    "title": "4 - Evaluating models",
    "section": "Brier Score",
    "text": "Brier Score\nThe Brier score is calibration metric originally meant for classification models:\n\\[\nBrier = \\frac{1}{N}\\sum_{i=1}^N\\sum_{k=1}^C (y_{ik} - \\hat{\\pi}_{ik})^2\n\\]\nFor our application, we have two classes and case weights\n\n\\[\nBrier(t) = \\frac{1}{W}\\sum_{i=1}^N w_{it}\\left[\\underbrace{I(y_{it} = 0)(y_{it} - \\hat{p}_{it})^2}_\\text{non-events} +  \\underbrace{I(y_{it} = 1)(y_{it} - (1 - \\hat{p}_{it}))^2}_\\text{events}\\right]\n\\]"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#brier-scores",
    "href": "slides/intro-04-evaluating-models.html#brier-scores",
    "title": "4 - Evaluating models",
    "section": "Brier Scores",
    "text": "Brier Scores\n\ndemo_brier &lt;- brier_survival(demo_cat_preds, truth = event_time, .pred)\ndemo_brier %&gt;% filter(.eval_time %in% seq(30, 300, by = 30))\n#&gt; # A tibble: 10 × 4\n#&gt;    .metric        .estimator .eval_time .estimate\n#&gt;    &lt;chr&gt;          &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;\n#&gt;  1 brier_survival standard           30     0.163\n#&gt;  2 brier_survival standard           60     0.170\n#&gt;  3 brier_survival standard           90     0.151\n#&gt;  4 brier_survival standard          120     0.174\n#&gt;  5 brier_survival standard          150     0.164\n#&gt;  6 brier_survival standard          180     0.188\n#&gt;  7 brier_survival standard          210     0.147\n#&gt;  8 brier_survival standard          240     0.156\n#&gt;  9 brier_survival standard          270     0.161\n#&gt; 10 brier_survival standard          300     0.125"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#brier-scores-over-evaluation-time",
    "href": "slides/intro-04-evaluating-models.html#brier-scores-over-evaluation-time",
    "title": "4 - Evaluating models",
    "section": "Brier Scores Over Evaluation Time",
    "text": "Brier Scores Over Evaluation Time"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#integrated-brier-score",
    "href": "slides/intro-04-evaluating-models.html#integrated-brier-score",
    "title": "4 - Evaluating models",
    "section": "Integrated Brier Score",
    "text": "Integrated Brier Score\n\nbrier_survival_integrated(demo_cat_preds, truth = event_time, .pred)\n#&gt; # A tibble: 1 × 3\n#&gt;   .metric                   .estimator .estimate\n#&gt;   &lt;chr&gt;                     &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 brier_survival_integrated standard       0.152"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#area-under-the-roc-curve",
    "href": "slides/intro-04-evaluating-models.html#area-under-the-roc-curve",
    "title": "4 - Evaluating models",
    "section": "Area Under the ROC Curve",
    "text": "Area Under the ROC Curve\nThis is more straightforward.\n\nWe can use the standard ROC curve machinery once we have the indicators, probabilities, and censoring weights at evaluation time \\(\\tau\\) (Hung and Chiang (2010)).\n\nROC curves measure the separation between events and non-events and are ignorant of how well-calibrated the probabilities are."
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#area-under-the-roc-curve-1",
    "href": "slides/intro-04-evaluating-models.html#area-under-the-roc-curve-1",
    "title": "4 - Evaluating models",
    "section": "Area Under the ROC Curve",
    "text": "Area Under the ROC Curve\n\ndemo_row_auc &lt;- roc_auc_survival(demo_cat_preds, truth = event_time, .pred)\ndemo_row_auc %&gt;% filter(.eval_time %in% seq(30, 300, by = 30))\n#&gt; # A tibble: 10 × 4\n#&gt;    .metric          .estimator .eval_time .estimate\n#&gt;    &lt;chr&gt;            &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;\n#&gt;  1 roc_auc_survival standard           30     0.660\n#&gt;  2 roc_auc_survival standard           60     0.679\n#&gt;  3 roc_auc_survival standard           90     0.582\n#&gt;  4 roc_auc_survival standard          120     0.582\n#&gt;  5 roc_auc_survival standard          150     0.515\n#&gt;  6 roc_auc_survival standard          180     0.515\n#&gt;  7 roc_auc_survival standard          210     0.490\n#&gt;  8 roc_auc_survival standard          240     0.490\n#&gt;  9 roc_auc_survival standard          270     0.490\n#&gt; 10 roc_auc_survival standard          300     0.679"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#roc-auc-over-evaluation-time",
    "href": "slides/intro-04-evaluating-models.html#roc-auc-over-evaluation-time",
    "title": "4 - Evaluating models",
    "section": "ROC AUC Over Evaluation Time",
    "text": "ROC AUC Over Evaluation Time"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#using-evaluation-times",
    "href": "slides/intro-04-evaluating-models.html#using-evaluation-times",
    "title": "4 - Evaluating models",
    "section": "Using Evaluation Times",
    "text": "Using Evaluation Times\nWhen predicting, you can get predictions at any values of \\(\\tau\\).\n\nDuring model development, we suggest picking a more focused set of evaluation times (for computational time).\n\nYou should also pick a time to perform your optimizations/comparisons and list that value first in the vector. If 90 days was of interest, you might use\n\ntimes &lt;- c(90, 30, 60, 120)"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#your-turn",
    "href": "slides/intro-04-evaluating-models.html#your-turn",
    "title": "4 - Evaluating models",
    "section": "Your turn",
    "text": "Your turn\n\nWhy haven’t we done this?\n\ncph_spline_fit %&gt;%\n  augment(cat_train, eval_time = 8:320) %&gt;%\n  brier_survival(truth = event_time, .pred)\n\n\n\n\n−+\n05:00\n\n\n\n\n\nrepredicting the training set is overly optimistic\noptimising that leads to overfitting"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#cross-validation",
    "href": "slides/intro-04-evaluating-models.html#cross-validation",
    "title": "4 - Evaluating models",
    "section": "Cross-validation ",
    "text": "Cross-validation \n\nset.seed(123)\ncat_folds &lt;- vfold_cv(cat_train, v = 10)# v = 10 is default\ncat_folds\n#&gt; #  10-fold cross-validation \n#&gt; # A tibble: 10 × 2\n#&gt;    splits             id    \n#&gt;    &lt;list&gt;             &lt;chr&gt; \n#&gt;  1 &lt;split [1588/177]&gt; Fold01\n#&gt;  2 &lt;split [1588/177]&gt; Fold02\n#&gt;  3 &lt;split [1588/177]&gt; Fold03\n#&gt;  4 &lt;split [1588/177]&gt; Fold04\n#&gt;  5 &lt;split [1588/177]&gt; Fold05\n#&gt;  6 &lt;split [1589/176]&gt; Fold06\n#&gt;  7 &lt;split [1589/176]&gt; Fold07\n#&gt;  8 &lt;split [1589/176]&gt; Fold08\n#&gt;  9 &lt;split [1589/176]&gt; Fold09\n#&gt; 10 &lt;split [1589/176]&gt; Fold10"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#cross-validation-1",
    "href": "slides/intro-04-evaluating-models.html#cross-validation-1",
    "title": "4 - Evaluating models",
    "section": "Cross-validation ",
    "text": "Cross-validation \nWhat is in this?\n\ncat_folds &lt;- vfold_cv(cat_train)\ncat_folds$splits[1:3]\n#&gt; [[1]]\n#&gt; &lt;Analysis/Assess/Total&gt;\n#&gt; &lt;1588/177/1765&gt;\n#&gt; \n#&gt; [[2]]\n#&gt; &lt;Analysis/Assess/Total&gt;\n#&gt; &lt;1588/177/1765&gt;\n#&gt; \n#&gt; [[3]]\n#&gt; &lt;Analysis/Assess/Total&gt;\n#&gt; &lt;1588/177/1765&gt;\n\n\nSet the seed when creating resamples\n\nTalk about a list column, storing non-atomic types in dataframe"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#bootstrapping",
    "href": "slides/intro-04-evaluating-models.html#bootstrapping",
    "title": "4 - Evaluating models",
    "section": "Bootstrapping ",
    "text": "Bootstrapping \n\nset.seed(3214)\nbootstraps(cat_train)\n#&gt; # Bootstrap sampling \n#&gt; # A tibble: 25 × 2\n#&gt;    splits             id         \n#&gt;    &lt;list&gt;             &lt;chr&gt;      \n#&gt;  1 &lt;split [1765/657]&gt; Bootstrap01\n#&gt;  2 &lt;split [1765/644]&gt; Bootstrap02\n#&gt;  3 &lt;split [1765/625]&gt; Bootstrap03\n#&gt;  4 &lt;split [1765/638]&gt; Bootstrap04\n#&gt;  5 &lt;split [1765/647]&gt; Bootstrap05\n#&gt;  6 &lt;split [1765/655]&gt; Bootstrap06\n#&gt;  7 &lt;split [1765/655]&gt; Bootstrap07\n#&gt;  8 &lt;split [1765/637]&gt; Bootstrap08\n#&gt;  9 &lt;split [1765/669]&gt; Bootstrap09\n#&gt; 10 &lt;split [1765/638]&gt; Bootstrap10\n#&gt; # ℹ 15 more rows"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#the-whole-game---status-update",
    "href": "slides/intro-04-evaluating-models.html#the-whole-game---status-update",
    "title": "4 - Evaluating models",
    "section": "The whole game - status update",
    "text": "The whole game - status update"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#fit-our-model-to-the-resamples",
    "href": "slides/intro-04-evaluating-models.html#fit-our-model-to-the-resamples",
    "title": "4 - Evaluating models",
    "section": "Fit our model to the resamples",
    "text": "Fit our model to the resamples\n\ncat_res &lt;- fit_resamples(cat_wflow, cat_folds, eval_time = c(90, 30, 60, 120))\ncat_res\n#&gt; # Resampling results\n#&gt; # 10-fold cross-validation \n#&gt; # A tibble: 10 × 4\n#&gt;    splits             id     .metrics         .notes          \n#&gt;    &lt;list&gt;             &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;          \n#&gt;  1 &lt;split [1588/177]&gt; Fold01 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt;\n#&gt;  2 &lt;split [1588/177]&gt; Fold02 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt;\n#&gt;  3 &lt;split [1588/177]&gt; Fold03 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt;\n#&gt;  4 &lt;split [1588/177]&gt; Fold04 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt;\n#&gt;  5 &lt;split [1588/177]&gt; Fold05 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt;\n#&gt;  6 &lt;split [1589/176]&gt; Fold06 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt;\n#&gt;  7 &lt;split [1589/176]&gt; Fold07 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt;\n#&gt;  8 &lt;split [1589/176]&gt; Fold08 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt;\n#&gt;  9 &lt;split [1589/176]&gt; Fold09 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt;\n#&gt; 10 &lt;split [1589/176]&gt; Fold10 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt;"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#evaluating-model-performance",
    "href": "slides/intro-04-evaluating-models.html#evaluating-model-performance",
    "title": "4 - Evaluating models",
    "section": "Evaluating model performance ",
    "text": "Evaluating model performance \n\ncat_res %&gt;%\n  collect_metrics()\n#&gt; # A tibble: 4 × 7\n#&gt;   .metric        .estimator .eval_time  mean     n std_err .config             \n#&gt;   &lt;chr&gt;          &lt;chr&gt;           &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n#&gt; 1 brier_survival standard           30 0.212    10 0.00413 Preprocessor1_Model1\n#&gt; 2 brier_survival standard           60 0.246    10 0.00555 Preprocessor1_Model1\n#&gt; 3 brier_survival standard           90 0.207    10 0.00677 Preprocessor1_Model1\n#&gt; 4 brier_survival standard          120 0.158    10 0.0105  Preprocessor1_Model1\n\n\ncollect_metrics() is one of a suite of collect_*() functions that can be used to work with columns of tuning results. Most columns in a tuning result prefixed with . have a corresponding collect_*() function with options for common summaries.\n\n\nWe can reliably measure performance using only the training data 🎉"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#where-are-the-fitted-models",
    "href": "slides/intro-04-evaluating-models.html#where-are-the-fitted-models",
    "title": "4 - Evaluating models",
    "section": "Where are the fitted models? ",
    "text": "Where are the fitted models? \n\ncat_res\n#&gt; # Resampling results\n#&gt; # 10-fold cross-validation \n#&gt; # A tibble: 10 × 4\n#&gt;    splits             id     .metrics         .notes          \n#&gt;    &lt;list&gt;             &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;          \n#&gt;  1 &lt;split [1588/177]&gt; Fold01 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt;\n#&gt;  2 &lt;split [1588/177]&gt; Fold02 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt;\n#&gt;  3 &lt;split [1588/177]&gt; Fold03 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt;\n#&gt;  4 &lt;split [1588/177]&gt; Fold04 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt;\n#&gt;  5 &lt;split [1588/177]&gt; Fold05 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt;\n#&gt;  6 &lt;split [1589/176]&gt; Fold06 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt;\n#&gt;  7 &lt;split [1589/176]&gt; Fold07 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt;\n#&gt;  8 &lt;split [1589/176]&gt; Fold08 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt;\n#&gt;  9 &lt;split [1589/176]&gt; Fold09 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt;\n#&gt; 10 &lt;split [1589/176]&gt; Fold10 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt;\n\n\n🗑️"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#but-its-easy-to-save-the-predictions",
    "href": "slides/intro-04-evaluating-models.html#but-its-easy-to-save-the-predictions",
    "title": "4 - Evaluating models",
    "section": "But it’s easy to save the predictions ",
    "text": "But it’s easy to save the predictions \n\n# Save the assessment set results\nctrl_cat &lt;- control_resamples(save_pred = TRUE)\ncat_res &lt;- fit_resamples(cat_wflow, cat_folds, eval_time = c(90, 30, 60, 120),\n                         control = ctrl_cat)\n\ncat_res\n#&gt; # Resampling results\n#&gt; # 10-fold cross-validation \n#&gt; # A tibble: 10 × 5\n#&gt;    splits             id     .metrics         .notes           .predictions\n#&gt;    &lt;list&gt;             &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;           &lt;list&gt;      \n#&gt;  1 &lt;split [1588/177]&gt; Fold01 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n#&gt;  2 &lt;split [1588/177]&gt; Fold02 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n#&gt;  3 &lt;split [1588/177]&gt; Fold03 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n#&gt;  4 &lt;split [1588/177]&gt; Fold04 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n#&gt;  5 &lt;split [1588/177]&gt; Fold05 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n#&gt;  6 &lt;split [1589/176]&gt; Fold06 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n#&gt;  7 &lt;split [1589/176]&gt; Fold07 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n#&gt;  8 &lt;split [1589/176]&gt; Fold08 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n#&gt;  9 &lt;split [1589/176]&gt; Fold09 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n#&gt; 10 &lt;split [1589/176]&gt; Fold10 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#but-its-easy-to-collect-the-predictions",
    "href": "slides/intro-04-evaluating-models.html#but-its-easy-to-collect-the-predictions",
    "title": "4 - Evaluating models",
    "section": "But it’s easy to collect the predictions ",
    "text": "But it’s easy to collect the predictions \n\ncat_preds &lt;- collect_predictions(cat_res)\ncat_preds\n#&gt; # A tibble: 1,765 × 5\n#&gt;    .pred            id      .row event_time .config             \n#&gt;    &lt;list&gt;           &lt;chr&gt;  &lt;int&gt;     &lt;Surv&gt; &lt;chr&gt;               \n#&gt;  1 &lt;tibble [4 × 3]&gt; Fold01    13       139  Preprocessor1_Model1\n#&gt;  2 &lt;tibble [4 × 3]&gt; Fold01    14        40  Preprocessor1_Model1\n#&gt;  3 &lt;tibble [4 × 3]&gt; Fold01    33        10+ Preprocessor1_Model1\n#&gt;  4 &lt;tibble [4 × 3]&gt; Fold01    52       121  Preprocessor1_Model1\n#&gt;  5 &lt;tibble [4 × 3]&gt; Fold01    55        39+ Preprocessor1_Model1\n#&gt;  6 &lt;tibble [4 × 3]&gt; Fold01    70        15+ Preprocessor1_Model1\n#&gt;  7 &lt;tibble [4 × 3]&gt; Fold01    84        35  Preprocessor1_Model1\n#&gt;  8 &lt;tibble [4 × 3]&gt; Fold01    91        18  Preprocessor1_Model1\n#&gt;  9 &lt;tibble [4 × 3]&gt; Fold01    93        82+ Preprocessor1_Model1\n#&gt; 10 &lt;tibble [4 × 3]&gt; Fold01   100        11+ Preprocessor1_Model1\n#&gt; # ℹ 1,755 more rows"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#random-forest-1",
    "href": "slides/intro-04-evaluating-models.html#random-forest-1",
    "title": "4 - Evaluating models",
    "section": "Random forest 🌳🌲🌴🌵🌳🌳🌴🌲🌵🌴🌳🌵",
    "text": "Random forest 🌳🌲🌴🌵🌳🌳🌴🌲🌵🌴🌳🌵\n\nEnsemble many decision tree models\nAll the trees vote! 🗳️\nBootstrap aggregating + random predictor sampling\n\n\n\nOften works well without tuning hyperparameters (more on this in a moment), as long as there are enough trees"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#create-a-random-forest-model",
    "href": "slides/intro-04-evaluating-models.html#create-a-random-forest-model",
    "title": "4 - Evaluating models",
    "section": "Create a random forest model ",
    "text": "Create a random forest model \n\nrf_spec &lt;- rand_forest(trees = 1000) %&gt;% \n  set_engine(\"aorsf\") %&gt;% \n  set_mode(\"censored regression\")\nrf_spec\n#&gt; Random Forest Model Specification (censored regression)\n#&gt; \n#&gt; Main Arguments:\n#&gt;   trees = 1000\n#&gt; \n#&gt; Computational engine: aorsf"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#create-a-random-forest-model-1",
    "href": "slides/intro-04-evaluating-models.html#create-a-random-forest-model-1",
    "title": "4 - Evaluating models",
    "section": "Create a random forest model ",
    "text": "Create a random forest model \n\nrf_wflow &lt;- workflow(event_time ~ ., rf_spec)\nrf_wflow\n#&gt; ══ Workflow ══════════════════════════════════════════════════════════\n#&gt; Preprocessor: Formula\n#&gt; Model: rand_forest()\n#&gt; \n#&gt; ── Preprocessor ──────────────────────────────────────────────────────\n#&gt; event_time ~ .\n#&gt; \n#&gt; ── Model ─────────────────────────────────────────────────────────────\n#&gt; Random Forest Model Specification (censored regression)\n#&gt; \n#&gt; Main Arguments:\n#&gt;   trees = 1000\n#&gt; \n#&gt; Computational engine: aorsf"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#your-turn-1",
    "href": "slides/intro-04-evaluating-models.html#your-turn-1",
    "title": "4 - Evaluating models",
    "section": "Your turn",
    "text": "Your turn\n\nUse fit_resamples() and rf_wflow to:\n\nkeep predictions\ncompute metrics\n\n\n\n\n−+\n08:00"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#evaluating-model-performance-1",
    "href": "slides/intro-04-evaluating-models.html#evaluating-model-performance-1",
    "title": "4 - Evaluating models",
    "section": "Evaluating model performance ",
    "text": "Evaluating model performance \n\nctrl_cat &lt;- control_resamples(save_pred = TRUE)\n\n# Random forest uses random numbers so set the seed first\nset.seed(2)\nrf_res &lt;- fit_resamples(rf_wflow, cat_folds, eval_time = c(90, 30, 60, 120), \n                        control = ctrl_cat)\n\ncollect_metrics(rf_res)\n#&gt; # A tibble: 4 × 7\n#&gt;   .metric        .estimator .eval_time  mean     n std_err .config             \n#&gt;   &lt;chr&gt;          &lt;chr&gt;           &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n#&gt; 1 brier_survival standard           30 0.210    10 0.00423 Preprocessor1_Model1\n#&gt; 2 brier_survival standard           60 0.243    10 0.00520 Preprocessor1_Model1\n#&gt; 3 brier_survival standard           90 0.200    10 0.00731 Preprocessor1_Model1\n#&gt; 4 brier_survival standard          120 0.151    10 0.0103  Preprocessor1_Model1"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#the-whole-game---status-update-1",
    "href": "slides/intro-04-evaluating-models.html#the-whole-game---status-update-1",
    "title": "4 - Evaluating models",
    "section": "The whole game - status update",
    "text": "The whole game - status update"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#the-final-fit",
    "href": "slides/intro-04-evaluating-models.html#the-final-fit",
    "title": "4 - Evaluating models",
    "section": "The final fit ",
    "text": "The final fit \nSuppose that we are happy with our random forest model.\nLet’s fit the model on the training set and verify our performance using the test set.\n\nWe’ve shown you fit() and predict() (+ augment()) but there is a shortcut:\n\n# cat_split has train + test info\nfinal_fit &lt;- last_fit(rf_wflow, cat_split, eval_time = c(90, 30, 60, 120)) \n\nfinal_fit\n#&gt; # Resampling results\n#&gt; # Manual resampling \n#&gt; # A tibble: 1 × 6\n#&gt;   splits             id               .metrics .notes   .predictions .workflow \n#&gt;   &lt;list&gt;             &lt;chr&gt;            &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    \n#&gt; 1 &lt;split [1765/442]&gt; train/test split &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#what-is-in-final_fit",
    "href": "slides/intro-04-evaluating-models.html#what-is-in-final_fit",
    "title": "4 - Evaluating models",
    "section": "What is in final_fit? ",
    "text": "What is in final_fit? \n\ncollect_metrics(final_fit)\n#&gt; # A tibble: 4 × 5\n#&gt;   .metric        .estimator .eval_time .estimate .config             \n#&gt;   &lt;chr&gt;          &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;               \n#&gt; 1 brier_survival standard           30     0.217 Preprocessor1_Model1\n#&gt; 2 brier_survival standard           60     0.225 Preprocessor1_Model1\n#&gt; 3 brier_survival standard           90     0.160 Preprocessor1_Model1\n#&gt; 4 brier_survival standard          120     0.108 Preprocessor1_Model1\n\n\nThese are metrics computed with the test set"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#what-is-in-final_fit-1",
    "href": "slides/intro-04-evaluating-models.html#what-is-in-final_fit-1",
    "title": "4 - Evaluating models",
    "section": "What is in final_fit? ",
    "text": "What is in final_fit? \n\nextract_workflow(final_fit)\n#&gt; ══ Workflow [trained] ════════════════════════════════════════════════\n#&gt; Preprocessor: Formula\n#&gt; Model: rand_forest()\n#&gt; \n#&gt; ── Preprocessor ──────────────────────────────────────────────────────\n#&gt; event_time ~ .\n#&gt; \n#&gt; ── Model ─────────────────────────────────────────────────────────────\n#&gt; ---------- Oblique random survival forest\n#&gt; \n#&gt;      Linear combinations: Accelerated Cox regression\n#&gt;           N observations: 1765\n#&gt;                 N events: 1116\n#&gt;                  N trees: 1000\n#&gt;       N predictors total: 18\n#&gt;    N predictors per node: 6\n#&gt;  Average leaves per tree: 142.739\n#&gt; Min observations in leaf: 5\n#&gt;       Min events in leaf: 1\n#&gt;           OOB stat value: 0.63\n#&gt;            OOB stat type: Harrell's C-index\n#&gt;      Variable importance: anova\n#&gt; \n#&gt; -----------------------------------------\n\n\nUse this for prediction on new data, like for deploying"
  },
  {
    "objectID": "slides/intro-04-evaluating-models.html#the-whole-game",
    "href": "slides/intro-04-evaluating-models.html#the-whole-game",
    "title": "4 - Evaluating models",
    "section": "The whole game",
    "text": "The whole game\n\n\n\n\nhttps://hfrick.github.io/tidymodels-survival-workshop"
  },
  {
    "objectID": "slides/intro-02-data-budget.html",
    "href": "slides/intro-02-data-budget.html",
    "title": "2 - Your data budget",
    "section": "",
    "text": "The city of Long Beach releases data on animals at the Long Beach Animal Shelter.\nOur dataset is a sample of the cats entering and leaving the shelter.\nType ?cat_adoption or check the sources to learn more about this dataset, including references.\n\n\n\n\n\n\nCredit: https://www.svgrepo.com/svg/194185/pet-house-kennel"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#data-on-shelter-cats",
    "href": "slides/intro-02-data-budget.html#data-on-shelter-cats",
    "title": "2 - Your data budget",
    "section": "Data on shelter cats",
    "text": "Data on shelter cats\n\n\n\nThe city of Long Beach releases data on animals at the Long Beach Animal Shelter.\nOur dataset is a sample of the cats entering and leaving the shelter.\nType ?cat_adoption or check the sources to learn more about this dataset, including references.\n\n\n\n\n\n\nCredit: https://www.svgrepo.com/svg/194185/pet-house-kennel"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#data-on-shelter-cats-1",
    "href": "slides/intro-02-data-budget.html#data-on-shelter-cats-1",
    "title": "2 - Your data budget",
    "section": "Data on shelter cats",
    "text": "Data on shelter cats\n\nN = 2257\nA time-to-event outcome, consisting of the time spent at the shelter and the event status.\nAn event is a cat being homed by the Long Beach animal shelter.\nIf a cat is transfered to a different organization that works to home them, this is recorded as a non-event.\nSeveral nominal variables like sex, intake type and condition, as well as fur color.\nTwo numeric variables for the location of the intake or capture, latitiude and logitude."
  },
  {
    "objectID": "slides/intro-02-data-budget.html#data-on-shelter-cats-2",
    "href": "slides/intro-02-data-budget.html#data-on-shelter-cats-2",
    "title": "2 - Your data budget",
    "section": "Data on shelter cats",
    "text": "Data on shelter cats\n\nlibrary(tidymodels)\nlibrary(censored)\nlibrary(modeldata)\n\ncat_adoption\n#&gt; # A tibble: 2,257 × 20\n#&gt;     time event sex    neutered intake_condition intake_type   latitude longitude\n#&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;            &lt;fct&gt;            &lt;dbl&gt;     &lt;dbl&gt;\n#&gt;  1    17     1 male   yes      fractious        owner_surren…     33.8     -118.\n#&gt;  2    98     1 male   yes      normal           stray             33.8     -118.\n#&gt;  3    15     0 male   yes      ill_moderatete   owner_surren…     33.8     -118.\n#&gt;  4    72     1 female yes      fractious        owner_surren…     33.8     -118.\n#&gt;  5    22     0 male   yes      normal           owner_surren…     33.8     -118.\n#&gt;  6    66     1 male   yes      normal           owner_surren…     33.8     -118.\n#&gt;  7   200     1 female yes      other            other             33.9     -118.\n#&gt;  8     9     0 female yes      normal           owner_surren…     33.9     -118.\n#&gt;  9    45     1 male   yes      ill_mild         stray             33.8     -118.\n#&gt; 10    38     1 male   no       ill_mild         stray             33.9     -118.\n#&gt; # ℹ 2,247 more rows\n#&gt; # ℹ 12 more variables: black &lt;int&gt;, brown &lt;int&gt;, brown_tabby &lt;int&gt;,\n#&gt; #   calico &lt;int&gt;, cream &lt;int&gt;, gray &lt;int&gt;, gray_tabby &lt;int&gt;, orange &lt;int&gt;,\n#&gt; #   orange_tabby &lt;int&gt;, tan &lt;int&gt;, tortie &lt;int&gt;, white &lt;int&gt;"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#make-the-outcome",
    "href": "slides/intro-02-data-budget.html#make-the-outcome",
    "title": "2 - Your data budget",
    "section": "Make the outcome ",
    "text": "Make the outcome \n\ncat_adoption &lt;- cat_adoption %&gt;% \n  mutate(event_time = Surv(time, event), .keep = \"unused\", .before = everything())"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#data-splitting-and-spending",
    "href": "slides/intro-02-data-budget.html#data-splitting-and-spending",
    "title": "2 - Your data budget",
    "section": "Data splitting and spending",
    "text": "Data splitting and spending\nFor machine learning, we typically split data into training and test sets:\n\n\nThe training set is used to estimate model parameters.\nThe test set is used to find an independent assessment of model performance.\n\n\n\nDo not 🚫 use the test set during training."
  },
  {
    "objectID": "slides/intro-02-data-budget.html#data-splitting-and-spending-1",
    "href": "slides/intro-02-data-budget.html#data-splitting-and-spending-1",
    "title": "2 - Your data budget",
    "section": "Data splitting and spending",
    "text": "Data splitting and spending\n\nSpending too much data in training prevents us from computing a good assessment of predictive performance.\n\n\n\nSpending too much data in testing prevents us from computing a good estimate of model parameters."
  },
  {
    "objectID": "slides/intro-02-data-budget.html#your-turn",
    "href": "slides/intro-02-data-budget.html#your-turn",
    "title": "2 - Your data budget",
    "section": "Your turn",
    "text": "Your turn\n\nWhen is a good time to split your data?\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#the-initial-split",
    "href": "slides/intro-02-data-budget.html#the-initial-split",
    "title": "2 - Your data budget",
    "section": "The initial split ",
    "text": "The initial split \n\nset.seed(123)\ncat_split &lt;- initial_split(cat_adoption)\ncat_split\n#&gt; &lt;Training/Testing/Total&gt;\n#&gt; &lt;1692/565/2257&gt;\n\n\nHow much data in training vs testing? This function uses a good default, but this depends on your specific goal/data We will talk about more powerful ways of splitting, like stratification, later"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#accessing-the-data",
    "href": "slides/intro-02-data-budget.html#accessing-the-data",
    "title": "2 - Your data budget",
    "section": "Accessing the data ",
    "text": "Accessing the data \n\ncat_train &lt;- training(cat_split)\ncat_test &lt;- testing(cat_split)"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#the-training-set",
    "href": "slides/intro-02-data-budget.html#the-training-set",
    "title": "2 - Your data budget",
    "section": "The training set",
    "text": "The training set\n\ncat_train\n#&gt; # A tibble: 1,692 × 19\n#&gt;    event_time sex     neutered intake_condition   intake_type latitude longitude\n#&gt;        &lt;Surv&gt; &lt;fct&gt;   &lt;fct&gt;    &lt;fct&gt;              &lt;fct&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n#&gt;  1        33  male    yes      under_age_or_weig… stray           33.8     -118.\n#&gt;  2        37  female  yes      normal             stray           33.8     -118.\n#&gt;  3        65  female  yes      feral              stray           33.9     -118.\n#&gt;  4        10  male    yes      other              stray           33.8     -118.\n#&gt;  5         8  female  yes      fractious          stray           33.8     -118.\n#&gt;  6        58+ unknown unknown  normal             stray           33.8     -118.\n#&gt;  7       452  male    no       under_age_or_weig… stray           33.8     -118.\n#&gt;  8        66  male    yes      normal             owner_surr…     33.8     -118.\n#&gt;  9        25+ male    no       normal             stray           33.9     -118.\n#&gt; 10       111+ male    no       ill_mild           stray           33.8     -118.\n#&gt; # ℹ 1,682 more rows\n#&gt; # ℹ 12 more variables: black &lt;int&gt;, brown &lt;int&gt;, brown_tabby &lt;int&gt;,\n#&gt; #   calico &lt;int&gt;, cream &lt;int&gt;, gray &lt;int&gt;, gray_tabby &lt;int&gt;, orange &lt;int&gt;,\n#&gt; #   orange_tabby &lt;int&gt;, tan &lt;int&gt;, tortie &lt;int&gt;, white &lt;int&gt;"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#the-test-set",
    "href": "slides/intro-02-data-budget.html#the-test-set",
    "title": "2 - Your data budget",
    "section": "The test set ",
    "text": "The test set \n🙈\n\nThere are 565 rows and 19 columns in the test set."
  },
  {
    "objectID": "slides/intro-02-data-budget.html#your-turn-1",
    "href": "slides/intro-02-data-budget.html#your-turn-1",
    "title": "2 - Your data budget",
    "section": "Your turn",
    "text": "Your turn\n\nSplit your data so 20% is held out for the test set.\n\nExtension/Challenge: This is a simple random split. Which other types of splits can you think of and does rsample offer corresponding functions?\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#data-splitting-and-spending-2",
    "href": "slides/intro-02-data-budget.html#data-splitting-and-spending-2",
    "title": "2 - Your data budget",
    "section": "Data splitting and spending ",
    "text": "Data splitting and spending \n\nset.seed(123)\ncat_split &lt;- initial_split(cat_adoption, prop = 0.8)\ncat_train &lt;- training(cat_split)\ncat_test &lt;- testing(cat_split)\n\nnrow(cat_train)\n#&gt; [1] 1805\nnrow(cat_test)\n#&gt; [1] 452"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#data-splitting-and-spending-3",
    "href": "slides/intro-02-data-budget.html#data-splitting-and-spending-3",
    "title": "2 - Your data budget",
    "section": "Data splitting and spending ",
    "text": "Data splitting and spending \nWe’ll use this setup:\n\nset.seed(27)\nin_demo &lt;- sample.int(nrow(cat_adoption), 50)\ndemo_cats &lt;- cat_adoption %&gt;% slice(in_demo)\n\nset.seed(123)\ncat_split &lt;- initial_split(cat_adoption %&gt;% slice(-in_demo), prop = 0.8)\ncat_train &lt;- training(cat_split)\ncat_test &lt;- testing(cat_split)"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#your-turn-2",
    "href": "slides/intro-02-data-budget.html#your-turn-2",
    "title": "2 - Your data budget",
    "section": "Your turn",
    "text": "Your turn\n\nExplore the cat_train data on your own!\n\nWhat does the Kaplan-Meier curve look like for the outcome, event_time?\nHow does event_time differ across the categorical variables?\nWhat’s the distribution of the location information, latitude and longitude?\n\n\nExtension/Challenge:\nHow would you visualize the relationship between the outcome\nand longitude and latitude, respectively?\n\n\n\n−+\n08:00\n\n\n\n\nMake a plot or summary and then share with neighbor"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#time-to-adoption",
    "href": "slides/intro-02-data-budget.html#time-to-adoption",
    "title": "2 - Your data budget",
    "section": "Time to adoption ",
    "text": "Time to adoption \n\nlibrary(ggsurvfit)\nsurvfit(event_time ~ 1, data = cat_adoption) %&gt;% ggsurvfit()"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#section",
    "href": "slides/intro-02-data-budget.html#section",
    "title": "2 - Your data budget",
    "section": "",
    "text": "survfit(event_time ~ neutered, data = cat_train) %&gt;% ggsurvfit()"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#section-1",
    "href": "slides/intro-02-data-budget.html#section-1",
    "title": "2 - Your data budget",
    "section": "",
    "text": "survfit(event_time ~ brown_tabby, data = cat_train) %&gt;% ggsurvfit()"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#section-2",
    "href": "slides/intro-02-data-budget.html#section-2",
    "title": "2 - Your data budget",
    "section": "",
    "text": "survfit(event_time ~ gray, data = cat_train) %&gt;% ggsurvfit()"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#section-3",
    "href": "slides/intro-02-data-budget.html#section-3",
    "title": "2 - Your data budget",
    "section": "",
    "text": "library(leaflet)\ncat_train %&gt;% \n  leaflet() %&gt;%\n  addProviderTiles(\"CartoDB.Positron\") %&gt;%  \n  addCircles(lng = ~ longitude, lat = ~ latitude)"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#section-4",
    "href": "slides/intro-02-data-budget.html#section-4",
    "title": "2 - Your data budget",
    "section": "",
    "text": "smooth_ph_linear_pred(event_time ~ latitude, data = cat_adoption, deg_free = 6)\n\n\nsmooth_ph_linear_pred() a custom function, available\nin slides/setup.R.\n\nlatitude ~ “y-axis”"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#section-5",
    "href": "slides/intro-02-data-budget.html#section-5",
    "title": "2 - Your data budget",
    "section": "",
    "text": "smooth_ph_linear_pred(event_time ~ longitude, data = cat_adoption, deg_free = 5)\n\n\n\nlongitude ~ “x-axis”"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#the-whole-game---status-update",
    "href": "slides/intro-02-data-budget.html#the-whole-game---status-update",
    "title": "2 - Your data budget",
    "section": "The whole game - status update",
    "text": "The whole game - status update\n\n\n\n\nhttps://hfrick.github.io/tidymodels-survival-workshop"
  },
  {
    "objectID": "slides/annotations.html#section",
    "href": "slides/annotations.html#section",
    "title": "Annotations",
    "section": "👀",
    "text": "👀\nThis page contains annotations for selected slides.\nThere’s a lot that we want to tell you. We don’t want people to have to frantically scribble down things that we say that are not on the slides.\nWe’ve added sections to this document with longer explanations and links to other resources."
  },
  {
    "objectID": "slides/annotations.html#the-initial-split",
    "href": "slides/annotations.html#the-initial-split",
    "title": "Annotations",
    "section": "The initial split",
    "text": "The initial split\nWhat does set.seed() do?\nWe’ll use pseudo-random numbers (PRN) to partition the data into training and testing. PRN are numbers that emulate truly random numbers (but really are not truly random).\nThink of PRN as a box that takes a starting value (the “seed”) that produces random numbers using that starting value as an input into its process.\nIf we know a seed value, we can reproduce our “random” numbers. To use a different set of random numbers, choose a different seed value.\nFor example:\n\nset.seed(1)\nrunif(3)\n#&gt; [1] 0.2655087 0.3721239 0.5728534\n\n# Get a new set of random numbers:\nset.seed(2)\nrunif(3)\n#&gt; [1] 0.1848823 0.7023740 0.5733263\n\n# We can reproduce the old ones with the same seed\nset.seed(1)\nrunif(3)\n#&gt; [1] 0.2655087 0.3721239 0.5728534\n\nIf we don’t set the seed, R uses the clock time and the process ID to create a seed. This isn’t reproducible.\nSince we want our code to be reproducible, we set the seeds before random numbers are used.\nIn theory, you can set the seed once at the start of a script. However, if we do interactive data analysis, we might unwittingly use random numbers while coding. In that case, the stream is not the same and we don’t get reproducible results.\nThe value of the seed is an integer and really has no meaning. Max has a script to generate random integers to use as seeds to “spread the randomness around”. It is basically:\n\ncat(paste0(\"set.seed(\", sample.int(10000, 5), \")\", collapse = \"\\n\"))\n#&gt; set.seed(9725)\n#&gt; set.seed(8462)\n#&gt; set.seed(4050)\n#&gt; set.seed(8789)\n#&gt; set.seed(1301)"
  },
  {
    "objectID": "slides/annotations.html#what-is-wrong-with-this",
    "href": "slides/annotations.html#what-is-wrong-with-this",
    "title": "Annotations",
    "section": "What is wrong with this?",
    "text": "What is wrong with this?\nIf we treat the preprocessing as a separate task, it raises the risk that we might accidentally overfit to the data at hand.\nFor example, someone might estimate something from the entire data set (such as the principle components) and treat that data as if it were known (and not estimated). Depending on the what was done with the data, consequences in doing that could be:\n\nYour performance metrics are slightly-to-moderately optimistic (e.g. you might think your accuracy is 85% when it is actually 75%)\nA consequential component of the analysis is not right and the model just doesn’t work.\n\nThe big issue here is that you won’t be able to figure this out until you get a new piece of data, such as the test set.\nA really good example of this is in ‘Selection bias in gene extraction on the basis of microarray gene-expression data’. The authors re-analyze a previous publication and show that the original researchers did not include feature selection in the workflow. Because of that, their performance statistics were extremely optimistic. In one case, they could do the original analysis on complete noise and still achieve zero errors.\nGenerally speaking, this problem is referred to as data leakage. Some other references:\n\nOverfitting to Predictors and External Validation\nAre We Learning Yet? A Meta Review of Evaluation Failures Across Machine Learning\nNavigating the pitfalls of applying machine learning in genomics\nA review of feature selection techniques in bioinformatics\nOn Over-fitting in Model Selection and Subsequent Selection Bias in Performance Evaluation"
  },
  {
    "objectID": "slides/annotations.html#an-example-model-fit",
    "href": "slides/annotations.html#an-example-model-fit",
    "title": "Annotations",
    "section": "An Example Model Fit",
    "text": "An Example Model Fit\nFirst, in regards to the weird formula assembly: this is a lot easier if we use a recipe.\nSecondly, a popular feature of the proportional hazards model is that it can use stratification; in this case, a different baseline hazard is created for each level of some factor variable. When using the survival package, you can use a “special” function to add this to the model:\ncph_strata_fit &lt;- \n  proportional_hazards() %&gt;%\n  fit(event_time ~ latitude + longitude + strata(sex), data = cat_train)\nThe glmnet package can also use stratification, but its syntax is unconventional. tidymodels allows you to use the same syntax from the survival package to compute this model:\nglmn_strata_fit &lt;- \n  proportional_hazards(penalty = 0.01) %&gt;%\n  set_engine(\"glmnet\") %&gt;% \n  fit(event_time ~ latitude + longitude + strata(sex), data = cat_train)\nThis is a little model complex when using a workflow.\nIn R, the model formula does various things: it specifies statistical details (e.g., random effects), data transformations (via in-line functions), encodes data as dummy variables, and so on.\nWhen using add_formula() with a workflow, that formula exclusively encodes data and is not directly executed by the model function. This means that if you have a formula with special inline functions, you must add the formula another way. This can affect adding a strata variable for a censored regression model, a smooth for a generalized additive model, random effects for the lme4 package, etc.\nSuppose we have a factor to use as strata (such as sex in our cat data). Since that is a factor, and survival::cph() needs numeric data, add_formula() will convert sex to a dummy variable. That would prevent you from using it in strata().\nFor workflows with special formulas, we suggest using add_variables() instead of add_formula(). To use the formula intended for the underlying model, there is an option to add_model() to do so. For example:\nworkflow() %&gt;% \n  add_variables(\n    # Adds raw variables with tidyr-like specifications. These will\n    # remain in the data as-is.\n    outcomes = c(event_time), \n    predictors = c(latitude, longitude, sex)\n  ) %&gt;% \n  add_model(\n    proportional_hazards(),\n    # Your model-specific formula goes here: \n    formula = event_time ~ latitude + longitude + strata(sex)\n  ) \nThere are more examples in Section 7.4.1 of Tidy Models with R."
  },
  {
    "objectID": "slides/annotations.html#converting-to-events",
    "href": "slides/annotations.html#converting-to-events",
    "title": "Annotations",
    "section": "Converting to Events",
    "text": "Converting to Events\nThe predicted class probabilities are then:\n\\[\n\\begin{align}\nPr[y_{i\\tau} = 1] &= 1- \\hat{S}(\\tau; \\boldsymbol{x}_{i})\\notag \\\\\nPr[y_{i\\tau} = 0] &= \\hat{S}(\\tau; \\boldsymbol{x}_{i}) \\notag\n\\end{align}\n\\]"
  },
  {
    "objectID": "slides/annotations.html#dealing-with-missing-outcome-data",
    "href": "slides/annotations.html#dealing-with-missing-outcome-data",
    "title": "Annotations",
    "section": "Dealing with Missing Outcome Data",
    "text": "Dealing with Missing Outcome Data\nFor our causal inference approach, we need to compute \\(\\hat{C}(t^*;\\boldsymbol{x}_{i})\\), the probability that sample \\(i\\) is censored at some time \\(t^*\\).\nWe have to consider how to compute the time point \\(t^*\\). Let’s say we are predicting what will happen at \\(t^* = 17\\) days.\nFirst, we are predicting future events, so we can only assume that we have data prior to 17 days. For this reason, when we use the observed time to compute the probability of censoring, we do it just prior to \\(t^*\\), at \\(t_i - \\epsilon\\) for some very small \\(\\epsilon\\).\nSecond, following Graf et al. (1999), we calculate the censoring probability differently for each event class:\n\\[\nt_i^*=\n\\begin{cases}\nt_i  - \\epsilon &  \\text{if }t_i \\le \\tau \\\\ \\notag\n\\tau - \\epsilon &  \\text{if }t_i &gt; \\tau  \\notag\n\\end{cases}\n\\]\nHow exactly do we estimate \\(\\hat{C}(t^*;\\boldsymbol{x}_{i})\\)? We currently only estimate the probability of non-informative right censoring (i.e., the predictors \\(x_i\\) are ignored). We may expand this API in the future when you have informative censoring.\nOur estimator \\(\\hat{C}(T;x_i)\\) is the “reverse Kaplan-Meier” (RKM, Korn (1986)) curve that inverts the event indicator.\nThe RKM curve is attached to the parsnip model object. Its curve:\n\n\n\n\n\n\n\n\n\nNow let’s look at how the probabilities are computed for four specific cats:\n\n\n\n\n\n\n\n\n\nWe’ve truncated the x-axis for readability.\nFrom this:\n\nAt \\(\\tau = 10\\), all four cats are used to measure performance and \\(t^*_i = t_i - \\epsilon\\).\nAt \\(\\tau = 30\\), only two cats are used and \\(t^*_1 = 36 - \\epsilon\\) and \\(t^*_4 = 30 - \\epsilon\\).\n\nHow the censoring probability varies over time can greatly impact the metrics. For the demonstration set, there are very few usable outcomes in the late stages of the analysis, but these have large weights.\n\n\n\n\n\n\n\n\n\nCase weights \\(w_i(\\tau)\\) are the inverse of these probabilities and \\(W(\\tau)\\) is their sum."
  },
  {
    "objectID": "slides/annotations.html#brier-scores-over-evaluation-time",
    "href": "slides/annotations.html#brier-scores-over-evaluation-time",
    "title": "Annotations",
    "section": "Brier Scores Over Evaluation Time",
    "text": "Brier Scores Over Evaluation Time\nIt’s reasonable to wonder about the uncertainty in these statistics, especially for a sample size of 50. When we get to resampling (in a bit), we will have standard errors of statistics that we can use to make confidence intervals.\nWe can use the bootstrap method to compute confidence intervals for a single data set (e.g., a validation set). A tidymodels function called int_pctl() is available for this purpose (more information). This will be able to work directly with objects resulting form resampling or tuning functions (again, in a bit) but for a single data set, we’ll need to create a wrapper that computes the statistic for different bootstrap samples.\n\nbrier_wrapper &lt;- function(split) {\n  dat &lt;- analysis(split)\n  brier_survival(dat, truth = event_time, .pred) %&gt;% \n    # Puts the data into a 'tidy' format:\n    dplyr::select(term = .eval_time, estimate = .estimate)\n}\n\nWe execute that on every bootstrap sample and then use int_pctl() on the results.\n\nset.seed(482)\nbrier_ci &lt;- \n  demo_cat_preds %&gt;% \n  bootstraps(times = 2000) %&gt;% \n  mutate(stats = map(splits, brier_wrapper)) %&gt;% \n  int_pctl(stats, alpha = 0.10) # 90% intervals\n\nYep, statistics from 50 cats has a lot of variation!\n\nbrier_ci %&gt;% \n  ggplot(aes(term, .estimate)) + \n  geom_line() + \n  geom_ribbon(\n    aes(ymin = .lower, ymax = .upper), \n    alpha = 1 / 10, \n    fill = \"blue\") +\n  labs(x = \"Evaluation time\", y = \"Brier score\")"
  },
  {
    "objectID": "slides/annotations.html#cross-validation",
    "href": "slides/annotations.html#cross-validation",
    "title": "Annotations",
    "section": "Cross-validation",
    "text": "Cross-validation\nIn the future, we might enable the strata argument of the resampling functions to accept Surv objects and stratify by the censoring indicator."
  },
  {
    "objectID": "slides/annotations.html#bootstrapping",
    "href": "slides/annotations.html#bootstrapping",
    "title": "Annotations",
    "section": "Bootstrapping",
    "text": "Bootstrapping\nDavison and Hinkley (1997) have specific methods for bootstrapping censored data. These are not currently implemented in the rsample package."
  },
  {
    "objectID": "slides/annotations.html#evaluating-model-performance",
    "href": "slides/annotations.html#evaluating-model-performance",
    "title": "Annotations",
    "section": "Evaluating model performance",
    "text": "Evaluating model performance\nNote that there is a column for std_err so that we can compute confidence intervals from these."
  },
  {
    "objectID": "slides/intro-01-introduction.html",
    "href": "slides/intro-01-introduction.html",
    "title": "1 - Introduction",
    "section": "",
    "text": "Welcome!"
  },
  {
    "objectID": "slides/intro-01-introduction.html#workshop-policies",
    "href": "slides/intro-01-introduction.html#workshop-policies",
    "title": "1 - Introduction",
    "section": "Workshop policies",
    "text": "Workshop policies\n\nPlease review the code of conduct: https://events.linuxfoundation.org/user/attend/code-of-conduct/"
  },
  {
    "objectID": "slides/intro-01-introduction.html#who-are-you",
    "href": "slides/intro-01-introduction.html#who-are-you",
    "title": "1 - Introduction",
    "section": "Who are you?",
    "text": "Who are you?\n\nYou can use the magrittr %&gt;% or base R |&gt; pipe\nYou are familiar with functions from dplyr, tidyr, ggplot2\nYou have exposure to basic concepts of survival analysis\nYou are familiar with the basic predictive modeling workflow\nYou do not need intermediate or expert familiarity with modeling or ML"
  },
  {
    "objectID": "slides/intro-01-introduction.html#who-are-tidymodels",
    "href": "slides/intro-01-introduction.html#who-are-tidymodels",
    "title": "1 - Introduction",
    "section": "Who are tidymodels?",
    "text": "Who are tidymodels?\n\nSimon Couch\nHannah Frick\nEmil Hvitfeldt\nMax Kuhn\n\n\nMany thanks to Davis Vaughan, Julia Silge, David Robinson, Julie Jung, Alison Hill, and Desirée De Leon for their role in creating these materials!"
  },
  {
    "objectID": "slides/intro-01-introduction.html#asking-for-help",
    "href": "slides/intro-01-introduction.html#asking-for-help",
    "title": "1 - Introduction",
    "section": "Asking for help",
    "text": "Asking for help\n\n🟪 “I’m stuck and need help!”\n\n\n🟩 “I finished the exercise”"
  },
  {
    "objectID": "slides/intro-01-introduction.html#section-2",
    "href": "slides/intro-01-introduction.html#section-2",
    "title": "1 - Introduction",
    "section": "👀",
    "text": "👀"
  },
  {
    "objectID": "slides/intro-01-introduction.html#plan-for-this-workshop",
    "href": "slides/intro-01-introduction.html#plan-for-this-workshop",
    "title": "1 - Introduction",
    "section": "Plan for this workshop",
    "text": "Plan for this workshop\n\nYour data budget\nWhat makes a model\nEvaluating models\nTuning models"
  },
  {
    "objectID": "slides/intro-01-introduction.html#section-3",
    "href": "slides/intro-01-introduction.html#section-3",
    "title": "1 - Introduction",
    "section": "",
    "text": "Introduce yourself to your neighbors 👋\n\n Log in to Posit Cloud (free): TODO-ADD-LATER"
  },
  {
    "objectID": "slides/intro-01-introduction.html#what-is-machine-learning",
    "href": "slides/intro-01-introduction.html#what-is-machine-learning",
    "title": "1 - Introduction",
    "section": "What is machine learning?",
    "text": "What is machine learning?\n\n\nhttps://xkcd.com/1838/"
  },
  {
    "objectID": "slides/intro-01-introduction.html#what-is-machine-learning-1",
    "href": "slides/intro-01-introduction.html#what-is-machine-learning-1",
    "title": "1 - Introduction",
    "section": "What is machine learning?",
    "text": "What is machine learning?\n\n\nIllustration credit: https://vas3k.com/blog/machine_learning/"
  },
  {
    "objectID": "slides/intro-01-introduction.html#what-is-machine-learning-2",
    "href": "slides/intro-01-introduction.html#what-is-machine-learning-2",
    "title": "1 - Introduction",
    "section": "What is machine learning?",
    "text": "What is machine learning?\n\n\nIllustration credit: https://vas3k.com/blog/machine_learning/"
  },
  {
    "objectID": "slides/intro-01-introduction.html#your-turn",
    "href": "slides/intro-01-introduction.html#your-turn",
    "title": "1 - Introduction",
    "section": "Your turn",
    "text": "Your turn\n\n\nHow are statistics and machine learning related?\nHow are they similar? Different?\n\n\n\n−+\n03:00\n\n\n\n\nthe “two cultures”\nmodel first vs. data first\ninference vs. prediction"
  },
  {
    "objectID": "slides/intro-01-introduction.html#what-is-tidymodels",
    "href": "slides/intro-01-introduction.html#what-is-tidymodels",
    "title": "1 - Introduction",
    "section": "What is tidymodels? ",
    "text": "What is tidymodels? \n\nlibrary(tidymodels)\n#&gt; ── Attaching packages ──────────────────────────── tidymodels 1.2.0 ──\n#&gt; ✔ broom        1.0.6      ✔ rsample      1.2.1 \n#&gt; ✔ dials        1.2.1      ✔ tibble       3.2.1 \n#&gt; ✔ dplyr        1.1.4      ✔ tidyr        1.3.1 \n#&gt; ✔ infer        1.0.7      ✔ tune         1.2.1 \n#&gt; ✔ modeldata    1.4.0      ✔ workflows    1.1.4 \n#&gt; ✔ parsnip      1.2.1      ✔ workflowsets 1.1.0 \n#&gt; ✔ purrr        1.0.2      ✔ yardstick    1.3.1 \n#&gt; ✔ recipes      1.0.10\n#&gt; ── Conflicts ─────────────────────────────── tidymodels_conflicts() ──\n#&gt; ✖ purrr::discard() masks scales::discard()\n#&gt; ✖ dplyr::filter()  masks stats::filter()\n#&gt; ✖ dplyr::lag()     masks stats::lag()\n#&gt; ✖ recipes::step()  masks stats::step()\n#&gt; • Search for functions across packages at https://www.tidymodels.org/find/"
  },
  {
    "objectID": "slides/intro-01-introduction.html#the-whole-game",
    "href": "slides/intro-01-introduction.html#the-whole-game",
    "title": "1 - Introduction",
    "section": "The whole game",
    "text": "The whole game\n\nRoadmap for today\nMinimal version of predictive modeling process\nFeature engineering and tuning as iterative extensions"
  },
  {
    "objectID": "slides/intro-01-introduction.html#the-whole-game-1",
    "href": "slides/intro-01-introduction.html#the-whole-game-1",
    "title": "1 - Introduction",
    "section": "The whole game",
    "text": "The whole game"
  },
  {
    "objectID": "slides/intro-01-introduction.html#the-whole-game-2",
    "href": "slides/intro-01-introduction.html#the-whole-game-2",
    "title": "1 - Introduction",
    "section": "The whole game",
    "text": "The whole game\n\n\nStress that we are not fitting a model on the entire training set other than for illustrative purposes in deck 2."
  },
  {
    "objectID": "slides/intro-01-introduction.html#the-whole-game-3",
    "href": "slides/intro-01-introduction.html#the-whole-game-3",
    "title": "1 - Introduction",
    "section": "The whole game",
    "text": "The whole game"
  },
  {
    "objectID": "slides/intro-01-introduction.html#the-whole-game-4",
    "href": "slides/intro-01-introduction.html#the-whole-game-4",
    "title": "1 - Introduction",
    "section": "The whole game",
    "text": "The whole game"
  },
  {
    "objectID": "slides/intro-01-introduction.html#the-whole-game-5",
    "href": "slides/intro-01-introduction.html#the-whole-game-5",
    "title": "1 - Introduction",
    "section": "The whole game",
    "text": "The whole game"
  },
  {
    "objectID": "slides/intro-01-introduction.html#the-whole-game-6",
    "href": "slides/intro-01-introduction.html#the-whole-game-6",
    "title": "1 - Introduction",
    "section": "The whole game",
    "text": "The whole game"
  },
  {
    "objectID": "slides/intro-01-introduction.html#the-whole-game-7",
    "href": "slides/intro-01-introduction.html#the-whole-game-7",
    "title": "1 - Introduction",
    "section": "The whole game",
    "text": "The whole game"
  },
  {
    "objectID": "slides/intro-01-introduction.html#lets-install-some-packages",
    "href": "slides/intro-01-introduction.html#lets-install-some-packages",
    "title": "1 - Introduction",
    "section": "Let’s install some packages",
    "text": "Let’s install some packages\nIf you are using your own laptop instead of Posit Cloud:\n\n# Install the packages for the workshop\npkgs &lt;- c(\"aorsf\", \"censored\", \"glmnet\", \"partykit\", \"pec\", \"rpart\", \"tidymodels\")\n\ninstall.packages(pkgs)\n\n\n Or log in to Posit Cloud:\nTODO-ADD-LATER"
  },
  {
    "objectID": "slides/intro-01-introduction.html#our-versions",
    "href": "slides/intro-01-introduction.html#our-versions",
    "title": "1 - Introduction",
    "section": "Our versions",
    "text": "Our versions\nR version 4.4.0 (2024-04-24), Quarto (1.4.555)\n\n\n\n\n\n\n\npackage\nversion\n\n\n\n\naorsf\n0.1.5\n\n\nbroom\n1.0.6\n\n\ncensored\n0.3.2\n\n\ndials\n1.2.1\n\n\ndplyr\n1.1.4\n\n\nggplot2\n3.5.1\n\n\nglmnet\n4.1-8\n\n\n\n\n\n\n\n\n\n\n\npackage\nversion\n\n\n\n\nlibcoin\n1.0-10\n\n\nmodeldata\n1.4.0\n\n\nmvtnorm\n1.2-5\n\n\nparsnip\n1.2.1\n\n\npartykit\n1.2-20\n\n\npec\n2023.04.12\n\n\nprodlim\n2023.08.28\n\n\n\n\n\n\n\n\n\n\n\npackage\nversion\n\n\n\n\npurrr\n1.0.2\n\n\nrecipes\n1.0.10\n\n\nrpart\n4.1.23\n\n\nrsample\n1.2.1\n\n\nscales\n1.3.0\n\n\nsurvival\n3.7-0\n\n\ntibble\n3.2.1\n\n\n\n\n\n\n\n\n\n\n\npackage\nversion\n\n\n\n\ntidymodels\n1.2.0\n\n\ntidyr\n1.3.1\n\n\ntune\n1.2.1\n\n\nworkflows\n1.1.4\n\n\nworkflowsets\n1.1.0\n\n\nyardstick\n1.3.1\n\n\n\n\n\n\n\n\n\n\nhttps://hfrick.github.io/tidymodels-survival-workshop"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html",
    "href": "slides/intro-03-what-makes-a-model.html",
    "title": "3 - What makes a model?",
    "section": "",
    "text": "How do you fit a linear model in R? \nHow many different ways can you think of?\n\n\n\n−+\n03:00\n\n\n\n. . .\n\nlm for linear model\nglm for generalized linear model (e.g. logistic regression)\nglmnet for regularized regression\nkeras for regression using TensorFlow\nstan for Bayesian regression\nspark for large data sets"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#your-turn",
    "href": "slides/intro-03-what-makes-a-model.html#your-turn",
    "title": "3 - What makes a model?",
    "section": "Your turn",
    "text": "Your turn\n\nHow do you fit a linear model in R? \nHow many different ways can you think of?\n\n\n\n−+\n03:00\n\n\n\n\n\nlm for linear model\nglm for generalized linear model (e.g. logistic regression)\nglmnet for regularized regression\nkeras for regression using TensorFlow\nstan for Bayesian regression\nspark for large data sets"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#to-specify-a-model",
    "href": "slides/intro-03-what-makes-a-model.html#to-specify-a-model",
    "title": "3 - What makes a model?",
    "section": "To specify a model ",
    "text": "To specify a model \n\n\n\n\nChoose a model\nSpecify an engine\nSet the mode\n\n\n\n\n\n\nCredit: https://www.svgrepo.com/svg/481270/cat-5"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-1",
    "href": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-1",
    "title": "3 - What makes a model?",
    "section": "To specify a model  ",
    "text": "To specify a model  \n\nproportional_hazards()\n#&gt; Proportional Hazards Model Specification (censored regression)\n#&gt; \n#&gt; Computational engine: survival\n\n\nModels have default engines"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-2",
    "href": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-2",
    "title": "3 - What makes a model?",
    "section": "To specify a model  ",
    "text": "To specify a model  \n\nproportional_hazards() %&gt;%\n  set_engine(\"glmnet\")\n#&gt; Proportional Hazards Model Specification (censored regression)\n#&gt; \n#&gt; Computational engine: glmnet\n\n\nPH has only one mode, hence also a default mode"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-3",
    "href": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-3",
    "title": "3 - What makes a model?",
    "section": "To specify a model ",
    "text": "To specify a model \n\ndecision_tree()\n#&gt; Decision Tree Model Specification (unknown mode)\n#&gt; \n#&gt; Computational engine: rpart\n\n\nSome models have a default mode but not all"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-4",
    "href": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-4",
    "title": "3 - What makes a model?",
    "section": "To specify a model  ",
    "text": "To specify a model  \n\ndecision_tree() %&gt;% \n  set_mode(\"censored regression\")\n#&gt; Decision Tree Model Specification (censored regression)\n#&gt; \n#&gt; Computational engine: rpart\n\n\n\n\nAll available models are listed at https://www.tidymodels.org/find/parsnip/"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-5",
    "href": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-5",
    "title": "3 - What makes a model?",
    "section": "To specify a model ",
    "text": "To specify a model \n\n\n\nChoose a model\nSpecify an engine\nSet the mode"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-6",
    "href": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-6",
    "title": "3 - What makes a model?",
    "section": "To specify a model ",
    "text": "To specify a model \n\ndecision_tree()\n#&gt; Decision Tree Model Specification (unknown mode)\n#&gt; \n#&gt; Computational engine: rpart\n\n\nSome models have a default mode"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-7",
    "href": "slides/intro-03-what-makes-a-model.html#to-specify-a-model-7",
    "title": "3 - What makes a model?",
    "section": "To specify a model  ",
    "text": "To specify a model  \n\ndecision_tree() %&gt;% \n  set_mode(\"censored regression\")\n#&gt; Decision Tree Model Specification (censored regression)\n#&gt; \n#&gt; Computational engine: rpart\n\n\n\n\nAll available models are listed at https://www.tidymodels.org/find/parsnip/"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#your-turn-1",
    "href": "slides/intro-03-what-makes-a-model.html#your-turn-1",
    "title": "3 - What makes a model?",
    "section": "Your turn",
    "text": "Your turn\n\nWrite the specification for a proportional hazards model.\nChoose your engine.\n\nAll available models are listed at https://www.tidymodels.org/find/parsnip/\n\n\nExtension/Challenge: Edit this code to use a different model. For example, try using a conditional inference tree as implemented in the partykit package - or try an entirely different model type!\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#models-well-be-using-today",
    "href": "slides/intro-03-what-makes-a-model.html#models-well-be-using-today",
    "title": "3 - What makes a model?",
    "section": "Models we’ll be using today",
    "text": "Models we’ll be using today\n\nProportional hazards (PH) model\nDecision tree"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#proportional-hazards-model",
    "href": "slides/intro-03-what-makes-a-model.html#proportional-hazards-model",
    "title": "3 - What makes a model?",
    "section": "Proportional hazards model",
    "text": "Proportional hazards model"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#proportional-hazards-model-1",
    "href": "slides/intro-03-what-makes-a-model.html#proportional-hazards-model-1",
    "title": "3 - What makes a model?",
    "section": "Proportional hazards model",
    "text": "Proportional hazards model\n\n\n\n\n\n\n\n\n\n\n\n\n\nHazard modeled via a baseline hazard and a linear combination of predictors:\n\n\\(\\lambda(t | x_i) = \\lambda_0(t) \\cdot \\exp (x_i^T \\beta)\\)"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#proportional-hazards-model-2",
    "href": "slides/intro-03-what-makes-a-model.html#proportional-hazards-model-2",
    "title": "3 - What makes a model?",
    "section": "Proportional hazards model",
    "text": "Proportional hazards model\n\n\n\n\n\n\n\n\n\n\n\n\n\nHazard modeled via a baseline hazard and a linear combination of predictors:\n\n\\(\\lambda(t | x_i) = \\lambda_0(t) \\cdot \\exp (x_i^T \\beta)\\)\n\nThe hazard is proportional over all time \\(t\\), and thus also the probability of survival is proportional."
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#decision-tree",
    "href": "slides/intro-03-what-makes-a-model.html#decision-tree",
    "title": "3 - What makes a model?",
    "section": "Decision tree",
    "text": "Decision tree\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeries of splits or if/then statements based on predictors\nFirst the tree grows until some condition is met (maximum depth, no more data)\nThen the tree is pruned to reduce its complexity"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#decision-tree-1",
    "href": "slides/intro-03-what-makes-a-model.html#decision-tree-1",
    "title": "3 - What makes a model?",
    "section": "Decision tree",
    "text": "Decision tree"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#decision-tree-2",
    "href": "slides/intro-03-what-makes-a-model.html#decision-tree-2",
    "title": "3 - What makes a model?",
    "section": "Decision tree",
    "text": "Decision tree"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#all-models-are-wrong-but-some-are-useful",
    "href": "slides/intro-03-what-makes-a-model.html#all-models-are-wrong-but-some-are-useful",
    "title": "3 - What makes a model?",
    "section": "All models are wrong, but some are useful!",
    "text": "All models are wrong, but some are useful!\n\n\nPH model\n\n\n\n\n\n\n\n\n\n\nDecision tree"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#workflows-bind-preprocessors-and-models",
    "href": "slides/intro-03-what-makes-a-model.html#workflows-bind-preprocessors-and-models",
    "title": "3 - What makes a model?",
    "section": "Workflows bind preprocessors and models",
    "text": "Workflows bind preprocessors and models\n\n\nExplain that PCA that is a preprocessor / dimensionality reduction, used to decorrelate data"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#what-is-wrong-with-this",
    "href": "slides/intro-03-what-makes-a-model.html#what-is-wrong-with-this",
    "title": "3 - What makes a model?",
    "section": "What is wrong with this?",
    "text": "What is wrong with this?"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#why-a-workflow",
    "href": "slides/intro-03-what-makes-a-model.html#why-a-workflow",
    "title": "3 - What makes a model?",
    "section": "Why a workflow()? ",
    "text": "Why a workflow()? \n\n\nMost importantly, a workflow captures the entire modeling process: fit() and predict() apply to the preprocessing steps in addition to the actual model fit\n\n\n\n\nYou can use other preprocessors besides formulas (more on feature engineering if time permits!)\n\n\n\n\nThey can help organize your work when working with multiple models\n\n\n\n\nWorkflows handle new data better than base R tools in terms of new factor levels\n\n\nTwo ways workflows handle levels better than base R:\n\nEnforces that new levels are not allowed at prediction time (this is an optional check that can be turned off)\nRestores missing levels that were present at fit time, but happen to be missing at prediction time (like, if your “new” data just doesn’t have an instance of that level)"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#a-model-workflow-1",
    "href": "slides/intro-03-what-makes-a-model.html#a-model-workflow-1",
    "title": "3 - What makes a model?",
    "section": "A model workflow   ",
    "text": "A model workflow   \n\ntree_spec &lt;-\n  decision_tree() %&gt;% \n  set_mode(\"censored regression\")\n\ntree_spec %&gt;% \n  fit(event_time ~ ., data = cat_train) \n#&gt; parsnip model object\n#&gt; \n#&gt; $rpart\n#&gt; n= 1765 \n#&gt; \n#&gt; node), split, n, deviance, yval\n#&gt;       * denotes terminal node\n#&gt; \n#&gt; 1) root 1765 1981.0090 1.0000000  \n#&gt;   2) neutered=no,unknown 696  576.4117 0.5937228 *\n#&gt;   3) neutered=yes 1069 1318.2450 1.1714650  \n#&gt;     6) intake_condition=ill_mild,ill_moderatete,normal,under_age_or_weight,other 921 1063.5830 1.0808970 *\n#&gt;     7) intake_condition=feral,fractious 148  195.7649 2.3866130 *\n#&gt; \n#&gt; $survfit\n#&gt; \n#&gt; Call: prodlim::prodlim(formula = form, data = data)\n#&gt; \n#&gt; \n#&gt; \n#&gt; Right-censored response of a survival model\n#&gt; \n#&gt; No.Observations: 1765 \n#&gt; \n#&gt; Pattern:\n#&gt;                 Freq\n#&gt;  event          1116\n#&gt;  right.censored 649 \n#&gt; \n#&gt; $levels\n#&gt; [1] \"0.593722848021764\" \"1.08089686322063\"  \"2.38661313111009\" \n#&gt; \n#&gt; attr(,\"class\")\n#&gt; [1] \"pecRpart\""
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#a-model-workflow-2",
    "href": "slides/intro-03-what-makes-a-model.html#a-model-workflow-2",
    "title": "3 - What makes a model?",
    "section": "A model workflow   ",
    "text": "A model workflow   \n\ntree_spec &lt;-\n  decision_tree() %&gt;% \n  set_mode(\"censored regression\")\n\nworkflow() %&gt;%\n  add_formula(event_time ~ .) %&gt;%\n  add_model(tree_spec) %&gt;%\n  fit(data = cat_train) \n#&gt; ══ Workflow [trained] ════════════════════════════════════════════════\n#&gt; Preprocessor: Formula\n#&gt; Model: decision_tree()\n#&gt; \n#&gt; ── Preprocessor ──────────────────────────────────────────────────────\n#&gt; event_time ~ .\n#&gt; \n#&gt; ── Model ─────────────────────────────────────────────────────────────\n#&gt; $rpart\n#&gt; n= 1765 \n#&gt; \n#&gt; node), split, n, deviance, yval\n#&gt;       * denotes terminal node\n#&gt; \n#&gt; 1) root 1765 1981.0090 1.0000000  \n#&gt;   2) neutered=no,unknown 696  576.4117 0.5937228 *\n#&gt;   3) neutered=yes 1069 1318.2450 1.1714650  \n#&gt;     6) intake_condition=ill_mild,ill_moderatete,normal,under_age_or_weight,other 921 1063.5830 1.0808970 *\n#&gt;     7) intake_condition=feral,fractious 148  195.7649 2.3866130 *\n#&gt; \n#&gt; $survfit\n#&gt; \n#&gt; Call: prodlim::prodlim(formula = form, data = data)\n#&gt; \n#&gt; \n#&gt; \n#&gt; Right-censored response of a survival model\n#&gt; \n#&gt; No.Observations: 1765 \n#&gt; \n#&gt; Pattern:\n#&gt;                 Freq\n#&gt;  event          1116\n#&gt;  right.censored 649 \n#&gt; \n#&gt; $levels\n#&gt; [1] \"0.593722848021763\" \"1.08089686322063\"  \"2.38661313111009\" \n#&gt; \n#&gt; attr(,\"class\")\n#&gt; [1] \"pecRpart\""
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#a-model-workflow-3",
    "href": "slides/intro-03-what-makes-a-model.html#a-model-workflow-3",
    "title": "3 - What makes a model?",
    "section": "A model workflow   ",
    "text": "A model workflow   \n\ntree_spec &lt;-\n  decision_tree() %&gt;% \n  set_mode(\"censored regression\")\n\ntree_fit &lt;-\n  workflow(event_time ~ ., tree_spec) %&gt;% \n  fit(data = cat_train)"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#your-turn-2",
    "href": "slides/intro-03-what-makes-a-model.html#your-turn-2",
    "title": "3 - What makes a model?",
    "section": "Your turn",
    "text": "Your turn\n\nMake a workflow with your own model of choice.\n\nExtension/Challenge: Other than formulas, what kinds of preprocessors are supported?\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#predict-with-your-model",
    "href": "slides/intro-03-what-makes-a-model.html#predict-with-your-model",
    "title": "3 - What makes a model?",
    "section": "Predict with your model   ",
    "text": "Predict with your model   \nHow do you use your new tree_fit model?\n\npredict(tree_fit, new_data = demo_cats)\n#&gt; # A tibble: 50 × 1\n#&gt;    .pred_time\n#&gt;         &lt;dbl&gt;\n#&gt;  1      1.08 \n#&gt;  2      0.594\n#&gt;  3      0.594\n#&gt;  4      1.08 \n#&gt;  5      2.39 \n#&gt;  6      0.594\n#&gt;  7      1.08 \n#&gt;  8      0.594\n#&gt;  9      1.08 \n#&gt; 10      0.594\n#&gt; # ℹ 40 more rows"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#predict-with-your-model-1",
    "href": "slides/intro-03-what-makes-a-model.html#predict-with-your-model-1",
    "title": "3 - What makes a model?",
    "section": "Predict with your model   ",
    "text": "Predict with your model   \nHow do you use your new tree_fit model?\n\npredict(tree_fit, new_data = demo_cats, type = \"time\")\n#&gt; # A tibble: 50 × 1\n#&gt;    .pred_time\n#&gt;         &lt;dbl&gt;\n#&gt;  1      1.08 \n#&gt;  2      0.594\n#&gt;  3      0.594\n#&gt;  4      1.08 \n#&gt;  5      2.39 \n#&gt;  6      0.594\n#&gt;  7      1.08 \n#&gt;  8      0.594\n#&gt;  9      1.08 \n#&gt; 10      0.594\n#&gt; # ℹ 40 more rows"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#predict-with-your-model-2",
    "href": "slides/intro-03-what-makes-a-model.html#predict-with-your-model-2",
    "title": "3 - What makes a model?",
    "section": "Predict with your model   ",
    "text": "Predict with your model   \n\npreds &lt;- predict(tree_fit, new_data = demo_cats, type = \"survival\", \n                 eval_time = seq(0, 365, by = 5))\npreds\n#&gt; # A tibble: 50 × 1\n#&gt;    .pred            \n#&gt;    &lt;list&gt;           \n#&gt;  1 &lt;tibble [74 × 2]&gt;\n#&gt;  2 &lt;tibble [74 × 2]&gt;\n#&gt;  3 &lt;tibble [74 × 2]&gt;\n#&gt;  4 &lt;tibble [74 × 2]&gt;\n#&gt;  5 &lt;tibble [74 × 2]&gt;\n#&gt;  6 &lt;tibble [74 × 2]&gt;\n#&gt;  7 &lt;tibble [74 × 2]&gt;\n#&gt;  8 &lt;tibble [74 × 2]&gt;\n#&gt;  9 &lt;tibble [74 × 2]&gt;\n#&gt; 10 &lt;tibble [74 × 2]&gt;\n#&gt; # ℹ 40 more rows"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#predict-with-your-model-3",
    "href": "slides/intro-03-what-makes-a-model.html#predict-with-your-model-3",
    "title": "3 - What makes a model?",
    "section": "Predict with your model   ",
    "text": "Predict with your model   \n\npreds$.pred[[1]]\n#&gt; # A tibble: 74 × 2\n#&gt;    .eval_time .pred_survival\n#&gt;         &lt;dbl&gt;          &lt;dbl&gt;\n#&gt;  1          0          1    \n#&gt;  2          5          1    \n#&gt;  3         10          0.923\n#&gt;  4         15          0.813\n#&gt;  5         20          0.749\n#&gt;  6         25          0.690\n#&gt;  7         30          0.637\n#&gt;  8         35          0.588\n#&gt;  9         40          0.536\n#&gt; 10         45          0.495\n#&gt; # ℹ 64 more rows"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#predict-with-your-model-4",
    "href": "slides/intro-03-what-makes-a-model.html#predict-with-your-model-4",
    "title": "3 - What makes a model?",
    "section": "Predict with your model   ",
    "text": "Predict with your model"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#predict-with-your-model-5",
    "href": "slides/intro-03-what-makes-a-model.html#predict-with-your-model-5",
    "title": "3 - What makes a model?",
    "section": "Predict with your model   ",
    "text": "Predict with your model"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#your-turn-3",
    "href": "slides/intro-03-what-makes-a-model.html#your-turn-3",
    "title": "3 - What makes a model?",
    "section": "Your turn",
    "text": "Your turn\n\nRun:\naugment(tree_fit, new_data = demo_cats,\neval_time = seq(0, 365, by = 5))\n\nWhat do you get?\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#the-whole-game---status-update",
    "href": "slides/intro-03-what-makes-a-model.html#the-whole-game---status-update",
    "title": "3 - What makes a model?",
    "section": "The whole game - status update",
    "text": "The whole game - status update\n\n\nStress that fitting a model on the entire training set was only for illustrating how to fit a model\n\n\n\n\nhttps://hfrick.github.io/tidymodels-survival-workshop"
  },
  {
    "objectID": "slides/intro-05-tuning-models.html",
    "href": "slides/intro-05-tuning-models.html",
    "title": "5 - Tuning models",
    "section": "",
    "text": "#&gt; ── Attaching packages ──────────────────────────── tidymodels 1.2.0 ──\n#&gt; ✔ broom        1.0.6      ✔ rsample      1.2.1 \n#&gt; ✔ dials        1.2.1      ✔ tibble       3.2.1 \n#&gt; ✔ dplyr        1.1.4      ✔ tidyr        1.3.1 \n#&gt; ✔ infer        1.0.7      ✔ tune         1.2.1 \n#&gt; ✔ modeldata    1.4.0      ✔ workflows    1.1.4 \n#&gt; ✔ parsnip      1.2.1      ✔ workflowsets 1.1.0 \n#&gt; ✔ purrr        1.0.2      ✔ yardstick    1.3.1 \n#&gt; ✔ recipes      1.0.10\n#&gt; ── Conflicts ─────────────────────────────── tidymodels_conflicts() ──\n#&gt; ✖ purrr::discard() masks scales::discard()\n#&gt; ✖ dplyr::filter()  masks stats::filter()\n#&gt; ✖ dplyr::lag()     masks stats::lag()\n#&gt; ✖ recipes::step()  masks stats::step()\n#&gt; • Search for functions across packages at https://www.tidymodels.org/find/\n#&gt; Loading required package: survival"
  },
  {
    "objectID": "slides/intro-05-tuning-models.html#tuning-parameters",
    "href": "slides/intro-05-tuning-models.html#tuning-parameters",
    "title": "5 - Tuning models",
    "section": "Tuning parameters",
    "text": "Tuning parameters\nSome model or preprocessing parameters cannot be estimated directly from the data.\n\nSome examples:\n\nTree depth in decision trees\nNumber of neighbors in a K-nearest neighbor model"
  },
  {
    "objectID": "slides/intro-05-tuning-models.html#optimize-tuning-parameters",
    "href": "slides/intro-05-tuning-models.html#optimize-tuning-parameters",
    "title": "5 - Tuning models",
    "section": "Optimize tuning parameters",
    "text": "Optimize tuning parameters\n\nTry different values and measure their performance.\n\n\n\nFind good values for these parameters.\n\n\n\n\nOnce the value(s) of the parameter(s) are determined, a model can be finalized by fitting the model to the entire training set."
  },
  {
    "objectID": "slides/intro-05-tuning-models.html#optimize-tuning-parameters-1",
    "href": "slides/intro-05-tuning-models.html#optimize-tuning-parameters-1",
    "title": "5 - Tuning models",
    "section": "Optimize tuning parameters",
    "text": "Optimize tuning parameters\nThe main two strategies for optimization are:\n\n\nGrid search 💠 which tests a pre-defined set of candidate values\nIterative search 🌀 which suggests/estimates new values of candidate parameters to evaluate"
  },
  {
    "objectID": "slides/intro-05-tuning-models.html#specifying-tuning-parameters",
    "href": "slides/intro-05-tuning-models.html#specifying-tuning-parameters",
    "title": "5 - Tuning models",
    "section": "Specifying tuning parameters",
    "text": "Specifying tuning parameters\nLet’s take our previous random forest workflow and tag for tuning the minimum number of data points in each node:\n\nrf_spec &lt;- rand_forest(min_n = tune()) %&gt;% \n  set_engine(\"aorsf\") %&gt;% \n  set_mode(\"censored regression\")\n\nrf_wflow &lt;- workflow(event_time ~ ., rf_spec)\nrf_wflow\n#&gt; ══ Workflow ══════════════════════════════════════════════════════════\n#&gt; Preprocessor: Formula\n#&gt; Model: rand_forest()\n#&gt; \n#&gt; ── Preprocessor ──────────────────────────────────────────────────────\n#&gt; event_time ~ .\n#&gt; \n#&gt; ── Model ─────────────────────────────────────────────────────────────\n#&gt; Random Forest Model Specification (censored regression)\n#&gt; \n#&gt; Main Arguments:\n#&gt;   min_n = tune()\n#&gt; \n#&gt; Computational engine: aorsf"
  },
  {
    "objectID": "slides/intro-05-tuning-models.html#try-out-multiple-values",
    "href": "slides/intro-05-tuning-models.html#try-out-multiple-values",
    "title": "5 - Tuning models",
    "section": "Try out multiple values",
    "text": "Try out multiple values\ntune_grid() works similar to fit_resamples() but covers multiple parameter values:\n\nset.seed(22)\nrf_res &lt;- tune_grid(\n  rf_wflow,\n  cat_folds,\n  eval_time = c(90, 30, 60, 120),\n  grid = 5\n)"
  },
  {
    "objectID": "slides/intro-05-tuning-models.html#compare-results",
    "href": "slides/intro-05-tuning-models.html#compare-results",
    "title": "5 - Tuning models",
    "section": "Compare results",
    "text": "Compare results\nInspecting results and selecting the best-performing hyperparameter(s):\n\nshow_best(rf_res)\n#&gt; # A tibble: 5 × 8\n#&gt;   min_n .metric        .estimator .eval_time  mean     n std_err .config        \n#&gt;   &lt;int&gt; &lt;chr&gt;          &lt;chr&gt;           &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;          \n#&gt; 1    33 brier_survival standard           90 0.197    10 0.00937 Preprocessor1_…\n#&gt; 2    31 brier_survival standard           90 0.198    10 0.00953 Preprocessor1_…\n#&gt; 3    13 brier_survival standard           90 0.198    10 0.00956 Preprocessor1_…\n#&gt; 4    21 brier_survival standard           90 0.199    10 0.00960 Preprocessor1_…\n#&gt; 5     6 brier_survival standard           90 0.199    10 0.00977 Preprocessor1_…\n\nbest_parameter &lt;- select_best(rf_res)\nbest_parameter\n#&gt; # A tibble: 1 × 2\n#&gt;   min_n .config             \n#&gt;   &lt;int&gt; &lt;chr&gt;               \n#&gt; 1    33 Preprocessor1_Model1\n\ncollect_metrics() and autoplot() are also available."
  },
  {
    "objectID": "slides/intro-05-tuning-models.html#the-final-fit",
    "href": "slides/intro-05-tuning-models.html#the-final-fit",
    "title": "5 - Tuning models",
    "section": "The final fit",
    "text": "The final fit\n\nrf_wflow &lt;- finalize_workflow(rf_wflow, best_parameter)\n\nfinal_fit &lt;- last_fit(rf_wflow, cat_split, eval_time = c(90, 30, 60, 120)) \n\ncollect_metrics(final_fit)\n#&gt; # A tibble: 4 × 5\n#&gt;   .metric        .estimator .eval_time .estimate .config             \n#&gt;   &lt;chr&gt;          &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;               \n#&gt; 1 brier_survival standard           30     0.221 Preprocessor1_Model1\n#&gt; 2 brier_survival standard           60     0.225 Preprocessor1_Model1\n#&gt; 3 brier_survival standard           90     0.160 Preprocessor1_Model1\n#&gt; 4 brier_survival standard          120     0.107 Preprocessor1_Model1"
  },
  {
    "objectID": "slides/intro-05-tuning-models.html#your-turn",
    "href": "slides/intro-05-tuning-models.html#your-turn",
    "title": "5 - Tuning models",
    "section": "Your turn",
    "text": "Your turn\n\nModify your model workflow to tune one or more parameters.\nUse grid search to find the best parameter(s).\n\n\n\n−+\n05:00\n\n\n\n\n\n\nhttps://hfrick.github.io/tidymodels-survival-workshop"
  },
  {
    "objectID": "slides/annotations.html#concordance",
    "href": "slides/annotations.html#concordance",
    "title": "Annotations",
    "section": "Concordance",
    "text": "Concordance\nSince risk regression and parametric survival models are modeling different characteristics (e.g. relative hazard versus event time), their linear predictors will be going in opposite directions.\nFor example, for parametric models, the linear predictor increases with time. For proportional hazards models the linear predictor decreases with time (since hazard is increasing). As such, the linear predictors for these two quantities will have opposite signs.\ntidymodels does not treat different models differently when computing performance metrics. To standardize across model types, the default for proportional hazards models is to have increasing values with time. As a result, the sign of the linear predictor will be the opposite of the value produced by the predict() method in the engine package.\nThis behavior can be changed by using the increasing argument when calling predict() on a parsnip model object."
  },
  {
    "objectID": "slides/intro-02-data-budget.html#location",
    "href": "slides/intro-02-data-budget.html#location",
    "title": "2 - Your data budget",
    "section": "Location",
    "text": "Location\n\n\nlibrary(leaflet)\n\ncat_train %&gt;% \n  leaflet() %&gt;%\n  addProviderTiles(\"CartoDB.Positron\") %&gt;%  \n  addCircles(lng = ~ longitude, \n             lat = ~ latitude)"
  },
  {
    "objectID": "slides/intro-02-data-budget.html#location-output",
    "href": "slides/intro-02-data-budget.html#location-output",
    "title": "2 - Your data budget",
    "section": "Location",
    "text": "Location"
  },
  {
    "objectID": "slides/annotations.html#location",
    "href": "slides/annotations.html#location",
    "title": "Annotations",
    "section": "Location",
    "text": "Location\nTo get a sense whether or not the location has an influence on our outcome, we can fit a proportional hazards model with a spline on the continuous predictor (logitude or latitude) and take a look at the linear predictor. To do so, Max wrote a custom function, smooth_ph_linear_pred(), that is available in slides/setup.R.\n\nsmooth_ph_linear_pred(event_time ~ latitude, data = cat_train, deg_free = 6)\n\n\n\n\n\n\n\n\n\nsmooth_ph_linear_pred(event_time ~ longitude, data = cat_train, deg_free = 5)"
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#fit-a-model-spec",
    "href": "slides/intro-03-what-makes-a-model.html#fit-a-model-spec",
    "title": "3 - What makes a model?",
    "section": "Fit a model spec  ",
    "text": "Fit a model spec  \n\ntree_spec &lt;-\n  decision_tree() %&gt;% \n  set_mode(\"censored regression\")\n\ntree_spec %&gt;% \n  fit(event_time ~ ., data = cat_train) \n#&gt; parsnip model object\n#&gt; \n#&gt; $rpart\n#&gt; n= 1765 \n#&gt; \n#&gt; node), split, n, deviance, yval\n#&gt;       * denotes terminal node\n#&gt; \n#&gt; 1) root 1765 1981.0090 1.0000000  \n#&gt;   2) neutered=no,unknown 696  576.4117 0.5937228 *\n#&gt;   3) neutered=yes 1069 1318.2450 1.1714650  \n#&gt;     6) intake_condition=ill_mild,ill_moderatete,normal,under_age_or_weight,other 921 1063.5830 1.0808970 *\n#&gt;     7) intake_condition=feral,fractious 148  195.7649 2.3866130 *\n#&gt; \n#&gt; $survfit\n#&gt; \n#&gt; Call: prodlim::prodlim(formula = form, data = data)\n#&gt; \n#&gt; \n#&gt; \n#&gt; Right-censored response of a survival model\n#&gt; \n#&gt; No.Observations: 1765 \n#&gt; \n#&gt; Pattern:\n#&gt;                 Freq\n#&gt;  event          1116\n#&gt;  right.censored 649 \n#&gt; \n#&gt; $levels\n#&gt; [1] \"0.593722848021764\" \"1.08089686322063\"  \"2.38661313111009\" \n#&gt; \n#&gt; attr(,\"class\")\n#&gt; [1] \"pecRpart\""
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#fit-a-model-workflow",
    "href": "slides/intro-03-what-makes-a-model.html#fit-a-model-workflow",
    "title": "3 - What makes a model?",
    "section": "Fit a model workflow   ",
    "text": "Fit a model workflow   \n\ntree_spec &lt;-\n  decision_tree() %&gt;% \n  set_mode(\"censored regression\")\n\nworkflow() %&gt;%\n  add_formula(event_time ~ .) %&gt;%\n  add_model(tree_spec) %&gt;%\n  fit(data = cat_train) \n#&gt; ══ Workflow [trained] ════════════════════════════════════════════════\n#&gt; Preprocessor: Formula\n#&gt; Model: decision_tree()\n#&gt; \n#&gt; ── Preprocessor ──────────────────────────────────────────────────────\n#&gt; event_time ~ .\n#&gt; \n#&gt; ── Model ─────────────────────────────────────────────────────────────\n#&gt; $rpart\n#&gt; n= 1765 \n#&gt; \n#&gt; node), split, n, deviance, yval\n#&gt;       * denotes terminal node\n#&gt; \n#&gt; 1) root 1765 1981.0090 1.0000000  \n#&gt;   2) neutered=no,unknown 696  576.4117 0.5937228 *\n#&gt;   3) neutered=yes 1069 1318.2450 1.1714650  \n#&gt;     6) intake_condition=ill_mild,ill_moderatete,normal,under_age_or_weight,other 921 1063.5830 1.0808970 *\n#&gt;     7) intake_condition=feral,fractious 148  195.7649 2.3866130 *\n#&gt; \n#&gt; $survfit\n#&gt; \n#&gt; Call: prodlim::prodlim(formula = form, data = data)\n#&gt; \n#&gt; \n#&gt; \n#&gt; Right-censored response of a survival model\n#&gt; \n#&gt; No.Observations: 1765 \n#&gt; \n#&gt; Pattern:\n#&gt;                 Freq\n#&gt;  event          1116\n#&gt;  right.censored 649 \n#&gt; \n#&gt; $levels\n#&gt; [1] \"0.593722848021763\" \"1.08089686322063\"  \"2.38661313111009\" \n#&gt; \n#&gt; attr(,\"class\")\n#&gt; [1] \"pecRpart\""
  },
  {
    "objectID": "slides/intro-03-what-makes-a-model.html#fit-a-model-workflow-1",
    "href": "slides/intro-03-what-makes-a-model.html#fit-a-model-workflow-1",
    "title": "3 - What makes a model?",
    "section": "Fit a model workflow   ",
    "text": "Fit a model workflow   \n\ntree_spec &lt;-\n  decision_tree() %&gt;% \n  set_mode(\"censored regression\")\n\ntree_fit &lt;-\n  workflow(event_time ~ ., tree_spec) %&gt;% \n  fit(data = cat_train)"
  }
]